{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Microsoft Purview One-Stop-Shop (OSS) \u2693\ufe0e The Customer Acceleration Team (CAT) is a World Wide team, our charter is helping customers deploy M365 security and compliance products. We do this through understanding the benefits of the product, being the voice of the customer inside engineering, help prioritize bugs and features, and lastly shape the product which benefits the customer's use cases scenarios while protecting and governing their most sensitive data. We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Also, do submit your feedback and contributions to the site via the appropriate links. Disclaimer This site supplements the official Microsoft Purview documentation and other information on the docs.microsoft.com site. The resources on this site are direct from the Microsoft Purview CAT team. We work closely with customers to collect insights, develop recommendations, and distil best practices for deploying Microsoft compliance solutions. Use the content on this site to benefit from our experience and lessons learned when you plan and deploy your own compliance solutions, and use the official documentation for supportability, licensing, and other information from the product group. Getting Started \u2693\ufe0e Visit the docs site to review Microsoft Purview documentation Ready to deploy? Start with guidance from CxE Deployment Acceleration Guides (DAGs) Review the license requirements for features Security and Compliance Licensing Guidance Always use a development tenant for Proof of Concept and testing What is a 'Dev Tenant' and why would you want one? Looking for information on Microsoft Security? Microsoft Security Technical Content Library Social Media and Forums \u2693\ufe0e Microsoft Purview Information Protection Yammer Channel Upcoming Webinars \u2693\ufe0e The Microsoft Purview CxE team regularly hosts webinars to present what's changing and new with our products. Check out the Webinars page for upcoming webinars. Note Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A. Learn more about... \u2693\ufe0e Microsoft Purview Audit (Premium) Microsoft Purview Communication Compliance Microsoft Purview Compliance Manager Microsoft Purview Data Loss Prevention Microsoft Purview eDiscovery (Premium) Microsoft Purview Insider Risk Management Microsoft Purview Data Lifecycle Management and Records Management Microsoft Purview Information Protection","title":"One Stop Shop"},{"location":"#microsoft-purview-one-stop-shop-oss","text":"The Customer Acceleration Team (CAT) is a World Wide team, our charter is helping customers deploy M365 security and compliance products. We do this through understanding the benefits of the product, being the voice of the customer inside engineering, help prioritize bugs and features, and lastly shape the product which benefits the customer's use cases scenarios while protecting and governing their most sensitive data. We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Also, do submit your feedback and contributions to the site via the appropriate links. Disclaimer This site supplements the official Microsoft Purview documentation and other information on the docs.microsoft.com site. The resources on this site are direct from the Microsoft Purview CAT team. We work closely with customers to collect insights, develop recommendations, and distil best practices for deploying Microsoft compliance solutions. Use the content on this site to benefit from our experience and lessons learned when you plan and deploy your own compliance solutions, and use the official documentation for supportability, licensing, and other information from the product group.","title":"Microsoft Purview One-Stop-Shop (OSS)"},{"location":"#getting-started","text":"Visit the docs site to review Microsoft Purview documentation Ready to deploy? Start with guidance from CxE Deployment Acceleration Guides (DAGs) Review the license requirements for features Security and Compliance Licensing Guidance Always use a development tenant for Proof of Concept and testing What is a 'Dev Tenant' and why would you want one? Looking for information on Microsoft Security? Microsoft Security Technical Content Library","title":"Getting Started"},{"location":"#social-media-and-forums","text":"Microsoft Purview Information Protection Yammer Channel","title":"Social Media and Forums"},{"location":"#upcoming-webinars","text":"The Microsoft Purview CxE team regularly hosts webinars to present what's changing and new with our products. Check out the Webinars page for upcoming webinars. Note Every webinar is always recorded and published here along with the PowerPoint Decks and Q&A.","title":"Upcoming Webinars"},{"location":"#learn-more-about","text":"Microsoft Purview Audit (Premium) Microsoft Purview Communication Compliance Microsoft Purview Compliance Manager Microsoft Purview Data Loss Prevention Microsoft Purview eDiscovery (Premium) Microsoft Purview Insider Risk Management Microsoft Purview Data Lifecycle Management and Records Management Microsoft Purview Information Protection","title":"Learn more about..."},{"location":"dag/","text":"Deployment Acceleration Guides \u2693\ufe0e The deployment acceleration guides (DAGs) are written and updated continually by the global Compliance CxE team and are a resource designed to help with the following: One Compliance Story covering how each solution complements each other Best Practices based on the CxE team's experience with customer roadblocks Considerations to take and research before starting your deployment Help Resources links to additional readings and topics to gain a deeper understanding of the solution Appendix for additional information on licensing The guides can be used both independently, but we recommend using all the solutions together for your deployment needs. We are not recommending one solution be implemented before another but have included information in each guide to tie all the solutions together with features to consider during your implementation. The guide covers current released feature as of today and is continuously updated as additional features progress from beta, or private preview to general availability. How to use the Deployment Acceleration Guide \u2693\ufe0e Organizations of all types are moving to the cloud and adopting more solutions to meet data protection and compliance requirements from the Microsoft 365 (M365) suite of capabilities. Use this guide as a comprehensive source for the suite of solutions across information protection and compliance. Start by understanding best practices, key considerations and lessons learned from others who have gone before you. Use this cumulative knowledge and processes outlined in the following pages to drive alignment and consensus in your organization by taking the first steps toward a more secure, compliant posture for your organization in the cloud. Each of the sections in this guide can be leveraged as standalone guidance, or all together to define your overall compliance strategy. Many of the solutions covered in this guide will require participation from various teams and business groups within your organization. Customers who achieve successful roll outs of the capabilities typically prioritize by a use case scenario and create a working virtual team to manage the requirements validation, proof of concept testing in a pre-production environment, internal checkpoints, and approvals and finally deployment into the production environment. We recommend identifying your top 1-2 scenarios for deployment and tackling those first, with the right resources from your broader team engaged. Once those priorities are deployed, come back to this guide to identify the next two priorities for deployment and repeat the process of stakeholder alignment, testing and validation on the path to successful deployment. We believe our solutions from Microsoft 365 are the best of suite to help our customers know their data better, by protecting and governing data throughout its lifecycle in a heterogenous environment. This is often the key starting point for many of our customers in their modern compliance journey \u2013 knowing what sensitive data they have, creating flexible, end-user friendly policies for both security and compliance outcomes and using more automation and intelligence. Getting Started \u2693\ufe0e Before jumping into the various sections detailing the deployment, there are some planning and prerequisite items that should be addressed. These include general prerequisites, such as scheduling and recommended attendance of meetings, and support and communication planning. We will touch on these items and provide some general guidance based on what we have seen help customers succeed in deployments of Microsoft Information Protection & Compliance. While these tips are meant to help guide you on your deployment journey, please keep in mind that these items will vary widely depending on the size, regulatory requirements, and complexity of your organization. DAGs By Feature \u2693\ufe0e Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Insider Risk Management and Communication Compliance Microsoft Information Governance and Records Management Microsoft Information Protection and Data Loss Prevention","title":"Getting Started"},{"location":"dag/#deployment-acceleration-guides","text":"The deployment acceleration guides (DAGs) are written and updated continually by the global Compliance CxE team and are a resource designed to help with the following: One Compliance Story covering how each solution complements each other Best Practices based on the CxE team's experience with customer roadblocks Considerations to take and research before starting your deployment Help Resources links to additional readings and topics to gain a deeper understanding of the solution Appendix for additional information on licensing The guides can be used both independently, but we recommend using all the solutions together for your deployment needs. We are not recommending one solution be implemented before another but have included information in each guide to tie all the solutions together with features to consider during your implementation. The guide covers current released feature as of today and is continuously updated as additional features progress from beta, or private preview to general availability.","title":"Deployment Acceleration Guides"},{"location":"dag/#how-to-use-the-deployment-acceleration-guide","text":"Organizations of all types are moving to the cloud and adopting more solutions to meet data protection and compliance requirements from the Microsoft 365 (M365) suite of capabilities. Use this guide as a comprehensive source for the suite of solutions across information protection and compliance. Start by understanding best practices, key considerations and lessons learned from others who have gone before you. Use this cumulative knowledge and processes outlined in the following pages to drive alignment and consensus in your organization by taking the first steps toward a more secure, compliant posture for your organization in the cloud. Each of the sections in this guide can be leveraged as standalone guidance, or all together to define your overall compliance strategy. Many of the solutions covered in this guide will require participation from various teams and business groups within your organization. Customers who achieve successful roll outs of the capabilities typically prioritize by a use case scenario and create a working virtual team to manage the requirements validation, proof of concept testing in a pre-production environment, internal checkpoints, and approvals and finally deployment into the production environment. We recommend identifying your top 1-2 scenarios for deployment and tackling those first, with the right resources from your broader team engaged. Once those priorities are deployed, come back to this guide to identify the next two priorities for deployment and repeat the process of stakeholder alignment, testing and validation on the path to successful deployment. We believe our solutions from Microsoft 365 are the best of suite to help our customers know their data better, by protecting and governing data throughout its lifecycle in a heterogenous environment. This is often the key starting point for many of our customers in their modern compliance journey \u2013 knowing what sensitive data they have, creating flexible, end-user friendly policies for both security and compliance outcomes and using more automation and intelligence.","title":"How to use the Deployment Acceleration Guide"},{"location":"dag/#getting-started","text":"Before jumping into the various sections detailing the deployment, there are some planning and prerequisite items that should be addressed. These include general prerequisites, such as scheduling and recommended attendance of meetings, and support and communication planning. We will touch on these items and provide some general guidance based on what we have seen help customers succeed in deployments of Microsoft Information Protection & Compliance. While these tips are meant to help guide you on your deployment journey, please keep in mind that these items will vary widely depending on the size, regulatory requirements, and complexity of your organization.","title":"Getting Started"},{"location":"dag/#dags-by-feature","text":"Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Insider Risk Management and Communication Compliance Microsoft Information Governance and Records Management Microsoft Information Protection and Data Loss Prevention","title":"DAGs By Feature"},{"location":"how-to-contribute/","text":"The Microsoft Purview CxE team encourages collaboration of our content. This article describes how you can contribute. Submitting an Issue \u2693\ufe0e Notice something incorrect? Have a comment? Submit an issue or make a comment. Select the 'Submit Feedback as an Issue' icon at the top right of the page. This will take you to GitHub, where you will fill out a new 'Issue', then click Submit new issue NOTE: You must be logged in to GitHub to submit an issue. Quick Editing a Page \u2693\ufe0e Want to just make quick changes yourself? Select the 'Edit Page' link at the top right of the page. In GitHub, select the pencil icon to the edit the article NOTE: You must be logged in to GitHub or the edit button will be greyed out Make changes in the web editor. Click the Preview changes tab to check formatting of your change. Once you have made your changes, scroll to the bottom of the page. Enter a title and description for your changes and click Propose file change Now that you've proposed your change, you need to ask the owners of the repository to \"pull\" your changes into their repository. This is done using something called a \"pull request\". When you select Propose file change , a new page similar to the following is displayed: Select Create pull request, enter a title, and optionally a description for the pull request, and then select Create pull request. If you are new to GitHub, see About Pull Requests for more information. That's it! Content team members will review and merge your PR when it's approved. You may get feedback requesting changes.","title":"How to contribute"},{"location":"how-to-contribute/#submitting-an-issue","text":"Notice something incorrect? Have a comment? Submit an issue or make a comment. Select the 'Submit Feedback as an Issue' icon at the top right of the page. This will take you to GitHub, where you will fill out a new 'Issue', then click Submit new issue NOTE: You must be logged in to GitHub to submit an issue.","title":"Submitting an Issue"},{"location":"how-to-contribute/#quick-editing-a-page","text":"Want to just make quick changes yourself? Select the 'Edit Page' link at the top right of the page. In GitHub, select the pencil icon to the edit the article NOTE: You must be logged in to GitHub or the edit button will be greyed out Make changes in the web editor. Click the Preview changes tab to check formatting of your change. Once you have made your changes, scroll to the bottom of the page. Enter a title and description for your changes and click Propose file change Now that you've proposed your change, you need to ask the owners of the repository to \"pull\" your changes into their repository. This is done using something called a \"pull request\". When you select Propose file change , a new page similar to the following is displayed: Select Create pull request, enter a title, and optionally a description for the pull request, and then select Create pull request. If you are new to GitHub, see About Pull Requests for more information. That's it! Content team members will review and merge your PR when it's approved. You may get feedback requesting changes.","title":"Quick Editing a Page"},{"location":"jumpstarts/","text":"What are Jump Start Guides? \u2693\ufe0e Jump starts are step-by-step guidance that we've created to help get started with a feature right away. Their purpose is to achieve a specific goal while considering best practices and guidance specified in our Deployment Acceleration Guides (DAGs) . How can I get started? \u2693\ufe0e Choose an available guide and follow the how-to steps to implement within your own environment. Can I contribute to Jump Start guides? \u2693\ufe0e Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Getting Started"},{"location":"jumpstarts/#what-are-jump-start-guides","text":"Jump starts are step-by-step guidance that we've created to help get started with a feature right away. Their purpose is to achieve a specific goal while considering best practices and guidance specified in our Deployment Acceleration Guides (DAGs) .","title":"What are Jump Start Guides?"},{"location":"jumpstarts/#how-can-i-get-started","text":"Choose an available guide and follow the how-to steps to implement within your own environment.","title":"How can I get started?"},{"location":"jumpstarts/#can-i-contribute-to-jump-start-guides","text":"Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Can I contribute to Jump Start guides?"},{"location":"notes/","text":"What are Notes from the Field? \u2693\ufe0e Notes from the field are similar to blog posts. They are generally targeting a specific idea, concept, or update that we consider important to note - but not deployment-driven like a playbook or jump start. How can I get started? \u2693\ufe0e Choose an available note and enjoy! Can I contribute to Notes from the Field? \u2693\ufe0e Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Getting Started"},{"location":"notes/#what-are-notes-from-the-field","text":"Notes from the field are similar to blog posts. They are generally targeting a specific idea, concept, or update that we consider important to note - but not deployment-driven like a playbook or jump start.","title":"What are Notes from the Field?"},{"location":"notes/#how-can-i-get-started","text":"Choose an available note and enjoy!","title":"How can I get started?"},{"location":"notes/#can-i-contribute-to-notes-from-the-field","text":"Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Can I contribute to Notes from the Field?"},{"location":"playbooks/","text":"What are Playbooks? \u2693\ufe0e Playbooks are guides that help get started with a concept, workload, or feature. Their purpose is to accompany our Deployment Acceleration Guides (DAGs) by providing best practices and recommendations for a successful deployment. How can I get started? \u2693\ufe0e Choose an available playbook and follow along! Can I contribute to Playbooks? \u2693\ufe0e Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Getting Started"},{"location":"playbooks/#what-are-playbooks","text":"Playbooks are guides that help get started with a concept, workload, or feature. Their purpose is to accompany our Deployment Acceleration Guides (DAGs) by providing best practices and recommendations for a successful deployment.","title":"What are Playbooks?"},{"location":"playbooks/#how-can-i-get-started","text":"Choose an available playbook and follow along!","title":"How can I get started?"},{"location":"playbooks/#can-i-contribute-to-playbooks","text":"Yes! All content on the OSS is open source and can be contributed to by anyone. Refer to how to contribute for more information.","title":"Can I contribute to Playbooks?"},{"location":"previews/","text":"New Features to Test! We are excited to on-board you to the Compliance preview program. Steps for joining a preview program \u2693\ufe0e A private Teams channel is the main communication for all preview programs. Request access to this channel via https://aka.ms/MIPC/JoinPreviews . Note If you already filled out the above form, you can access the Private Preview channels here Each preview is discussed in a dedicated channel that is exposed based on preview registration to the specific program. Some preview channels are private and visible just for registered customers. Don't worry if you don't see the channel you are looking for. It means you are not registered to any preview yet. Each available private preview is announced in the \" Preview Notifications \" channel, with a link to a form to fill out to request joining the preview (if applicable). Tip Please verify you publish new posts in the correct channel for each preview.","title":"Join Private Previews"},{"location":"previews/#steps-for-joining-a-preview-program","text":"A private Teams channel is the main communication for all preview programs. Request access to this channel via https://aka.ms/MIPC/JoinPreviews . Note If you already filled out the above form, you can access the Private Preview channels here Each preview is discussed in a dedicated channel that is exposed based on preview registration to the specific program. Some preview channels are private and visible just for registered customers. Don't worry if you don't see the channel you are looking for. It means you are not registered to any preview yet. Each available private preview is announced in the \" Preview Notifications \" channel, with a link to a form to fill out to request joining the preview (if applicable). Tip Please verify you publish new posts in the correct channel for each preview.","title":"Steps for joining a preview program"},{"location":"privacy/","text":"Privacy Policy \u2693\ufe0e Your current consent status is: Unknown ( Change ) TL;DR \u2693\ufe0e This site does not directly collect any data that can be used to identify you. If you consent, we may use cookies for analytics purposes only. The fine print \u2693\ufe0e When we launched our site, we wanted to provide a transparent and privacy-focused experience for our visitors. Our only goal with this site is to provide guidance enriched by our 1:1 customer relationships for deploying Microsoft Purview products. Therefore we elected to not collect any site analytics upon initial release. However, over a short period of time, we learned that certain metrics are needed to better understand how many users are visiting our site, how many are or are not finding it useful, and what content is popular so that we can continue to provide guidance that is useful. Since we still want to be privacy-focused, we decided to use an open-source solution from Microsoft called Clarity which, by default does not use cookies to track our visitors . We have also elected to provide users the option to consent to allowing us to use cookies for analytics purposes only. Doing so will allow us to know if you are a unique visitor or a return visitor. With or without cookies, however, all information is for analytics only and for the sole purpose of improving our site. If you choose to allow necessary cookies only, the only cookie we will drop is to allow your choice to persist. If you choose to allow all cookies, we will only drop a cookie to allow your choice to persist and any cookies that Clarity uses . If you choose to change your cookie preferences , all cookies that we previously dropped will be removed until you update your preferences. You can review the current status at the top of this page. For more information on what data is collected by Clarity, review this document .","title":"Privacy Policy"},{"location":"privacy/#privacy-policy","text":"Your current consent status is: Unknown ( Change )","title":"Privacy Policy"},{"location":"privacy/#tldr","text":"This site does not directly collect any data that can be used to identify you. If you consent, we may use cookies for analytics purposes only.","title":"TL;DR"},{"location":"privacy/#the-fine-print","text":"When we launched our site, we wanted to provide a transparent and privacy-focused experience for our visitors. Our only goal with this site is to provide guidance enriched by our 1:1 customer relationships for deploying Microsoft Purview products. Therefore we elected to not collect any site analytics upon initial release. However, over a short period of time, we learned that certain metrics are needed to better understand how many users are visiting our site, how many are or are not finding it useful, and what content is popular so that we can continue to provide guidance that is useful. Since we still want to be privacy-focused, we decided to use an open-source solution from Microsoft called Clarity which, by default does not use cookies to track our visitors . We have also elected to provide users the option to consent to allowing us to use cookies for analytics purposes only. Doing so will allow us to know if you are a unique visitor or a return visitor. With or without cookies, however, all information is for analytics only and for the sole purpose of improving our site. If you choose to allow necessary cookies only, the only cookie we will drop is to allow your choice to persist. If you choose to allow all cookies, we will only drop a cookie to allow your choice to persist and any cookies that Clarity uses . If you choose to change your cookie preferences , all cookies that we previously dropped will be removed until you update your preferences. You can review the current status at the top of this page. For more information on what data is collected by Clarity, review this document .","title":"The fine print"},{"location":"sbd/","text":"Introduction \u2693\ufe0e In this new series we explore a fictitious company and the process they must go through to fully adopt and deploy Microsoft Purview technologies. Make sure to check back frequently as we continue to release new episodes! The Story \u2693\ufe0e We are a medical research institution, specializing in conducting research on prominent diseases and are currently focused on developing a research study on COVID 19. We are based in two geographic locations, Australia and US. With the recent increase of cyber attacks worldwide however, we need to develop an IP&G strategy to be able to enhance our information security posture.","title":"About the Series"},{"location":"sbd/#introduction","text":"In this new series we explore a fictitious company and the process they must go through to fully adopt and deploy Microsoft Purview technologies. Make sure to check back frequently as we continue to release new episodes!","title":"Introduction"},{"location":"sbd/#the-story","text":"We are a medical research institution, specializing in conducting research on prominent diseases and are currently focused on developing a research study on COVID 19. We are based in two geographic locations, Australia and US. With the recent increase of cyber attacks worldwide however, we need to develop an IP&G strategy to be able to enhance our information security posture.","title":"The Story"},{"location":"surveys/","text":"Microsoft Insider Risk and Communication Compliance Customer Feature Survey \u2693\ufe0e We are excited to announce that the IRCC 22H1 customer feature survey is now open and available! This survey captures some of the asks we captured from our customers via the various engagements, discussions, and feedback channels. Please take a few minutes to share your feedback and help influence the platform. https://aka.ms/mipc/IRCC22H1-FeatureSurvey The survey is available until November 1st, 2021. MIP & DLP 22H1 Customer feature surveys \u2693\ufe0e We are excited to announce that the MIP & DLP 22H1 customer feature surveys are now open and available! These surveys captures the top asks we captured from our customers via the various engagements, discussions and feedback channels. The surveys are available at: Microsoft Information Protection: https://aka.ms/MIPC/MIP22H1-FeatureSurvey Data Loss Prevention: https://aka.ms/MIPC/DLP22H1-FeatureSurvey Surveys will be available until November 2nd, 2021. If you want to influence the platform with features and capabilities that you want, need and like, this is the time to make it happen and share your feedback.","title":"Surveys"},{"location":"surveys/#microsoft-insider-risk-and-communication-compliance-customer-feature-survey","text":"We are excited to announce that the IRCC 22H1 customer feature survey is now open and available! This survey captures some of the asks we captured from our customers via the various engagements, discussions, and feedback channels. Please take a few minutes to share your feedback and help influence the platform. https://aka.ms/mipc/IRCC22H1-FeatureSurvey The survey is available until November 1st, 2021.","title":"Microsoft Insider Risk and Communication Compliance Customer Feature Survey"},{"location":"surveys/#mip-dlp-22h1-customer-feature-surveys","text":"We are excited to announce that the MIP & DLP 22H1 customer feature surveys are now open and available! These surveys captures the top asks we captured from our customers via the various engagements, discussions and feedback channels. The surveys are available at: Microsoft Information Protection: https://aka.ms/MIPC/MIP22H1-FeatureSurvey Data Loss Prevention: https://aka.ms/MIPC/DLP22H1-FeatureSurvey Surveys will be available until November 2nd, 2021. If you want to influence the platform with features and capabilities that you want, need and like, this is the time to make it happen and share your feedback.","title":"MIP &amp; DLP 22H1 Customer feature surveys"},{"location":"webinars/","text":"Microsoft Purview Webinars \u2693\ufe0e The Compliance CxE team regularly hosts webinars to present what's changing and new within the Compliance solutions. Every webinar is always recorded and published here under Past Webinars along with the PowerPoint Decks and Q&A. Upcoming Webinars \u2693\ufe0e Webinar Topic Date & Time Registration Link MIP : Protecting your sensitive assets in a hybrid environment using Microsoft Compliance products US/EMEA March 8, 2022 16:00 GMT / 8:00 PST Register Past Webinars \u2693\ufe0e Microsoft Purview eDiscovery and Audit \u2693\ufe0e Date Topic Recording Resources December 1, 2021 How to use the Advanced eDiscovery with Microsoft Teams Video Deck November 17, 2021 How to use the Microsoft Graph API for Advanced eDiscovery to automate and customize your eDiscovery workflows Video Deck November 10, 2021 What's New in Advanced eDiscovery Video Deck April 7, 2021 What's New with Advanced eDiscovery Spring 2021 YouTube Deck/FAQ Oct 19, 2020 New Announcements and Updates Deck/FAQ May 14, 2020 eDiscovery for Teams Deck/FAQ Apr. 7, 2020 Advanced Audit Deck/FAQ Microsoft Purview Compliance Manager \u2693\ufe0e Date Topic Recording Resources November 29, 2021 What's New with Compliance Manager Video Coming soon August 24, 2021 Compliance Manager Updates Video Deck / FAQ April 20, 2021 What's New from Ignite regarding Compliance Manager YouTube Deck/FAQ Oct 01, 2020 Compliance Manager Overview Deck/FAQ Apr. 15, 2020 Compliance score how-to Deck/FAQ Microsoft Purview Insider Risk Management and Communication Compliance \u2693\ufe0e Date Topic Recording Resources December 7, 2021 What\u2019s new with Insider Risk and Communication Compliance Video Deck / FAQ June 15, 2021 Reducing Code of Conduct and Regulatory Compliance Violation Risks Video Deck / FAQ March 24, 2021 What's New from Ignite regarding Insider Risk Management YouTube Deck/FAQ Oct 29, 2020 New Announcements and Updates Deck/FAQ Mar. 10, 2020 Insider Risk Management & Communications Compliance Deck/FAQ Microsoft Purview Data Lifecycle Management and Records Management \u2693\ufe0e Date Topic Recording Resources January 20, 2021 Building Advanced Queries for SharePoint Sites with Adaptive Policy Scopes Video Deck November 11, 2021 Building Advanced Queries for Users and Groups with Adaptive Policy Scopes Video Deck September 21, 2021 Deep Dive on Adaptive Scopes Video Deck - FAQ May 19, 2021 What's New with Information Governance: Announcing multi-stage disposition and adaptive scopes Video FAQ / Deck Oct 26, 2020 New Announcements and Updates Deck/FAQ May 26, 2020 Records Management Deck/FAQ Microsoft Purview Information Protection \u2693\ufe0e Date Topic Recording Resources December 14, 2021 Be a Privacy Hero: Start your organization's M365 Privacy journey today before the end of this webinar! (Trial available to E1/E3/E5) Video Deck November 15, 2021 What\u2019s new with Microsoft Information Protection + Data Loss Prevention Video Coming Soon September 28, 2021 New features to help secure external collaboration using Microsoft Information Protection Video Deck - FAQ July 13, 2021 Advanced Classification and Auto Labeling Video Deck - FAQ July 7, 2021 Leverage M365 sensitivity labels to improve your Power BI deployment compliance and protect sensitive business data Video Deck - FAQ May 4, 2021 What's New from Ignite regarding Microsoft Information Protection YouTube Deck/FAQ Feb 19, 2021 Office Channels Deck/FAQ Feb 10, 2021 Extending MIP with high-value third-party solutions Deck/FAQ Oct 13, 2020 New Announcements and Updates Deck/FAQ Sep 30, 2020 Protection for on-premises data Video Deck Jul 14, 2020 Feature Improvements for Sensitivity Labels for Containers Deck/FAQ Jun. 2, 2020 Power BI and MIP Integration Video Deck May 28, 2020 Moving to unified labeling Deck/FAQ Apr. 22, 2020 Exact Data Match (EDM) classification Deck/FAQ Mar. 17, 2020 Trainable classifiers Deck/FAQ Mar. 5, 2020 Using Sensitivity labels with Microsoft Teams, O365 Groups and SharePoint Online sites Deck/FAQ Feb. 11, 2020 Know your data Deck/FAQ Jan. 22, 2020 Introduction to SharePoint & OneDrive Auto-labeling N/A Jan. 15, 2020 Moving to unified labeling YouTube Deck/FAQ Microsoft Purview Data Loss Prevention \u2693\ufe0e Date Topic Recording Resources February 9, 2022 Endpoint DLP Updates Coming Soon Coming Soon November 15, 2021 What\u2019s new with Microsoft Information Protection + Data Loss Prevention Video Coming Soon November 9, 2021 Migration of Exchange Transport Rules (EAC-DLP) to Unified DLP (DLP-ExO) Using Wizard Video Deck - FAQ March 17, 2021 Unified DLP YouTube Deck/FAQ Jan 26, 2021 Remote Workers DLP YouTube Deck/FAQ Nov 04, 2020 On-Premises DLP Deck/FAQ Sep 9, 2020 Microsoft Endpoint DLP Deck/FAQ Other \u2693\ufe0e Date Topic Recording Resources Apr. 27, 2020 Working remotely during challenging times Deck/FAQ","title":"Webinars"},{"location":"webinars/#microsoft-purview-webinars","text":"The Compliance CxE team regularly hosts webinars to present what's changing and new within the Compliance solutions. Every webinar is always recorded and published here under Past Webinars along with the PowerPoint Decks and Q&A.","title":"Microsoft Purview Webinars"},{"location":"webinars/#upcoming-webinars","text":"Webinar Topic Date & Time Registration Link MIP : Protecting your sensitive assets in a hybrid environment using Microsoft Compliance products US/EMEA March 8, 2022 16:00 GMT / 8:00 PST Register","title":"Upcoming Webinars"},{"location":"webinars/#past-webinars","text":"","title":"Past Webinars"},{"location":"webinars/#microsoft-purview-ediscovery-and-audit","text":"Date Topic Recording Resources December 1, 2021 How to use the Advanced eDiscovery with Microsoft Teams Video Deck November 17, 2021 How to use the Microsoft Graph API for Advanced eDiscovery to automate and customize your eDiscovery workflows Video Deck November 10, 2021 What's New in Advanced eDiscovery Video Deck April 7, 2021 What's New with Advanced eDiscovery Spring 2021 YouTube Deck/FAQ Oct 19, 2020 New Announcements and Updates Deck/FAQ May 14, 2020 eDiscovery for Teams Deck/FAQ Apr. 7, 2020 Advanced Audit Deck/FAQ","title":"Microsoft Purview eDiscovery and Audit"},{"location":"webinars/#microsoft-purview-compliance-manager","text":"Date Topic Recording Resources November 29, 2021 What's New with Compliance Manager Video Coming soon August 24, 2021 Compliance Manager Updates Video Deck / FAQ April 20, 2021 What's New from Ignite regarding Compliance Manager YouTube Deck/FAQ Oct 01, 2020 Compliance Manager Overview Deck/FAQ Apr. 15, 2020 Compliance score how-to Deck/FAQ","title":"Microsoft Purview Compliance Manager"},{"location":"webinars/#microsoft-purview-insider-risk-management-and-communication-compliance","text":"Date Topic Recording Resources December 7, 2021 What\u2019s new with Insider Risk and Communication Compliance Video Deck / FAQ June 15, 2021 Reducing Code of Conduct and Regulatory Compliance Violation Risks Video Deck / FAQ March 24, 2021 What's New from Ignite regarding Insider Risk Management YouTube Deck/FAQ Oct 29, 2020 New Announcements and Updates Deck/FAQ Mar. 10, 2020 Insider Risk Management & Communications Compliance Deck/FAQ","title":"Microsoft Purview Insider Risk Management and Communication Compliance"},{"location":"webinars/#microsoft-purview-data-lifecycle-management-and-records-management","text":"Date Topic Recording Resources January 20, 2021 Building Advanced Queries for SharePoint Sites with Adaptive Policy Scopes Video Deck November 11, 2021 Building Advanced Queries for Users and Groups with Adaptive Policy Scopes Video Deck September 21, 2021 Deep Dive on Adaptive Scopes Video Deck - FAQ May 19, 2021 What's New with Information Governance: Announcing multi-stage disposition and adaptive scopes Video FAQ / Deck Oct 26, 2020 New Announcements and Updates Deck/FAQ May 26, 2020 Records Management Deck/FAQ","title":"Microsoft Purview Data Lifecycle Management and Records Management"},{"location":"webinars/#microsoft-purview-information-protection","text":"Date Topic Recording Resources December 14, 2021 Be a Privacy Hero: Start your organization's M365 Privacy journey today before the end of this webinar! (Trial available to E1/E3/E5) Video Deck November 15, 2021 What\u2019s new with Microsoft Information Protection + Data Loss Prevention Video Coming Soon September 28, 2021 New features to help secure external collaboration using Microsoft Information Protection Video Deck - FAQ July 13, 2021 Advanced Classification and Auto Labeling Video Deck - FAQ July 7, 2021 Leverage M365 sensitivity labels to improve your Power BI deployment compliance and protect sensitive business data Video Deck - FAQ May 4, 2021 What's New from Ignite regarding Microsoft Information Protection YouTube Deck/FAQ Feb 19, 2021 Office Channels Deck/FAQ Feb 10, 2021 Extending MIP with high-value third-party solutions Deck/FAQ Oct 13, 2020 New Announcements and Updates Deck/FAQ Sep 30, 2020 Protection for on-premises data Video Deck Jul 14, 2020 Feature Improvements for Sensitivity Labels for Containers Deck/FAQ Jun. 2, 2020 Power BI and MIP Integration Video Deck May 28, 2020 Moving to unified labeling Deck/FAQ Apr. 22, 2020 Exact Data Match (EDM) classification Deck/FAQ Mar. 17, 2020 Trainable classifiers Deck/FAQ Mar. 5, 2020 Using Sensitivity labels with Microsoft Teams, O365 Groups and SharePoint Online sites Deck/FAQ Feb. 11, 2020 Know your data Deck/FAQ Jan. 22, 2020 Introduction to SharePoint & OneDrive Auto-labeling N/A Jan. 15, 2020 Moving to unified labeling YouTube Deck/FAQ","title":"Microsoft Purview Information Protection"},{"location":"webinars/#microsoft-purview-data-loss-prevention","text":"Date Topic Recording Resources February 9, 2022 Endpoint DLP Updates Coming Soon Coming Soon November 15, 2021 What\u2019s new with Microsoft Information Protection + Data Loss Prevention Video Coming Soon November 9, 2021 Migration of Exchange Transport Rules (EAC-DLP) to Unified DLP (DLP-ExO) Using Wizard Video Deck - FAQ March 17, 2021 Unified DLP YouTube Deck/FAQ Jan 26, 2021 Remote Workers DLP YouTube Deck/FAQ Nov 04, 2020 On-Premises DLP Deck/FAQ Sep 9, 2020 Microsoft Endpoint DLP Deck/FAQ","title":"Microsoft Purview Data Loss Prevention"},{"location":"webinars/#other","text":"Date Topic Recording Resources Apr. 27, 2020 Working remotely during challenging times Deck/FAQ","title":"Other"},{"location":"dag/aed-audit/","text":"Last updated: 05/11/2021 How can Advanced eDiscovery and Advanced Audit support your organization in responding to legal, regulatory, and compliance obligations? It starts with discovering the data that is relevant without the need to export this data out of Microsoft 365. The ability to natively search for data in Teams, Yammer, SharePoint Online, OneDrive for Business, Exchange Online leveraging conversations reconstruction, along with support other file types using 3rd party connectors, enhances your collection prowess. Advanced eDiscovery allows you to manage the workflows in solution reducing the amount of data intelligently through the use of ML mapping unique and share data resources of custodians, and reporting or using analytics prior to data collection before your review. Advanced Audit supports your organizations requirements in assessing the scope of compromise during a data breach or to give you an efficient way to go back to historical data without holding large volumes of data. Using forensic investigations and responding to legal requests leverages the audit logs to define the scope of a data breach and determine the length of an investigation. Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while providing workflows that respond to needs of investigations in an efficient, repeatable, and defensible manner. Advanced eDiscovery \u2693\ufe0e The Advanced eDiscovery solution provides customers with the ability to identify, preserve, collect, process, analyze, review and product content that's responsive to your organization's internal and external investigations. Discovering and managing data is challenging. To help solve these challenges, we provide customers with tools that enable them to do more in-place eDiscovery in Microsoft 365, thereby reducing risks associated with either creating multiple copies or exporting content outside of your security and compliance boundaries. Using Advanced eDiscovery, you can reduce the content in-place and only export matter relevant content. Best Practices \u2693\ufe0e To help frame the Advanced eDiscovery solution, it is important to note that our capabilities align with the eDiscovery Reference Model (EDRM) workflow as shown in figure 1. Figure 1: Microsoft eDiscovery solutions aligned with eDiscovery Reference Model (EDRM) Within Advanced eDiscovery, we have enhanced identification, preservation, and collection from core eDiscovery with things like custodian management and advanced indexing. On top of this, to further cull and reduce data intelligently, in Advanced eDiscovery, provides capabilities to process, review and analyze your data so that what you export is minimized. See figure 2 below for a suggested linear workflow. Workflows \u2693\ufe0e Figure 2: Linear Advanced eDiscovery Workflow In the suggested workflows below you have the ability to hit the ground running in implementing Advanced eDiscovery in your tenant. Basic Workflow \u2693\ufe0e Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Create a search on identified source locations Add your results to a Review Set Further reduce content in your review set using the Analytics to find near duplicates and thread messages Export out of AeD Advanced Workflow \u2693\ufe0e Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Remediate any processing errors Create and send legal hold notifications to custodians Create and run a search on identified source locations Add your results to a review set. Select the options to include modern attachments as well as contextual conversation review. Further reduce using Analyze to group together near duplicates and email threads, and identify content that is potentially privileged . Review the content within your review set for responsiveness using tags. Annotate and Redact documents Export out only case relevant content Next Steps Workflow \u2693\ufe0e Set up attorney-client privilege Custodian Audit Activity Themes Case Management \u2693\ufe0e When navigating to the compliance center, you will see an overview of all cases in Advanced eDiscovery. Think of a case as the container for your legal matter. The case will include all searches, holds, hold notifications, reviews, and exports. Note that the name of your case cannot be changed later, careful thought should be used in creating a naming convention that allows all in your organization to follow and understand. If connecting to a matter management tool, please ensure that you use the same naming convention. When creating a new case, you have the opportunity to adjust your analytics settings, enable OCR, adjust your settings for Themes, configure Ignore text, and add any additional members to the case. As mentioned below in considerations, the similarity threshold is set to 65% by default. This means that when running the analytics job, the application will group together items that are within 65% similar to another document. You can enhance it if you need. The Themes functionality analyzes documents with text in a review set to parse out common clusters or themes that appear across all the documents in the review set. Consider selecting Adjust Maximum Number Of Themes Dynamically to ensure that you can still take advantage of the feature even if there are not enough documents to create the desired number of themes. There are situations where certain text will diminish the quality of analytics, such as lengthy disclaimers that get added to email messages regardless of the content of the email. If you know of text that should be ignored, you can exclude it from analytics by specifying the text string and the analytics functionality (Near-duplicates, Email threading, Themes, and Relevance) that the text should be excluded for. Using regular expressions (RegEx) as ignored text is also supported. OCR processing will be run on image files when sources are added to a case during the advanced indexing job. This means that text in image files that matches the search criteria will be returned in a collection search. Source Location Management \u2693\ufe0e A user is so much more than their mailbox and their OneDrive site. They are able to collaborate in Teams, Yammer and SharePoint. They use third party tools like Bloomberg, Facebook and more. When using Advanced eDiscovery, you can associate other data locations to a custodian beyond their mailbox and OneDrive site alone. Once your legal team has identified a custodian, you can use the Data Sources tab in Advanced eDiscovery to manage the following: User mailbox User OneDrive site Any Teams that they are currently a member of Any Yammer networks (in native mode) SharePoint sites a custodian may have accessed or contributed to Custodians and source locations can be added on-by-one in the user interface using the picker or they can be added in bulk using the Import Custodian feature. If your legal team has given you a list of custodians, consider using the custodian template to import your custodial locations. For tips on how to populate the .csv, please follow our guidance found here . The Data Sources tab within an Advanced eDiscovery case contains a list of all custodians that have been added to the case. After you add custodians to a case, details about each custodian are automatically collected from Azure Active Directory and are viewable in Advanced eDiscovery. You may have additional data locations located within Microsoft 365 that do not need to be associated with a custodian. These locations are typically group mailboxes or SharePoint sites. You can still add these non-custodial data sources to your case in order to take advantage of the advanced indexing, search, preservation, analytics and review. Not all documents that you need to analyze in Advanced eDiscovery are located within Microsoft 365. You can also upload items that are not located in Microsoft 365 later in the workflow directly into a review set. This would be content like on-premises exchange data or local files. Keep in mind that custodians must be added to the case before you can upload and associate non-Microsoft 365 data to them. Non-Microsoft 365 data must be a file type that is supported by Advanced eDiscovery. For more information, see Supported file types in Advanced eDiscovery . Processing \u2693\ufe0e Once a source location has been added to a case, any content that is partially indexed will be processed. Content can be partially indexed for a number of reasons including the existence of images, unsupported file types or when indexing file size limits are encountered. All items (including the content and metadata) are re-indexed so that all data in the review set is fully searchable during the review of the case data. Re-indexing the data results in thorough and fast searches when you search the data in the review set during the case investigation. After the indexing job is complete, you can see a report of the effectiveness of the job. The graph will give you the number of items that were added to the hybrid index where Advanced eDiscovery stores the reprocessed content. You will also have the opportunity to remediate any errors including decryption of content that was encrypted using third party encryption tools. Preservation \u2693\ufe0e Using the Advanced eDiscovery hold capabilities, you can place a hold on custodial data including their collaborative data sources. When you place content locations on hold, content is held until you release the custodian, remove a specific data location, or delete the hold policy entirely. Custodian hold policies are managed when adding locations as a source in your case. When adding a custodial data source, you will have the opportunity to decide whether you would like the locations placed on hold. As mentioned in the Helpful Resources section below, Channel conversations that are part of a Microsoft Teams channel are stored in the mailbox that is associated with the Team. Similarly, files that team members share in a channel are stored on the team's SharePoint site. Therefore, you have to place the Microsoft Team mailbox and SharePoint site on hold to retain conversations and files in a channel. Conversations that are part of the Chat list in Microsoft Teams are stored in the mailbox of the users who participate in the chat. Files that a user shares in Chat conversations are stored in the OneDrive for Business site of the user who shares the file. Therefore, you have to place the individual user mailboxes and OneDrive for Business sites on hold to retain conversations and files in the Chat list. If you the need to place a Microsoft 365 Group or Microsoft Team on hold for a specific custodian, consider mapping the group site and group mailbox to the custodian. If the Microsoft 365 Group or Microsoft Team is not attributable to a single custodian, consider adding the source to a non-custodial hold. Hold Notifications \u2693\ufe0e Once a custodian is added to a case in Advanced eDiscovery, your legal team can create and customize their legal hold notification workflow. The custodian communications tool lets legal teams configure the following notices and workflows: Issuance notice: A legal hold notice is issued (or initiated) by a notification from the legal department to custodians who may have relevant information about the case matter. This notice instructs the custodians to preserve any information that may be needed for discovery. Re-Issuance notice: During a case, custodians may be required to preserve additional content (or less content) than was previously requested. For this scenario, you can update the existing hold notice and re-issue it to custodians. Release notice: Once a matter is resolved and the custodian is no longer subject to a preservation requirement, the custodian can be released from the case. Additionally, you can notify the custodian that they are no longer required to preserve content and provide instructions about how to resume their normal work activity with regard to their data. Reminders and escalations: In some instances, just issuing a notice is not enough to satisfy legal discovery requirements. With each notification, legal teams can schedule a set of reminder and escalation workflows to automatically follow up with unresponsive custodians. Reminders: After a legal hold notice has been issued or re-issued to a set of custodians, an organization can set up reminders to alert unresponsive custodians. Escalations: In some cases, if a custodian remains unresponsive even after a set of reminders over a period of time, the legal team can set up an escalation workflow to notify unresponsive custodians and their manager. After you've defined the contents of the hold notice, you can set up the workflows around sending and managing the notification process . Notifications are email messages that are sent to notify and follow up with custodians. Every custodian added to the communication will receive the same notification. To set up and send a hold notice, you must include Issuance, Re-Issuance, and Release notifications. Collection \u2693\ufe0e Using Searches in Advanced eDiscovery, you can collect case data from your Microsoft 365 data source locations. This includes the source content that was previously processed in the above step or any additional content source locations. When creating a search, you will define the source location as well as your query. Consider reducing the amount of data you collect by using the available query conditions . Once your search is complete, you will need to add the results to a review set. This job copies the data from its source location to a static Azure Blob storage container so that you can review the content from within your data boundaries. Upon initiating this job, you will need to name your review set and decide which additional settings are required for this specific review: Include All Document Versions From SharePoint: This setting will ingest all versions of the item from SharePoint or OneDrive. Only select this if there is a specific requirement to review all versions of a specific item. Contextual conversation review : Teams chats and conversations are stored as individual messages in the associated user or group mailbox. When selecting the option to include contextual conversation review, the Advanced eDiscovery solution will thread the messages together into a conversation format to provide full context. Enable Retrieval For Modern Attachments: With modern attachments, you can check a box to auto collect all cloud attachments to your users Teams, Yammer and Exchange conversations. This is familiar to your current process for reviewing regular attachments as families or email sets. If there are downstream processes that rely on these relationships, we ensure that we are able to preserve these relationships in the load file Analysis \u2693\ufe0e Using the analytics and machine learning capabilities in Advanced eDiscovery, you can reduce the amount of data to review. Analyze \u2693\ufe0e The first step you will take after your search results are added to your review set will be to run the analytics job . Analyze allows for the identification and grouping of exact and near-duplicate files. It also identifies and organizes emails into hierarchically structured groups of email Threads , based on the progressive inclusiveness of the emails. Sets of near duplicates (ND) documents are grouped together in an ND Set. For a document to join an ND Set, there must be at least one document in the ND Set with a level of resemblance exceeding the similarity. Themes \u2693\ufe0e Themes is a content-analytics application that identifies themes and thematic relationships across file collections. The application to identify interdependencies between themes allows users to browse associatively across the collection, navigating intuitively from theme to related theme. By generating meaningful labels for each thematic group, Themes provides an immediate snapshot of a file collection. In early case assessment and investigations, Themes enables litigators and analysts to intuitively acquire an informed and rapid overview of the data set. Keep in mind that increasing the \u201cNumber of themes\u201d can affect the ability of a theme to generalize. The higher the number of themes, the more granular they are. For example, if a set of 50 themes produces themes such as \u201cBasketball, Spurs, Clippers, Lakers\u201d, a set of 300 themes may include separate themes such as \u201cSpurs\u201d, \u201cClippers\u201d, \u201cLakers\u201d. If the user had no awareness of the theme \u201cBasketball\u201d and uses this feature for Early Case Assessment (ECA), seeing the theme \u201cBasketball\u201d could be useful. If the clustering is too granular (too many themes), the user may never see the word \u201cBasketball\u201d and may not know that Spurs and Clippers are good Basketball themes to review rather than items that go on boots and are used for hair. Attorney-Client Privilege \u2693\ufe0e When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine learning to determine the likelihood that a document contains content that is legal in nature. When setting up attorney-client privilege detection, you will need to submit a list of attorneys for your organization. The model will compare the participants of the document with the attorney list to determine if any attorneys are participants. Relevance \u2693\ufe0e The relevance module identifies and ranks files by relevance, which assists with early case assessment, document culling and review. Once the trained sample of files are reviewed and tagged by a human expert as Relevant or Not Relevant, the model will rank the relevance of all files in your case. There will be more information on the Relevance module in next version of this document. Review \u2693\ufe0e The review portion of the eDiscovery process can be the most time consuming and costly step. Using Advanced eDiscovery, you can cull the data in order to only produce the relevant data. A review set is simply a static set of documents that you can analyze, query, tag, and export. Review set \u2693\ufe0e Advanced eDiscovery allows you to further query and filter data within a review set so that you can focus on a subset of documents. You can build a query by using a combination of keywords, properties, and conditions in the Keywords condition. You can also group conditions as a block (called a condition group) to build a more complex query. For a list and description of metadata properties that you can search, see Document metadata fields in Advanced eDiscovery . Once you are ready to review the case data, Advanced eDiscovery displays content via several viewers each with different purposes. The various viewers can be used by clicking on any document within a review set. Above the content viewing pane, you will be able to view metadata for each document within your review set. The Native viewer displays the richest view of a document. It supports hundreds of file types and is meant to display the truest to native experience possible. The Text viewer provides a view of the extracted text of a file. It ignores any embedded images and formatting but is very effective if you are trying to understand the content quickly. The Annotate view provides features that allow users to apply markup on a document. When reviewing documents, you can annotate and redact documents to hide confidential information. You can preserve these markings during the export process. During review, you may want to further tag documents based on criteria like responsive vs non-responsive. Tags are customizable to meet the needs of your review process. You can also use the annotation tool to annotate and redact content in documents. Content with redactions and annotations will be exported in PDF form. Custodian Audit Activity \u2693\ufe0e Need to find if a user viewed a specific document or purged an item from their mailbox? Advanced eDiscovery is now integrated with the existing audit log search tool in the M365 compliance center. Using this embedded experience, you can use the Advanced eDiscovery custodian management tool to facilitate your investigation by easily accessing and searching the activity for custodians within your case. Audit has access to a broad and rich set of information around user activities across 30 Microsoft services send user and admin activity to Audit. This can help answer questions during a legal investigation like: What SharePoint files did this custodian view or share? Did the custodian read this message? While we cover Advanced Audit in more depth below, there is great benefit in understanding how a custodian interacts with data in the context of a legal investigation. Production \u2693\ufe0e Once your review is complete, you can export content from your Advanced eDiscovery case. You will need to consider where the data goes after exported out of Microsoft 365 to determine the export options that fit your needs. Currently, you can export files out in two formats: Loose files and PSTs (email is added to PSTs when possible) - Files are exported in a format that resembles the original directory structure seen by users in their native applications. For more information, see the Loose files and PST export structure section. Native files within the condensed directory structure - Files are exported in their native format along with a load file containing mapping and metadata for each file. Consider whether you require conversations to be exported as Conversation Files. These messages will be threaded together and exported in PDF format. Once export is complete, you will need to use AzCopy to download the results. While if you implement all the recommendations above you are set for a successful deployment of AeD, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on steps that allow you to learn the end-to-end process with minimal disruptions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e The M365 compliance center provides two out-of-box role groups, eDiscovery Manager and eDiscovery Administrator, that include the required roles to complete eDiscovery tasks. An eDiscovery Manager will only have access to cases that they create or are assigned to. An eDiscovery Administrator can access all eDiscovery cases. You can create and define custom role groups in order to manage a subset of eDiscovery tasks. Assign eDiscovery permissions in the Security & Compliance Center - Microsoft 365 Compliance Consider using Compliance Boundaries to control the content locations (such as mailboxes, OneDrive locations or SharePoint sites) that your eDiscovery Manager is able to search. They can also be used to control access to eDiscovery cases used to manage the legal, HR or other investigations within your organization. The need for compliance boundaries is often necessary for multi-national corporations that have to respect geographical boarders and regulations and for governments, which are often divided into different agencies. The analytics similarity threshold is set to 65% by default. When creating your case, discuss the expected similarity threshold with your legal team to ensure the value is correct. This setting cannot be changed once Analytics are run on the case data. When applying a hold to a custodian, an in-place hold is placed on their mailbox. This differs from a Litigation Hold in that it can be query based. There is also no limit to the number of in-place holds that can be applied to a mailbox or site. The holds within Advanced eDiscovery should be used for legal preservation and not for overall governance in your organization . If you require additional governance policies, please use the Microsoft 365 Retention policies. When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine leaning to determine the likelihood that the content is legal in nature. It will also compare the participants of the document against the pre-submitted list of attorneys for your organization. To leverage the export option to produce the redacted PDFs instead of files in their native format, you must first use the action to convert all redacted files to PDF within your review set When uploading non-Microsoft 365 data into your review set, all custodians that you will be associating the data with still require the appropriate license. Microsoft 365 eDiscovery tools now incorporate decryption of encrypted files that are attached to email messages and sent in Exchange Online. Additionally, encrypted documents stored in SharePoint Online and OneDrive for Business are decrypted in Advanced eDiscovery. You can review and query the decrypted file in the review set. For more information, see Decryption in Microsoft 365 eDiscovery tools . Advanced eDiscovery supports double-byte character set languages (these include Simplified Chinese, Traditional Chinese, Japanese, and Korean, which are collectively known as CJK languages) when querying the data within a review set, tagging the data within a review set and when analyzing the data. At the current time, we do not support OCR of CJK characters from image files. Query based holds and the relevance module do not support CJK languages. The goal of the APIs is to reduce some of the risk with repetitive processes that can be error prone. At the current time, four out of the eight eDiscovery APIs are available in Beta. The APIs are set up to deliver on 2 scenarios. Automating common processes and task by taking jobs that are repeatable and creating an application. Consider things like kicking off an email once the review set creation job is complete or automatically searching all Teams that a custodian is currently a member of. Integration with existing systems, whether they be custom or a common industry tool. Helpful Resources \u2693\ufe0e Understanding how and what types of content is stored in a mailbox is key to a successful eDiscovery posture. An exchange mailbox stores so much more than just email messages. Your calendar items, tasks, Skype messages, Teams messages, Voicemails, Forms, Sway, To-Do, Yammer conversations and so much more are stored in either user or group mailboxes. An understanding of where content is stored in SharePoint based on the type of hold can be key during an investigation. Consider reading this blog that covers the lifecycle of an item in SharePoint. Teams 1:1 and 1:N chats are stored in the user mailbox. Teams conversations are stored in the Team Group mailbox. Items that are uploaded to chats are stored in the user OneDrive location. Items that are uploaded to conversations are stored in the Team SharePoint site. eDiscovery of messages and files in private channels works differently than in standard channels. To learn more, see eDiscovery of private channels . Teams chat content that is associated with a guest user is stored in a cloud-based storage location and can be searched for using eDiscovery. This includes searching for content in 1:1 and 1:N chat conversations in which a guest user is a participant with other users in your organization. You can also search for private channel messages in which a guest user is a participant and search for content in guest:guest chat conversations where the only participants are guest users. You can add inactive mailboxes, Microsoft Teams, Yammer Groups, Office 365 Groups, and distribution groups to the list of mailboxes to search. Dynamic distribution groups are not supported. If you add Microsoft Teams, Yammer Groups, or Office 365 Groups, the group or team mailbox is searched; the mailboxes of the group members are not searched. Cloud links or modern attachments are items attached to messages in either Teams or Exchange. Cloud links differ from legacy attachments in that a copy of the item is not stored along with the message. Cloud attachments are a pointer to the location (in either OneDrive or SharePoint) that the item is stored. Contextual conversation review enables you to review a single message that matches your query within the context of the conversation. At the current time, 4/8 of the eDiscovery APIs in Microsoft Graph are available in beta. The APIs can be used to automate or customize your workflow to reduce redundant tasks. For instance, you can create a PowerBI Dashboard that will give you real time case statistics or custodian reports. One compliance story with Microsoft 365 Advanced eDiscovery \u2693\ufe0e Insider risk management is a compliance solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and act on malicious and inadvertent activities in your organization. Insider risk policies allow you to define the types of risks to identify and detect in your organization, including acting on cases and escalating cases to Microsoft Advanced eDiscovery if needed. The content identified for escalation from IRM is automatically added to a review set in a case within Advanced eDiscovery. For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Communication compliance is an insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. The content identified for escalation from CC is automatically added to a review set within a case in Advanced eDiscovery. For CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your eDiscovery strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and Microsoft Information Protection (specifically sensitivity labels). If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. This allows eDiscovery managers to view the content of encrypted email attachments and site documents when previewing search results, and review them after they have been added to a review set in Advanced eDiscovery. Advanced Audit \u2693\ufe0e Advanced Audit aims to expand on the capabilities of the Microsoft 365 unified auditing capabilities by offering additional features. The retention of audit logs for Exchange, SharePoint, and Azure Active Directory activities for each licensed user can be extended from 90 days to 1 year, by default. You can now create custom audit log retention policies for the services mentioned, allowing you to target records generated in the other services that are not covered by the default retention policy for periods up to 1 year. There are additional Exchange Online and SharePoint Online events captured which are crucial for conducting forensic and compliance investigations. These new events help investigators understand if mail items were accessed through the mail sync and mail bind operation. This is extremely helpful to organizations with regulatory obligations that require breach notifications because now they have the ability to scope mail items that may have been compromised to reduce fines and penalties. Customers will receive additional bandwidth when accessing audit data through the Office 365 Management Activity API based on the new tenant-level bandwidth quota. When you are conducting an investigation, it is not just about the content. You may need to investigate an individual user\u2019s behavior and activity more deeply. These activities can be reviewed through the unified audit log. Best Practices \u2693\ufe0e While the advanced audit features are going to be key for many of our customers to address their compliance requirements, it is also important for all customers to start with a basic understanding of the unified audit log. Many organizations consider the information contained in the audit logs to be sensitive in nature. As such, formulate a plan and execute how you will manage access to view those logs. That access is granted through the View-Only Audit Logs or Audit Logs roles in Exchange Online. These roles are managed in the Exchange admin center (EAC) and not in the M365 compliance center. Before you start, please check that the audit log is enabled by navigating to the Audit solution in the M365 compliance center. If you see a banner stating that auditing needs to be turned on, see link . Make sure your staff knows how to search and export the audit logs using the UI. There are reference links in the appendix to point them to resources that can help guide them. Follow the steps in the Helpful Resources section below to enable mailbox audit logging for all users. Once you have the basics down, it is time to plan how you will implement the advanced audit features. If your organization has decided not to license all your users with one of the E5 licenses that enable the advanced features, you will need to identify the population that warrants the additional oversight and longer-term retention of their activities to assign them E5 licenses. Decide if the default advanced retention policy works for you. By default, the audit records for Exchange, SharePoint, and Azure Active Directory are kept for one year. You may require that those records be kept for a shorter or longer period of time. Decide on the length of your audit retention for the activities in the other services not covered by the default policy mentioned above. Create a retention policy to retain your data for the appropriate amount of time. You can use an audit log retention policy to modify the default retention policy, or keep other data for longer than 90 days, up to 1 year. Additionally, an Audit add-on license for 10-year retention can allow records to be stored for long-term retention. Conduct forensic and compliance investigations by providing access to crucial events such as when mail items were accessed, when mail items were replied to and forwarded, and when and what a user searched for in Exchange Online and SharePoint Online. If you have a need to export data or integrate with a Security Information Event Management (SIEM) solution, you will need staff that are familiar with APIs or work with a partner. If you have a need to automate some of your audit search activities or need to perform very large searches, we recommend having resources that are comfortable using PowerShell cmdlets in Exchange Online and M365 compliance center. Considerations \u2693\ufe0e To manage audit log retention policies, you will need to be assigned the Organization Configuration role in the M365 compliance center. You can have a maximum of 50 audit log retention policies in your organization. To benefit from user-level Advanced Audit capabilities, a user needs to be assigned an E5 license. The higher bandwidth access to the API does not change the standard documented latencies for activities. When performing a search in the Audit solution that spans a timeframe longer than 90 days, you will receive a warning indicating that only users that have the proper licensing applied will return activities beyond the 90 day window. While not directly related to Advanced Audit, it is important to note that audit logging for Power BI isn't enabled by default. To search for Power BI activities in the audit log, you must enable auditing in the Power BI admin portal. Helpful Resources \u2693\ufe0e A list of the additional events included with Advanced Audit as well as an explanation of each can be found here . For details on creating and managing your audit retention policies, please use this link . For more information on the high-bandwidth access to the Office 365 Management Activity API you can read about it here . For instructions on how to enable Power BI logs see the \"Audit logs\" section in Power BI admin portal . This article includes a table indicating the time it takes for corresponding records to be returned for the different services in Office 365. Follow the steps outlined here to enable mailbox audit logging for user without an E5 licenses. Appendix - Additional Resources \u2693\ufe0e This section contains links to the information regarding license requirements and provides additional links to additional information related to Advanced eDiscovery. Advanced eDiscovery License Requirements \u2693\ufe0e Before you get started with Advanced eDiscovery, you should confirm your Microsoft 365 subscriptions and any add-ons. To access and use Advanced eDiscovery, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions) Advanced Audit License Requirements \u2693\ufe0e Before you get started with Advanced Audit, you should confirm your Microsoft 365 subscription and any add-ons. To access and use Advanced Audit, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"eDiscovery and Audit"},{"location":"dag/aed-audit/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while providing workflows that respond to needs of investigations in an efficient, repeatable, and defensible manner.","title":"Your Deployment Plan"},{"location":"dag/aed-audit/#advanced-ediscovery","text":"The Advanced eDiscovery solution provides customers with the ability to identify, preserve, collect, process, analyze, review and product content that's responsive to your organization's internal and external investigations. Discovering and managing data is challenging. To help solve these challenges, we provide customers with tools that enable them to do more in-place eDiscovery in Microsoft 365, thereby reducing risks associated with either creating multiple copies or exporting content outside of your security and compliance boundaries. Using Advanced eDiscovery, you can reduce the content in-place and only export matter relevant content.","title":"Advanced eDiscovery"},{"location":"dag/aed-audit/#best-practices","text":"To help frame the Advanced eDiscovery solution, it is important to note that our capabilities align with the eDiscovery Reference Model (EDRM) workflow as shown in figure 1. Figure 1: Microsoft eDiscovery solutions aligned with eDiscovery Reference Model (EDRM) Within Advanced eDiscovery, we have enhanced identification, preservation, and collection from core eDiscovery with things like custodian management and advanced indexing. On top of this, to further cull and reduce data intelligently, in Advanced eDiscovery, provides capabilities to process, review and analyze your data so that what you export is minimized. See figure 2 below for a suggested linear workflow.","title":"Best Practices"},{"location":"dag/aed-audit/#workflows","text":"Figure 2: Linear Advanced eDiscovery Workflow In the suggested workflows below you have the ability to hit the ground running in implementing Advanced eDiscovery in your tenant.","title":"Workflows"},{"location":"dag/aed-audit/#basic-workflow","text":"Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Create a search on identified source locations Add your results to a Review Set Further reduce content in your review set using the Analytics to find near duplicates and thread messages Export out of AeD","title":"Basic Workflow"},{"location":"dag/aed-audit/#advanced-workflow","text":"Create a case in Advanced eDiscovery. Identify your custodial and non-custodial source locations and add to case for advanced indexing. Remediate any processing errors Create and send legal hold notifications to custodians Create and run a search on identified source locations Add your results to a review set. Select the options to include modern attachments as well as contextual conversation review. Further reduce using Analyze to group together near duplicates and email threads, and identify content that is potentially privileged . Review the content within your review set for responsiveness using tags. Annotate and Redact documents Export out only case relevant content","title":"Advanced Workflow"},{"location":"dag/aed-audit/#next-steps-workflow","text":"Set up attorney-client privilege Custodian Audit Activity Themes","title":"Next Steps Workflow"},{"location":"dag/aed-audit/#case-management","text":"When navigating to the compliance center, you will see an overview of all cases in Advanced eDiscovery. Think of a case as the container for your legal matter. The case will include all searches, holds, hold notifications, reviews, and exports. Note that the name of your case cannot be changed later, careful thought should be used in creating a naming convention that allows all in your organization to follow and understand. If connecting to a matter management tool, please ensure that you use the same naming convention. When creating a new case, you have the opportunity to adjust your analytics settings, enable OCR, adjust your settings for Themes, configure Ignore text, and add any additional members to the case. As mentioned below in considerations, the similarity threshold is set to 65% by default. This means that when running the analytics job, the application will group together items that are within 65% similar to another document. You can enhance it if you need. The Themes functionality analyzes documents with text in a review set to parse out common clusters or themes that appear across all the documents in the review set. Consider selecting Adjust Maximum Number Of Themes Dynamically to ensure that you can still take advantage of the feature even if there are not enough documents to create the desired number of themes. There are situations where certain text will diminish the quality of analytics, such as lengthy disclaimers that get added to email messages regardless of the content of the email. If you know of text that should be ignored, you can exclude it from analytics by specifying the text string and the analytics functionality (Near-duplicates, Email threading, Themes, and Relevance) that the text should be excluded for. Using regular expressions (RegEx) as ignored text is also supported. OCR processing will be run on image files when sources are added to a case during the advanced indexing job. This means that text in image files that matches the search criteria will be returned in a collection search.","title":"Case Management"},{"location":"dag/aed-audit/#source-location-management","text":"A user is so much more than their mailbox and their OneDrive site. They are able to collaborate in Teams, Yammer and SharePoint. They use third party tools like Bloomberg, Facebook and more. When using Advanced eDiscovery, you can associate other data locations to a custodian beyond their mailbox and OneDrive site alone. Once your legal team has identified a custodian, you can use the Data Sources tab in Advanced eDiscovery to manage the following: User mailbox User OneDrive site Any Teams that they are currently a member of Any Yammer networks (in native mode) SharePoint sites a custodian may have accessed or contributed to Custodians and source locations can be added on-by-one in the user interface using the picker or they can be added in bulk using the Import Custodian feature. If your legal team has given you a list of custodians, consider using the custodian template to import your custodial locations. For tips on how to populate the .csv, please follow our guidance found here . The Data Sources tab within an Advanced eDiscovery case contains a list of all custodians that have been added to the case. After you add custodians to a case, details about each custodian are automatically collected from Azure Active Directory and are viewable in Advanced eDiscovery. You may have additional data locations located within Microsoft 365 that do not need to be associated with a custodian. These locations are typically group mailboxes or SharePoint sites. You can still add these non-custodial data sources to your case in order to take advantage of the advanced indexing, search, preservation, analytics and review. Not all documents that you need to analyze in Advanced eDiscovery are located within Microsoft 365. You can also upload items that are not located in Microsoft 365 later in the workflow directly into a review set. This would be content like on-premises exchange data or local files. Keep in mind that custodians must be added to the case before you can upload and associate non-Microsoft 365 data to them. Non-Microsoft 365 data must be a file type that is supported by Advanced eDiscovery. For more information, see Supported file types in Advanced eDiscovery .","title":"Source Location Management"},{"location":"dag/aed-audit/#processing","text":"Once a source location has been added to a case, any content that is partially indexed will be processed. Content can be partially indexed for a number of reasons including the existence of images, unsupported file types or when indexing file size limits are encountered. All items (including the content and metadata) are re-indexed so that all data in the review set is fully searchable during the review of the case data. Re-indexing the data results in thorough and fast searches when you search the data in the review set during the case investigation. After the indexing job is complete, you can see a report of the effectiveness of the job. The graph will give you the number of items that were added to the hybrid index where Advanced eDiscovery stores the reprocessed content. You will also have the opportunity to remediate any errors including decryption of content that was encrypted using third party encryption tools.","title":"Processing"},{"location":"dag/aed-audit/#preservation","text":"Using the Advanced eDiscovery hold capabilities, you can place a hold on custodial data including their collaborative data sources. When you place content locations on hold, content is held until you release the custodian, remove a specific data location, or delete the hold policy entirely. Custodian hold policies are managed when adding locations as a source in your case. When adding a custodial data source, you will have the opportunity to decide whether you would like the locations placed on hold. As mentioned in the Helpful Resources section below, Channel conversations that are part of a Microsoft Teams channel are stored in the mailbox that is associated with the Team. Similarly, files that team members share in a channel are stored on the team's SharePoint site. Therefore, you have to place the Microsoft Team mailbox and SharePoint site on hold to retain conversations and files in a channel. Conversations that are part of the Chat list in Microsoft Teams are stored in the mailbox of the users who participate in the chat. Files that a user shares in Chat conversations are stored in the OneDrive for Business site of the user who shares the file. Therefore, you have to place the individual user mailboxes and OneDrive for Business sites on hold to retain conversations and files in the Chat list. If you the need to place a Microsoft 365 Group or Microsoft Team on hold for a specific custodian, consider mapping the group site and group mailbox to the custodian. If the Microsoft 365 Group or Microsoft Team is not attributable to a single custodian, consider adding the source to a non-custodial hold.","title":"Preservation"},{"location":"dag/aed-audit/#hold-notifications","text":"Once a custodian is added to a case in Advanced eDiscovery, your legal team can create and customize their legal hold notification workflow. The custodian communications tool lets legal teams configure the following notices and workflows: Issuance notice: A legal hold notice is issued (or initiated) by a notification from the legal department to custodians who may have relevant information about the case matter. This notice instructs the custodians to preserve any information that may be needed for discovery. Re-Issuance notice: During a case, custodians may be required to preserve additional content (or less content) than was previously requested. For this scenario, you can update the existing hold notice and re-issue it to custodians. Release notice: Once a matter is resolved and the custodian is no longer subject to a preservation requirement, the custodian can be released from the case. Additionally, you can notify the custodian that they are no longer required to preserve content and provide instructions about how to resume their normal work activity with regard to their data. Reminders and escalations: In some instances, just issuing a notice is not enough to satisfy legal discovery requirements. With each notification, legal teams can schedule a set of reminder and escalation workflows to automatically follow up with unresponsive custodians. Reminders: After a legal hold notice has been issued or re-issued to a set of custodians, an organization can set up reminders to alert unresponsive custodians. Escalations: In some cases, if a custodian remains unresponsive even after a set of reminders over a period of time, the legal team can set up an escalation workflow to notify unresponsive custodians and their manager. After you've defined the contents of the hold notice, you can set up the workflows around sending and managing the notification process . Notifications are email messages that are sent to notify and follow up with custodians. Every custodian added to the communication will receive the same notification. To set up and send a hold notice, you must include Issuance, Re-Issuance, and Release notifications.","title":"Hold Notifications"},{"location":"dag/aed-audit/#collection","text":"Using Searches in Advanced eDiscovery, you can collect case data from your Microsoft 365 data source locations. This includes the source content that was previously processed in the above step or any additional content source locations. When creating a search, you will define the source location as well as your query. Consider reducing the amount of data you collect by using the available query conditions . Once your search is complete, you will need to add the results to a review set. This job copies the data from its source location to a static Azure Blob storage container so that you can review the content from within your data boundaries. Upon initiating this job, you will need to name your review set and decide which additional settings are required for this specific review: Include All Document Versions From SharePoint: This setting will ingest all versions of the item from SharePoint or OneDrive. Only select this if there is a specific requirement to review all versions of a specific item. Contextual conversation review : Teams chats and conversations are stored as individual messages in the associated user or group mailbox. When selecting the option to include contextual conversation review, the Advanced eDiscovery solution will thread the messages together into a conversation format to provide full context. Enable Retrieval For Modern Attachments: With modern attachments, you can check a box to auto collect all cloud attachments to your users Teams, Yammer and Exchange conversations. This is familiar to your current process for reviewing regular attachments as families or email sets. If there are downstream processes that rely on these relationships, we ensure that we are able to preserve these relationships in the load file","title":"Collection"},{"location":"dag/aed-audit/#analysis","text":"Using the analytics and machine learning capabilities in Advanced eDiscovery, you can reduce the amount of data to review.","title":"Analysis"},{"location":"dag/aed-audit/#analyze","text":"The first step you will take after your search results are added to your review set will be to run the analytics job . Analyze allows for the identification and grouping of exact and near-duplicate files. It also identifies and organizes emails into hierarchically structured groups of email Threads , based on the progressive inclusiveness of the emails. Sets of near duplicates (ND) documents are grouped together in an ND Set. For a document to join an ND Set, there must be at least one document in the ND Set with a level of resemblance exceeding the similarity.","title":"Analyze"},{"location":"dag/aed-audit/#themes","text":"Themes is a content-analytics application that identifies themes and thematic relationships across file collections. The application to identify interdependencies between themes allows users to browse associatively across the collection, navigating intuitively from theme to related theme. By generating meaningful labels for each thematic group, Themes provides an immediate snapshot of a file collection. In early case assessment and investigations, Themes enables litigators and analysts to intuitively acquire an informed and rapid overview of the data set. Keep in mind that increasing the \u201cNumber of themes\u201d can affect the ability of a theme to generalize. The higher the number of themes, the more granular they are. For example, if a set of 50 themes produces themes such as \u201cBasketball, Spurs, Clippers, Lakers\u201d, a set of 300 themes may include separate themes such as \u201cSpurs\u201d, \u201cClippers\u201d, \u201cLakers\u201d. If the user had no awareness of the theme \u201cBasketball\u201d and uses this feature for Early Case Assessment (ECA), seeing the theme \u201cBasketball\u201d could be useful. If the clustering is too granular (too many themes), the user may never see the word \u201cBasketball\u201d and may not know that Spurs and Clippers are good Basketball themes to review rather than items that go on boots and are used for hair.","title":"Themes"},{"location":"dag/aed-audit/#attorney-client-privilege","text":"When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine learning to determine the likelihood that a document contains content that is legal in nature. When setting up attorney-client privilege detection, you will need to submit a list of attorneys for your organization. The model will compare the participants of the document with the attorney list to determine if any attorneys are participants.","title":"Attorney-Client Privilege"},{"location":"dag/aed-audit/#relevance","text":"The relevance module identifies and ranks files by relevance, which assists with early case assessment, document culling and review. Once the trained sample of files are reviewed and tagged by a human expert as Relevant or Not Relevant, the model will rank the relevance of all files in your case. There will be more information on the Relevance module in next version of this document.","title":"Relevance"},{"location":"dag/aed-audit/#review","text":"The review portion of the eDiscovery process can be the most time consuming and costly step. Using Advanced eDiscovery, you can cull the data in order to only produce the relevant data. A review set is simply a static set of documents that you can analyze, query, tag, and export.","title":"Review"},{"location":"dag/aed-audit/#review-set","text":"Advanced eDiscovery allows you to further query and filter data within a review set so that you can focus on a subset of documents. You can build a query by using a combination of keywords, properties, and conditions in the Keywords condition. You can also group conditions as a block (called a condition group) to build a more complex query. For a list and description of metadata properties that you can search, see Document metadata fields in Advanced eDiscovery . Once you are ready to review the case data, Advanced eDiscovery displays content via several viewers each with different purposes. The various viewers can be used by clicking on any document within a review set. Above the content viewing pane, you will be able to view metadata for each document within your review set. The Native viewer displays the richest view of a document. It supports hundreds of file types and is meant to display the truest to native experience possible. The Text viewer provides a view of the extracted text of a file. It ignores any embedded images and formatting but is very effective if you are trying to understand the content quickly. The Annotate view provides features that allow users to apply markup on a document. When reviewing documents, you can annotate and redact documents to hide confidential information. You can preserve these markings during the export process. During review, you may want to further tag documents based on criteria like responsive vs non-responsive. Tags are customizable to meet the needs of your review process. You can also use the annotation tool to annotate and redact content in documents. Content with redactions and annotations will be exported in PDF form.","title":"Review set"},{"location":"dag/aed-audit/#custodian-audit-activity","text":"Need to find if a user viewed a specific document or purged an item from their mailbox? Advanced eDiscovery is now integrated with the existing audit log search tool in the M365 compliance center. Using this embedded experience, you can use the Advanced eDiscovery custodian management tool to facilitate your investigation by easily accessing and searching the activity for custodians within your case. Audit has access to a broad and rich set of information around user activities across 30 Microsoft services send user and admin activity to Audit. This can help answer questions during a legal investigation like: What SharePoint files did this custodian view or share? Did the custodian read this message? While we cover Advanced Audit in more depth below, there is great benefit in understanding how a custodian interacts with data in the context of a legal investigation.","title":"Custodian Audit Activity"},{"location":"dag/aed-audit/#production","text":"Once your review is complete, you can export content from your Advanced eDiscovery case. You will need to consider where the data goes after exported out of Microsoft 365 to determine the export options that fit your needs. Currently, you can export files out in two formats: Loose files and PSTs (email is added to PSTs when possible) - Files are exported in a format that resembles the original directory structure seen by users in their native applications. For more information, see the Loose files and PST export structure section. Native files within the condensed directory structure - Files are exported in their native format along with a load file containing mapping and metadata for each file. Consider whether you require conversations to be exported as Conversation Files. These messages will be threaded together and exported in PDF format. Once export is complete, you will need to use AzCopy to download the results. While if you implement all the recommendations above you are set for a successful deployment of AeD, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on steps that allow you to learn the end-to-end process with minimal disruptions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production"},{"location":"dag/aed-audit/#considerations","text":"The M365 compliance center provides two out-of-box role groups, eDiscovery Manager and eDiscovery Administrator, that include the required roles to complete eDiscovery tasks. An eDiscovery Manager will only have access to cases that they create or are assigned to. An eDiscovery Administrator can access all eDiscovery cases. You can create and define custom role groups in order to manage a subset of eDiscovery tasks. Assign eDiscovery permissions in the Security & Compliance Center - Microsoft 365 Compliance Consider using Compliance Boundaries to control the content locations (such as mailboxes, OneDrive locations or SharePoint sites) that your eDiscovery Manager is able to search. They can also be used to control access to eDiscovery cases used to manage the legal, HR or other investigations within your organization. The need for compliance boundaries is often necessary for multi-national corporations that have to respect geographical boarders and regulations and for governments, which are often divided into different agencies. The analytics similarity threshold is set to 65% by default. When creating your case, discuss the expected similarity threshold with your legal team to ensure the value is correct. This setting cannot be changed once Analytics are run on the case data. When applying a hold to a custodian, an in-place hold is placed on their mailbox. This differs from a Litigation Hold in that it can be query based. There is also no limit to the number of in-place holds that can be applied to a mailbox or site. The holds within Advanced eDiscovery should be used for legal preservation and not for overall governance in your organization . If you require additional governance policies, please use the Microsoft 365 Retention policies. When attorney-client privilege detection is enabled, all documents in a review set will be processed by the attorney-client privilege detection model when you analyze the data in the review set. The model uses machine leaning to determine the likelihood that the content is legal in nature. It will also compare the participants of the document against the pre-submitted list of attorneys for your organization. To leverage the export option to produce the redacted PDFs instead of files in their native format, you must first use the action to convert all redacted files to PDF within your review set When uploading non-Microsoft 365 data into your review set, all custodians that you will be associating the data with still require the appropriate license. Microsoft 365 eDiscovery tools now incorporate decryption of encrypted files that are attached to email messages and sent in Exchange Online. Additionally, encrypted documents stored in SharePoint Online and OneDrive for Business are decrypted in Advanced eDiscovery. You can review and query the decrypted file in the review set. For more information, see Decryption in Microsoft 365 eDiscovery tools . Advanced eDiscovery supports double-byte character set languages (these include Simplified Chinese, Traditional Chinese, Japanese, and Korean, which are collectively known as CJK languages) when querying the data within a review set, tagging the data within a review set and when analyzing the data. At the current time, we do not support OCR of CJK characters from image files. Query based holds and the relevance module do not support CJK languages. The goal of the APIs is to reduce some of the risk with repetitive processes that can be error prone. At the current time, four out of the eight eDiscovery APIs are available in Beta. The APIs are set up to deliver on 2 scenarios. Automating common processes and task by taking jobs that are repeatable and creating an application. Consider things like kicking off an email once the review set creation job is complete or automatically searching all Teams that a custodian is currently a member of. Integration with existing systems, whether they be custom or a common industry tool.","title":"Considerations"},{"location":"dag/aed-audit/#helpful-resources","text":"Understanding how and what types of content is stored in a mailbox is key to a successful eDiscovery posture. An exchange mailbox stores so much more than just email messages. Your calendar items, tasks, Skype messages, Teams messages, Voicemails, Forms, Sway, To-Do, Yammer conversations and so much more are stored in either user or group mailboxes. An understanding of where content is stored in SharePoint based on the type of hold can be key during an investigation. Consider reading this blog that covers the lifecycle of an item in SharePoint. Teams 1:1 and 1:N chats are stored in the user mailbox. Teams conversations are stored in the Team Group mailbox. Items that are uploaded to chats are stored in the user OneDrive location. Items that are uploaded to conversations are stored in the Team SharePoint site. eDiscovery of messages and files in private channels works differently than in standard channels. To learn more, see eDiscovery of private channels . Teams chat content that is associated with a guest user is stored in a cloud-based storage location and can be searched for using eDiscovery. This includes searching for content in 1:1 and 1:N chat conversations in which a guest user is a participant with other users in your organization. You can also search for private channel messages in which a guest user is a participant and search for content in guest:guest chat conversations where the only participants are guest users. You can add inactive mailboxes, Microsoft Teams, Yammer Groups, Office 365 Groups, and distribution groups to the list of mailboxes to search. Dynamic distribution groups are not supported. If you add Microsoft Teams, Yammer Groups, or Office 365 Groups, the group or team mailbox is searched; the mailboxes of the group members are not searched. Cloud links or modern attachments are items attached to messages in either Teams or Exchange. Cloud links differ from legacy attachments in that a copy of the item is not stored along with the message. Cloud attachments are a pointer to the location (in either OneDrive or SharePoint) that the item is stored. Contextual conversation review enables you to review a single message that matches your query within the context of the conversation. At the current time, 4/8 of the eDiscovery APIs in Microsoft Graph are available in beta. The APIs can be used to automate or customize your workflow to reduce redundant tasks. For instance, you can create a PowerBI Dashboard that will give you real time case statistics or custodian reports.","title":"Helpful Resources"},{"location":"dag/aed-audit/#one-compliance-story-with-microsoft-365-advanced-ediscovery","text":"Insider risk management is a compliance solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and act on malicious and inadvertent activities in your organization. Insider risk policies allow you to define the types of risks to identify and detect in your organization, including acting on cases and escalating cases to Microsoft Advanced eDiscovery if needed. The content identified for escalation from IRM is automatically added to a review set in a case within Advanced eDiscovery. For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Communication compliance is an insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. The content identified for escalation from CC is automatically added to a review set within a case in Advanced eDiscovery. For CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to be a member of the eDiscovery Manager role group in the Security and Compliance center. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your eDiscovery strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and Microsoft Information Protection (specifically sensitivity labels). If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. This allows eDiscovery managers to view the content of encrypted email attachments and site documents when previewing search results, and review them after they have been added to a review set in Advanced eDiscovery.","title":"One compliance story with Microsoft 365 Advanced eDiscovery"},{"location":"dag/aed-audit/#advanced-audit","text":"Advanced Audit aims to expand on the capabilities of the Microsoft 365 unified auditing capabilities by offering additional features. The retention of audit logs for Exchange, SharePoint, and Azure Active Directory activities for each licensed user can be extended from 90 days to 1 year, by default. You can now create custom audit log retention policies for the services mentioned, allowing you to target records generated in the other services that are not covered by the default retention policy for periods up to 1 year. There are additional Exchange Online and SharePoint Online events captured which are crucial for conducting forensic and compliance investigations. These new events help investigators understand if mail items were accessed through the mail sync and mail bind operation. This is extremely helpful to organizations with regulatory obligations that require breach notifications because now they have the ability to scope mail items that may have been compromised to reduce fines and penalties. Customers will receive additional bandwidth when accessing audit data through the Office 365 Management Activity API based on the new tenant-level bandwidth quota. When you are conducting an investigation, it is not just about the content. You may need to investigate an individual user\u2019s behavior and activity more deeply. These activities can be reviewed through the unified audit log.","title":"Advanced Audit"},{"location":"dag/aed-audit/#best-practices_1","text":"While the advanced audit features are going to be key for many of our customers to address their compliance requirements, it is also important for all customers to start with a basic understanding of the unified audit log. Many organizations consider the information contained in the audit logs to be sensitive in nature. As such, formulate a plan and execute how you will manage access to view those logs. That access is granted through the View-Only Audit Logs or Audit Logs roles in Exchange Online. These roles are managed in the Exchange admin center (EAC) and not in the M365 compliance center. Before you start, please check that the audit log is enabled by navigating to the Audit solution in the M365 compliance center. If you see a banner stating that auditing needs to be turned on, see link . Make sure your staff knows how to search and export the audit logs using the UI. There are reference links in the appendix to point them to resources that can help guide them. Follow the steps in the Helpful Resources section below to enable mailbox audit logging for all users. Once you have the basics down, it is time to plan how you will implement the advanced audit features. If your organization has decided not to license all your users with one of the E5 licenses that enable the advanced features, you will need to identify the population that warrants the additional oversight and longer-term retention of their activities to assign them E5 licenses. Decide if the default advanced retention policy works for you. By default, the audit records for Exchange, SharePoint, and Azure Active Directory are kept for one year. You may require that those records be kept for a shorter or longer period of time. Decide on the length of your audit retention for the activities in the other services not covered by the default policy mentioned above. Create a retention policy to retain your data for the appropriate amount of time. You can use an audit log retention policy to modify the default retention policy, or keep other data for longer than 90 days, up to 1 year. Additionally, an Audit add-on license for 10-year retention can allow records to be stored for long-term retention. Conduct forensic and compliance investigations by providing access to crucial events such as when mail items were accessed, when mail items were replied to and forwarded, and when and what a user searched for in Exchange Online and SharePoint Online. If you have a need to export data or integrate with a Security Information Event Management (SIEM) solution, you will need staff that are familiar with APIs or work with a partner. If you have a need to automate some of your audit search activities or need to perform very large searches, we recommend having resources that are comfortable using PowerShell cmdlets in Exchange Online and M365 compliance center.","title":"Best Practices"},{"location":"dag/aed-audit/#considerations_1","text":"To manage audit log retention policies, you will need to be assigned the Organization Configuration role in the M365 compliance center. You can have a maximum of 50 audit log retention policies in your organization. To benefit from user-level Advanced Audit capabilities, a user needs to be assigned an E5 license. The higher bandwidth access to the API does not change the standard documented latencies for activities. When performing a search in the Audit solution that spans a timeframe longer than 90 days, you will receive a warning indicating that only users that have the proper licensing applied will return activities beyond the 90 day window. While not directly related to Advanced Audit, it is important to note that audit logging for Power BI isn't enabled by default. To search for Power BI activities in the audit log, you must enable auditing in the Power BI admin portal.","title":"Considerations"},{"location":"dag/aed-audit/#helpful-resources_1","text":"A list of the additional events included with Advanced Audit as well as an explanation of each can be found here . For details on creating and managing your audit retention policies, please use this link . For more information on the high-bandwidth access to the Office 365 Management Activity API you can read about it here . For instructions on how to enable Power BI logs see the \"Audit logs\" section in Power BI admin portal . This article includes a table indicating the time it takes for corresponding records to be returned for the different services in Office 365. Follow the steps outlined here to enable mailbox audit logging for user without an E5 licenses.","title":"Helpful Resources"},{"location":"dag/aed-audit/#appendix-additional-resources","text":"This section contains links to the information regarding license requirements and provides additional links to additional information related to Advanced eDiscovery.","title":"Appendix - Additional Resources"},{"location":"dag/aed-audit/#advanced-ediscovery-license-requirements","text":"Before you get started with Advanced eDiscovery, you should confirm your Microsoft 365 subscriptions and any add-ons. To access and use Advanced eDiscovery, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Advanced eDiscovery License Requirements"},{"location":"dag/aed-audit/#advanced-audit-license-requirements","text":"Before you get started with Advanced Audit, you should confirm your Microsoft 365 subscription and any add-ons. To access and use Advanced Audit, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 eDiscovery & Audit add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Discovery & Audit add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Discovery & Audit add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Advanced Audit License Requirements"},{"location":"dag/cm/","text":"Last updated: 06/21/2021 We can all agree that protecting customer's data is of critical importance, but with an average of 222 updates per day from 1000 regulatory bodies, the task of safeguarding your organization\u2019s compliance posture in such a rapidly evolving landscape can feel insurmountable at times. Compliance Manager is an end to end information compliance management solution in the Microsoft 365 compliance center that helps you understand your organization's compliance posture. Compliance Manager uses the inventory of data protection risk allowing you to manage the complexities of controls, adhering to regulations and certifications along with reporting needed for auditors. Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle. Compliance Manager Overview \u2693\ufe0e Compliance Manager allows your organization to simplify compliance and start reducing risk by completing pre-built assessments targeting industries, standards, regulations or leveraging a custom assessment created by you\u202fand your organization. In addition to the assessments, this tool provides step-by-step guidance on open actions and displays\u202fa score for measuring\u202fyour\u202fcompliance posture. The tool focuses on identifying gaps and controls\u202fthat need to be addressed and\u202fprovides suggestions on how to improve these\u202fitems,\u202fdrawing elements from\u202fstandard Information Security and Compliance frameworks like GDPR, NIST etc.\u202f Compliance Manager provides:\u202f Built in assessments for common industry and regional standards and regulations, or custom assessments to meet your unique compliance needs. Flagged issues with detailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. \u202f Automated testing and validation to help you stay compliant with various regulations. \u202f An overall risk-based compliance score to help understand your compliance posture by measuring your progress in completing improvement actions. Frequent updates ensures that if a regulation or control changes, you are made aware of it to help you to continue to stay compliant. Best Practices \u2693\ufe0e Below is a list of best practices we have gathered to help you take advantage of what Compliance Manager brings to your organization. Updates to an action propagate tenant wide. Our recommendation is to accept the updates so that you get the latest guidance and improvement actions to meet a requirement. \u202f\u202f Use correctly formatted Excel files when working with Compliance Manager to prevent errors with the import process. Export any existing assessment before deleting it in case you need to add it back through the import process. If you reassign an action that has a pending update, the direct link to the action in the reassignment email will break if the update is accepted after reassignment. You can fix this by reassigning the action to the user after the update is accepted.\u202f Prior to Deployment Plan \u2693\ufe0e Understanding your current organizational landscape \u2693\ufe0e Before starting your compliance journey, it is important to understand what current regulations your organization needs to comply with so that you know what regulations you need to track and monitor your progress against. Compliance Manager offers over 330 regulation assessments that you can use to help your organization stay compliant. Most organizations are using some method to track these regulations, either with other tools or Excel spreadsheets. It is important to understand how your organization is managing this today, as Compliance Manager can standardize and centralize all of these into one location. If you are currently using other methods to track regulations, you can even bring your own controls into Compliance Manager. One of the primary values of using Compliance Manager is that we can provide actions items, assess, update, test and stay current with changes happening to the regulations. The pre-built assessments are being updated as regulations or technology changes, so that Microsoft can provide you the most up to date data in a central location. When thinking about compliance for your organization it is important to make sure you have the right stakeholders or technical decision makers (TDM) involved in your Compliance Manager journey. For most organizations this is not just the IT department, although they might have a role to play in the implementation of some of the action items. Below is a list of key personas we see using and being involved in Compliance Manager discussions. Key personas \u2693\ufe0e Compliance Manager personas at\u202fhigh\u202flevel can be put into one of these categories:\u202f Assessors: \u2693\ufe0e Assessors are compliance, security, privacy, and risk officers (Officers). They ensure that their organizational assets are compliant with applicable regulations, data is protected as per standards, and compliance / technology risks are managed as per their organizational policies. Assessors can also be auditors who maintain independent audit of assessment work performed by officers listed above. How assessors\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f They are most likely personas who create assessments as per their organizational compliance management needs. They will work with admins to ensure that assessment actions are implemented, tested, and completed. \u202f They will review assessment progress, compliance metrics, and risks with executive personas. \u202f Admins: \u2693\ufe0e Admins are security, compliance, process, and IT administrators. These personas have the ability to make configurational changes to implement actions / controls. They are typically the people who need to pull evidence to showcase that actions / controls have been implemented and performing effectively. How admins\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f Admins will review actions assigned to them, implement these actions using S-C-M (security, compliance and management) solutions, and collect evidence for closing actions assigned to them. They may create IT risk / data protection related assessment on their own, as per their org maturity around IT / Technology risk management. They may participate in executive reviews. Executives: \u2693\ufe0e Chief Compliance, IT, Information Security, Privacy, Finance, HR and Risk officers. Depending upon how compliance, security, privacy, and risk management functions are structured within an organization, these executives have overall responsibility for compliance and risk management. How executives\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f Set overall compliance and risk management policies and objectives for their organization. This will influence type and number of assessments created within Compliance Manager. They may review Compliance Manager dashboard on ongoing basis to track compliance management progress, blockers, and risks. Permissions \u2693\ufe0e Compliance Manager is enabled in your tenant but only individuals with the right access can view scores, add assessments and work with the actions. Users will need at least the Compliance Manager reader role or Azure AD global reader role to access Compliance Manager. The Microsoft 365 global administrator for your organization will likely be the first user to access Compliance Manager. We recommend the global admin sign in and set user permissions as outlined below when visiting Compliance Manager for the first time. Additional details about permissions and role type are available here: https://docs.microsoft.com/en-us/microsoft-365/compliance/compliance-manager-setup?view=o365-worldwide#where-to-set-permissions Deployment Plan \u2693\ufe0e This document offers guidance and steps that customer compliance executive and IT teams can utilize to adopt the service. This document is divided into three sections offering an overview approach for service adoption using General Data Protection Regulation (GDPR) as the assessment of choice. The sections are designed to represent the recommended deployment approach crawl-walk-run for Microsoft 365 Compliance Manager. Note GDPR assessment has been chosen as the assessment of choice to demonstrate the walk approach; however, you can choose any other regulatory assessment that is relevant to your organization. Crawl:\u202fCore\u202fService \u2693\ufe0e This is where you should start your compliance journey. This will set the foundation for using Compliance Manager to help your organization become and stay compliant. This will include tasks like: Becoming familiar with Compliance Manager, settings, and how to enable this service for your organization. Going through key service features and capabilities. Understanding your data protection baseline score.\u202f\u202f Setup automated testing and scoring Using the user history to audit who has what actions and reassign actions if needed. How to enable this service for your organization \u2693\ufe0e Compliance Manager comes enabled by default for your organization. An initial score will be provided based on the Microsoft 365 data protection baseline. This baseline is a set of controls that includes key regulations and standards for data protection and general data governance. A great way to get started is to use this score to understand where your organization baseline is and ways to improve this by reviewing and taking actions outlined in your improvement actions. Also consider the concepts and process you use to correct and work with data baseline actions is the same process and concepts that apply to any other prebuilt or custom assessment you add to Compliance Manager. Configure permissions and adding users to role groups \u2693\ufe0e Compliance Manager uses a role-based access control (RBAC) permission model. Only users who are assigned a role may access Compliance Manager, and the actions allowed by each user are restricted by\u202f role type . Permissions can be configured in two (2) places: Azure Active Directory which allows you the ability to use PIMs (privileged identity management). There are four roles that can be used with Azure AD. The benefit of using PIMs is that you can enable just in time access. The drawback to this method is that currently, the available permission is not as granular as the permission in the security and compliance center. Security and Compliance center (Compliance Center). There are five roles that can be used to set permissions for Compliance Manager. You have the ability to be a bit more granular here when assigning access via roles, but this is standing access to the users added to the roles. Customers in US Government Community (GCC) High and Department of Defense (DoD) environments can only set user permissions and roles for Compliance Manager in Azure AD. See below for Azure AD instructions and role type definitions. Role Types \u2693\ufe0e Users will need at least the Compliance Manager reader role, or Azure AD global reader role to access Compliance Manager.\u202f ROLE TYPES User can: Compliance Manager role Azure AD role Read but not edit data Compliance Manager Reader Azure AD Global reader, Security reader Edit data Compliance Manager Contribution Compliance Administrator Edit test results Compliance Manager Assessor Compliance Administrator Manage assessments, and template and tenant data Compliance Manager Administration Compliance Administrator, Compliance Data Administrator, Security Administrator Assign users Global Administrator Global Administrator Add users to Compliance Manager administrator role group \u2693\ufe0e A role group is a set of roles that allows users to perform their job across the Security & Compliance Center. For example, the Compliance Administrator role group includes (among other roles) the roles for Case Management, Content Search, and Organization Configuration (plus others), because someone who is a compliance admin will need the permissions for those tasks to perform their job. You can add role groups and achieve separation of roles and responsibilities by simply adding individual users as members to the role group . The role groups you want to create help to apply principle of least privilege by delegating tasks and functions that you'll need to assign users to. Create a custom role group for auditors \u2693\ufe0e You can directly add users to a specific role group or create custom role groups to expand the portfolio of the team responsible for managing compliance in an organization. One of these custom groups you should consider is the compliance auditors . These are users who can review the compliance posture of your organization with read only access to Compliance Manager by using the Compliance Manager Reader role . Key service elements, features and capabilities \u2693\ufe0e Compliance Manager uses several data elements to help you manage your compliance activities. As you use Compliance Manager to assign, test, and monitor compliance activities, it\u2019s helpful to have a basic understanding of the key elements: controls, assessments, templates, and improvement actions. Controls : A control is a requirement of a regulation, standard, or policy. It defines how you assess and manage system configuration, organizational process, and people responsible for meeting a specific requirement of a regulation, standard, or policy. Compliance Manager tracks the following types of controls: Microsoft managed controls : controls for Microsoft cloud services, which Microsoft is responsible for implementing. Your controls : sometimes referred to as customer managed controls, these are controls implemented and managed by your organization. Shared Controls : sometimes referred to as customer managed controls, these are controls implemented and managed by your organization. Compliance Manager automatically scans through your Microsoft 365 environment and detects your system settings, continuously and automatically updating your technical action status. Microsoft Secure Score is the underlying engine that performs the monitoring. Your action status is updated on your dashboard every 24 hours. Once you follow a recommendation to implement a control, you\u2019ll typically see the control status updated the next day. Assessments :\u202fAn assessment is a grouping of controls from a specific regulation, standard, or policy. Completing the actions within an assessment help you meet the requirements of a standard, regulation, or law. Assessments have several components:\u202f In-scope services :\u202fthe specific set of Microsoft services applicable to the assessment Controls :\u202fMicrosoft managed, your controls and shared controls \u202f Assessment score :\u202fshows your progress in achieving total possible points from actions within the assessment that are managed by your organization and by Microsoft. Templates :\u202fTemplates to help you quickly create assessments. You can modify templates to create an assessment optimized for your needs. You can also build a custom assessment by creating a template with your own controls and actions (We will cover this in the Run section). Included and Premium Templates:\u202f Included templates \u202fare available for use as part of your organization\u2019s licensing agreement. Premium templates \u202fmust be purchased to create assessments from them. Once purchased, you may create as many assessments from a template as needed. You can also try these templates out before you buy them. (In the Appendix section we\u2019ll cover how to sign up for a trial.) Active and inactive templates\u202f\u202f A template is considered active once you create an assessment from that template. Your assessment page has a counter near the top which displays the number of templates in use vs the number of assessments you are licensed to use. For example, if you see 2/5 that means you have 2 active templates out of 5 that you are licensed for. If you see 5/2 this means you have exceeded the limits you are licensed for, and you need to remove or purchase more license. A template is considered inactive if your organization isn\u2019t using it for an assessment. Improvement actions : Improvement actions help centralize your compliance activities. Each improvement action provides recommended guidance that\u2019s intended to help you align with data protection regulations and standards. Improvement actions can be assigned to users in your organization to perform implementation and testing work. You can also store documentation, notes, and record status updates within the improvement action. Groups : When creating assessments, you\u2019ll assign them to a group. You can configure groups in whatever way is most logical for your organization. For example, you may group assessments by audit year, region, solution, teams within your organization, or some other way. Once you create groups, you can filter your Compliance Manager dashboard to view your score by one or more groups. It is important to note that the same action, if tenant scoped, can be in multiple groups. If this is the case, the action can be updated in one of the groups and it would be replicated to all groups that contain that action. For example, take MFA being required on Admin accounts. If this is enabled, it would be enabled for all groups that contain this action. Understanding your data protection baseline score \u2693\ufe0e Compliance Manager by default creates a data protection baseline that can be used to implement data protection controls and measure the control effectiveness against this baseline. It helps to establish and maintain technical, procedural, and people control for your organization. Data protection baseline is built by leveraging leading standards for data protection, information security, and privacy. Using guidance provided by data protection baseline, you can protect your data against insider, and malicious threats. By implementing actions that are part of data protection baseline, you can get ahead of compliance by being better prepared for new regulations coming. Setting up a good baseline also builds a strong foundation before adding additional regulatory specific assessments. Set up automated testing \u2693\ufe0e Some improvement actions in Compliance Manager are also monitored by Microsoft Secure Score. You can set up automated testing of actions that are jointly monitored, which means that when an action is tested and updated in Secure Score, those results sync with the same actions in Compliance Manager and count toward your compliance score. Automatic testing is turned on by default for organizations new to Compliance Manager. When you first deploy Microsoft 365 or Office 365, it takes approximately seven days for Secure Score to fully collect data and factor it into your compliance score. When automated testing is turned on, the action\u2019s test date won\u2019t be updated, but its test status will update. When new assessments are created, scores automatically include Microsoft control scores and Secure Score integration. If you want to change these setting it can be done by a global administrator at any time. You can turn off automated testing for common improvement actions or turn it on for individual actions. User history \u2693\ufe0e User history helps you quickly identify which users have worked with improvement actions in Compliance Manager. The identifiable user data associated with improvement actions includes any implementation and testing work done, documents uploaded, and any notes entered. Understanding and retrieving this type of data may be necessary for your organization\u2019s own compliance needs. You can use the search button to find a user who you are looking for, which can be useful when working with many users. You might find it useful to be able to export the data to an Excel file which will contain a list of improvement actions currently assigned to a user and any evidence files uploaded by that user. This information can help you reassign open improvement actions. It is important to note that the report reflects the improvement action\u2019s status as of its creation date. It\u2019s not a historical report of all previous changes to its status or assignment. If a user leaves the organization or their role changes, you might be required to reassign improvement actions from one user to another. This is possible to do in the Compliance Manager user history section. It is important to note that when you reassign an action, the document upload history doesn't change, but the name of the user who originally uploaded the documentation no longer appears within the improvement action. Walk: Working with an assessment \u2693\ufe0e The Walk phase builds upon the components of the crawl phase and looks to add one or more regulatory assessments for your organization, such as GDPR. This would include tasks like: * How to choose a pre-built assessment * How to read and understand your score * How to read, implement, and test your improvement actions * Assigning tasks and managing controls * How to track your way to become compliant * Keeping the assessment actions updated The most important data elements for configuring Compliance Manager are Assessment Templates and Assessments. Compliance Manager provides a rich library of over 330 assessment\u202ftemplates, each of which represents a specific regulation, certification, or standard that aligns to an industrial, regional, and common data protection standard, such as GDPR or ISO 27001. These assessment templates contain all the control families and controls from the regulation or standard, and a set of actions that are mapped to these controls. These actions include both improvement actions for helping you meet the requirements of that regulation or standard, and Microsoft actions that have already been taken by Microsoft. Each action has points associated with it and these help determine your compliance score. Choose a pre-built assessment \u2693\ufe0e To get started quickly, you can pick from one of over 330 assessments already set up and available to you in Compliance Manager. There is a wide selection of templates for regulations and certifications that align to industries, regions, and common data protection standards, such as GDPR and ISO 27001. Templates contain the controls and improvement actions for helping you meet the requirements of a particular certification. For a full list of templates available check out - Microsoft Compliance Manager templates list - Microsoft 365 Compliance | Microsoft Docs. Adding a pre-built assessment allows you to immediately begin to review actions items, make the required changes, test, and complete the action item. Within a few minutes, you can add multiple regulations that are important to your organization and start tracking your progress against meeting these regulations. Assessment Types \u2693\ufe0e Assessment templates are added to Compliance Manager as new laws and regulations are enacted. Compliance Manager updates its templates when the underlying laws or regulations change. Compliance Manager classifies assessment into two (2) categories. Included templates are templates included as part of your organization's licensing agreement. Premium templates display additional templates your organization may choose to obtain on additional credits Below is the included templates for the M365 A5/E5/G5 license. Visit the Compliance Manager templates list for the most up-to-date information on assessments. Microsoft Compliance Manager templates list - Microsoft 365 Compliance | Microsoft Docs Microsoft Data Protection Baseline European Union GDPR (Microsoft 365, Office 365, Intune) ISO 27001:2013 NIST 800-53 Rev.4 NIST 800-53 Rev.5 Cybersecurity Maturity Model Certification (CMMC) Levels 1 through 5 (G5 Only) Understand groups \u2693\ufe0e Before you create or modify assessments, it\u2019s important to understand how groups work. When you create an assessment, you\u2019ll need to assign it to a group during the process. This is an important step to plan out before you create assessments. Groups are containers that you can use to organize your assessments that are logical to you. Some examples might be by year, regulation, department, or geographies. An example of this might be: Assessments 2020 FFIEC IS GDPR US 2020 FFIEC IS FISMA United States of America Privacy Act Ohio 2021 Ohio Data Protection Act 2018 EU 2020 GDPR Directive 2006/24/EC It is important to understand how improvement actions work within a group and across groups. When two different assessments in the same group share improvement actions that are managed by you, any updates you make to an action's implementation details or status will automatically synchronize to the same action in any other assessment in the group. This synchronization allows you to implement one improvement action and meet several requirements across multiple regulations. If the improvement action is a tenant action, for example require MFA, there will only be one action for all groups. So, completing this in one group will apply the same status to all groups that have this action. While working within a group you can see all the actions for that group and a breakdown of the score for the group you are working on. While you can always see the score for the tenant, it is sometimes easier to focus in on a particular group. What to know when working with groups \u2693\ufe0e There are some additional guidelines when working with groups that you should be aware of. Group names must be unique within your organization. At this time, groups cannot be deleted but they can be reused. Groups don't have security properties. All permissions are associated with assessments. Once you add an assessment to a group, the grouping can't be changed. Related assessment controls in different assessments within the same group automatically update when completed. If you add a new assessment to an existing group, common information from assessments in that group are copied to the new assessment. Groups can contain assessments for the same certification or regulation, but each group can only contain one assessment for a specific product-certification pair. For example, a group can't contain two assessments for Office 365 and NIST CSF. A group can contain multiple assessments for the same product only if the corresponding certification or regulation for each one is different. Deleting an assessment breaks the relationship between that assessment and the group. When a change is made to an improvement that appears in multiple groups, that change is reflected in all instances of that improvement action. Pre-built Assessments \u2693\ufe0e Now that you know how to configure groups, it\u2019s time to get started by picking from one of the more than 330 assessments Compliance Manager offers out of the box. You\u2019ll be asked to choose an assessment template when you start\u202fbuilding an assessment. You can also create your own custom assessment template, which we will cover in the run phase. It can be quick and easy to use the templates we have built for you which also update automatically. Below is an example of the assessments page. It lists the assessments you select to track for your organization and your compliance score denominator is determined by all your tracked assessments. Thus, the more assessments you add, the more improvement actions you see on your improvement actions page, and the higher your score denominator is. Setting up an assessment \u2693\ufe0e There are two starting points for creating an assessment from a Compliance Manager template. You can begin the process from your assessments page by selecting the Add assessment button and then working through the assessment creation wizard. You can also start from your assessment templates page by finding the template you want and selecting it from the list to arrive at its details page. On the template details page, select Create assessment. You\u2019ll then enter the wizard with your template already selected. Assignment and tracking \u2693\ufe0e Improvement actions centralize your compliance activities. Each improvement action provides detailed implementation guidance to help you align with data protection regulations and standards. It is common that the Compliance Manager administrator is not always the person preforming the actions to implement the controls. Compliance Manager allows actions to be assigned to users in your organization to perform implementation and testing work. When you assign an action to someone, they get notified that they have been assigned and if they have the right permissions, they are able to see details about the action. Emails are not currently sent if you are in GCC High or a DOD environment Implementation and testing \u2693\ufe0e The person or team who is assigned an action then uses the details of the action item to complete the work, conduct testing, upload evidence, and change the status of the action item. Once that has been completed, it is assigned to an assessor for validation. The assessor validates the work, examines the documentation, and selects the appropriate test status. If test status is set to \u201cPassed\u201d : the action is complete, and the points achieved shows the maximum points achieved. The points are then counted toward your overall compliance score. If test status is set to \u201cFailed\u201d : the action doesn't meet the requirements, and the assessor can update the notes and assign it back to the appropriate user for additional work. Keeping the assessment actions update \u2693\ufe0e One of the many values of Compliance Manager is that it is continuously updated to keep up with regulatory changes and changes in M365. When you see a pending update label next to its name on the improvement actions page and on the details page of its related assessments, you can either accept the update or defer it to a later date. You can get more details about the update before accepting it or deferring it. Updates normally occur on a quarterly cycle. An update occurs when there are changes related to scoring, automation, and/or scope. Changes may involve new guidance for improvement actions based on regulatory changes or could be because of product changes. Only the improvement actions managed by your organizations receive update notifications. We do not provide updates to the Microsoft managed actions. Accepting updates helps ensure that you have the most updated guidance on using solutions and taking appropriate improvement actions to help you meet the requirements of the certification at hand. There are times when you might want to defer an update if you\u2019re in the middle of completing an assessment that includes the improvement action. You may want to ensure you\u2019ve finished work on it before you accept the update. Accepted changes are permanent. When you accept an update to an action, you\u2019re also accepting updates to any other versions or instances of this action. Updates will propagate tenant-wide for technical actions and will propagate group-wide for non-technical actions. How to track your way to become compliant \u2693\ufe0e The Compliance Manager dashboard displays an overall compliance score. This score measures progress in completing recommended improvement actions within controls. Compliance score can help in understanding your current compliance posture. It can also help prioritize actions based on their potential to reduce risk. A score value is assigned at three (3) levels: Improvement action score: each action has a different impact on your score depending on the potential risk involved. Control score: this score is the sum of points earned by completing improvement actions within the control. This sum is applied in its entirety to your overall compliance score when the control meets both of the following conditions: Implementation Status \u202fequals\u202f Implemented \u202for\u202f Alternative Implementation , and Test Result \u202fequals\u202f Passed . Assessment score : this score is the sum of your control scores. It is calculated using action scores. Each Microsoft action and each improvement action managed by your organization is counted once, regardless of how often it is referenced in a control. The overall compliance score is calculated using action scores, where each Microsoft action is counted once, each technical action you manage is counted once, and each non-technical action you manage is counted once per group. This logic is designed to provide the most accurate accounting of how actions are implemented and tested in your organization. You may notice that this can cause your overall compliance score to differ from the average of your assessment scores. Read more below about \u202f how actions are scored . Initial score based on Microsoft 365 data protection baseline \u2693\ufe0e Compliance Manager gives you an initial score based on the Microsoft 365 data protection baseline . This baseline is a set of controls that includes key regulations and standards for data protection and general data governance. This baseline draws elements primarily from the National Institute of Standards and Technology Cybersecurity Framework ( NIST CSF ) and International Organization for Standardization ( ISO ), as well as from Federal Risk and Authorization Management Program ( FedRAMP ) and General Data Protection Regulation of the European Union ( GDPR ). Your initial score is calculated according to the default Data Protection Baseline assessment provided to all organizations. Upon your first visit, Compliance Manager is already collecting signals from your Microsoft 365 solutions. You will be able to see how your organization is performing relative to key data protection standards and regulations. You will be also able to see suggested improvement actions to take. Because every organization has specific needs, Compliance Manager relies on you to set up and manage assessments to help minimize and mitigate risk as comprehensively as possible. Continuously assesses controls \u2693\ufe0e Compliance Manager automatically scans through your Microsoft 365 environment and detects your system settings, continuously and automatically updating your technical action status. Microsoft Secure Score is the underlying engine that performs the monitoring. Your action status is updated on your dashboard every 24 hours. Once you follow a recommendation to implement a control, you\u2019ll typically see the control status updated the next day. For example, if you turn on multi-factor authentication (MFA) in the Azure AD portal, Compliance Manager detects the setting and reflects it in the control access solution details. Conversely, if you didn\u2019t turn on MFA, Compliance Manager flags that as a recommended action for you to take. Learn more about \u202f Secure Score and how it works . Action types and points \u2693\ufe0e Compliance Manager tracks two types of actions: Your improvement actions : actions that your organization manages. Microsoft actions : actions that Microsoft manages. Both types of actions have points that count toward your overall score when completed. Technical and non-technical actions \u2693\ufe0e Actions are grouped by whether they are technical or non-technical in nature. The scoring impact of each action differs by type. Technical actions \u202fare implemented by interacting with the technology of a solution (for example, changing a configuration). The points for technical actions are granted once per action, regardless of how many groups it belongs to. Non-technical actions \u202fare managed by your organization and implemented in ways other than working with the technology of a solution. There are two types of non-technical actions:\u202f documentation \u202fand\u202f operational . The points for these actions are applied to your compliance score at a group level. This means that if an action exists in multiple groups, you will receive the action's point value each time you implement it within a group. Example of how technical and non-technical actions are scored \u2693\ufe0e For example, you have a technical action worth 3 points that exists in 5 groups, and you have a non-technical action worth 3 points that exists in the same 5 groups. If you successfully implement the technical action, the total number of points you receive is 3. This is because you only need to implement the action once for your tenant. The implementation and test status for the technical action will show the same in all instances of that action, in every group it belongs to. This scoring logic is designed to provide the most accurate accounting of how actions are implemented and tested in your organization. Score Value Determination \u2693\ufe0e Actions are assigned a score value based on whether they\u2019re mandatory or discretionary, and whether they\u2019re preventative, detective, or corrective. Mandatory and discretionary actions \u2693\ufe0e Mandatory actions\u202fcan't be bypassed, either intentionally or accidentally. An example of a mandatory action is a centrally managed password policy that sets requirements for password length, complexity, and expiration. Users must follow these requirements to access the system. Discretionary actions\u202frely upon users to understand and adhere to a policy. For example, a policy requiring users to lock their computer when they leave it is a discretionary action because it relies on the user. Preventative, detective, and corrective actions \u2693\ufe0e Preventative actions\u202faddress specific risks. For example, protecting information at rest using encryption is a preventative action against attacks and breaches. Separation of duties is a preventative action to manage conflict of interest and guard against fraud. Detective actions\u202factively monitor systems to identify irregular conditions or behaviors that represent risk, or that can be used to detect intrusions or breaches. Examples include system access auditing and privileged administrative actions. Regulatory compliance audits are a type of detective action used to find process issues. Corrective actions\u202ftry to keep the adverse effects of a security incident to a minimum, take corrective action to reduce the immediate effect, and reverse the damage if possible. Privacy incident response is a corrective action to limit damage and restore systems to an operational state after a breach. Each action has an assigned value in Compliance Manager based on the risk it represents: Run: Customize and Expand Assessments \u2693\ufe0e Now that you have a strong foundation in Compliance Manager and you have worked with an out of box assessment template, we\u2019ll look at how you can build on this to create your own assessments, expand on the prebuilt assessments, or use Compliance Manager to assess 3rd party platforms or applications. This can really drive home the value of having a centrally managed location to track all your compliance management needs. We see customers using a mix of out of box assessment and adding their own custom assessments or expanding on the out of box assessments to meet their company\u2019s needs. This allows for a lot of flexibility. We know that most organizations, in addition to Microsoft software, will have presence of heterogenous software, multiple on-prem services either commercially purchased on home grown, and multiple SaaS services such as Salesforce, ServiceNow or others. For an organization, it is important to have compliance to assessments for all Microsoft & Non-Microsoft services. Let\u2019s look at how you can leverage Compliance Manager to complete 3rd party assessments or build bring-your own assessments to cover your entire organizational scope. This section will focus on how you can leverage Compliance Manager to expand and cover your entire organizational scope by taking advantage of: Extending a prebuilt assessment by adding your own controls and improvements How to create your own custom assessment Extend pre-built assessment templates \u2693\ufe0e First you might want to take what we give you with a prebuilt assessment and modify it to fit your organizational needs. You can do this by taking an out of the box assessment template and adding your own controls and improvement actions to the assessment template. This process is called \u201c extending a Microsoft template \u201d in Compliance Manager. When you extend an out of the box assessment template, it will continue to receive any updates released by Microsoft, which may happen when there are changes to the related regulation or product. The nice benefit of this is you can customize what we have given to you as a template to meet your organizational needs or expand to assess your 3rd party platforms. An example of this might be GDPR regulation that you need to take some type of action on your on-prem environment. You could use the GDPR template to monitor and track everything inside of O365 but then have additional actions to track items that need to happen with your on-prem environment. This keeps everything under the GDPR Assessment score and when looking at the actions to stay compliant it is all in one location. Let\u2019s discuss how this process works. You first need to assemble a specially formatted Excel spreadsheet to import the necessary template data. There are specific requirements for the\u202f formatted Excel files\u202fused in the extension process and some points to be aware of to prevent errors in the import process: Your spreadsheet should contain only the actions and controls you want to add to the assessment. The spreadsheet can not contain any of the controls or actions that already exist in the assessment you want to modify. Consider including \u201cextension\u201d in your template\u2019s title, for example, \u201cGDPR \u2013 [your company name] extension\u201d. This makes it easier to identify in the list on your\u202f assessment templates \u202fpage as distinct from the standard Microsoft-provided template or a custom template with a similar name. Create and maintain your own custom assessments \u2693\ufe0e If expanding an existing template does not meet your needs, or you already have an assessment template you manage in excel or another platform, you can build your own assessments from scratch. We call this creating a custom assessment and this capability is available at the A5/E5/G5 SKUS. Creating a custom assessment in Compliance Manager requires you to create your own template. To create your own template, you\u2019ll first assemble a formatted Excel spreadsheet to import the necessary template data. A sample template can be found here: https://go.microsoft.com/fwlink/?linkid=2124865 . Begin by formatting your template data into an Excel spreadsheet using\u202f these instructions . Formatting your template with Excel \u2693\ufe0e When you start with the Excel spreadsheet you will notice it contains four (4) tabs, three (3) of which are required: Template\u202f(required) ControlFamily\u202f(required) Actions\u202f(required) Dimensions\u202f(optional) Template tab (required) \u2693\ufe0e The\u202f Template \u202ftab is required. The information in this tab provides metadata about the template. There are four (4) required columns. The columns must retain the order on the Excel sheet as listed below. You can add your own column\u202fafter\u202fthe four (4) columns to provide your own dimensions. If you do this, be sure to add them to the\u202fDimensions\u202ftab using the\u202finstructions below. title : This is the title for your template which must be unique. It can't share a name with another template you have in Compliance Manager, including your own templates or an out of the box template. product : This is a required dimension. List the product associated with the template. certification : This is the regulation you're using for the template. inScopeServices : These are the services within the product that this assessment addresses (for example, if you listed Office 365 as the product, Microsoft Teams could be an in-scope service). You can list multiple services separated by two (2) semi-colons. ControlFamily tab (Required) \u2693\ufe0e The\u202f ControlFamily \u202ftab is required. The required columns in this tab, which must follow the order provided in the sample spreadsheet, are: controlName : This is the control name from the certification, standard, or regulation, which is typically some type of ID. Control names must be unique within a template. You can't have multiple controls with the same name in the spreadsheet. controlFamily : Provide a word or phrase for the controlFamily, which identifies a broad grouping of controls. A controlFamily doesn't have to be unique; it can be listed more than once in a spreadsheet. The same controlFamily can also be listed in multiple templates, though they have no relation to each other. Every controlFamily must be mapped to at least one control. controlTitle : Provide a title for the control. Whereas the controlName is a reference code, the title is a rich text format typically seen in the regulations. controlDescription : Provide a description of the control. controlActionTitle : This is the title of an action that you want to relate to this control. You can add multiple actions by separating with two semi-colons with no space in between. Every control you list must include at least one action, and the action must exist (which means you can list an action that you list on the\u202fActions\u202ftab of the same spreadsheet, an action that exists in a different template, or an action created by Microsoft). Different controls can reference the same action. Actions tab (Required) \u2693\ufe0e The\u202f Actions \u202ftab is required. It designates improvement actions managed by your organization and not those of Microsoft, which already exist in Compliance Manager. The required columns for this tab, which must follow the order provided in the sample spreadsheet, are: actionTitle : This is the title for your action and is a required field. The title you provide must be unique. Important note: if you reference an action that you own which already exists (such as in another template) and you modify any of its elements in the subsequent columns, those changes will propagate to the same action in other templates. implementationType : In this required field, list one of the three implementation types below: Operational \u202f- actions implemented by people and processes to protect the confidentiality, integrity, and availability of organizational systems, assets, data, and personnel (example: security awareness and training) Technical \u202f- actions completed using technology and mechanisms contained in the hardware, software, or firmware components of the information system to protect the confidentiality, integrity, and availability of organizational systems and data (example: multi-factor authentication) Documentation \u202f- actions implemented through documented policies and procedures establishing and defining the controls required to protect the confidentiality, integrity, and availability of organizational systems, assets, data, and personnel (example: an information security policy) ActionScore : Provide a score for the action between 1 and 99 \u2013 you may only use whole numbers. ActionDescription : Provide a description of the action, which will be shown under \u201cHow to Implement\u201d for the action\u2019s page in Compliance Manager. (Optional) Dimension fields \u2013 use syntax dimension-yourdimensionkey. Add any additional dimensions you wish to use to describe this action \u2013 if you are using a new DimensionKey or DimensionValue, you need to provide it in the Dimensions Tab, described in the next section below. Dimensions tab (Optional) \u2693\ufe0e The\u202fDimensions\u202ftab is optional. However, if you reference a dimension elsewhere, you need to specify it here if it does not exist in the template, you've already created or in a Microsoft template. The columns for this tab are listed below: dimensionKey : list as \"product\", \"certifications,\" \"action purpose\" dimensionValue : examples: Office 365, HIPPA, Preventative, Detective You can view your existing dimensions by exporting an existing template. The exported spreadsheet will have the\u202fDimensions\u202ftab, which lists all the dimensions used in the template. Maintain your Assessments \u2693\ufe0e Over time you might need to modify or change the template you created. You can modify the template you created or extended. To start this process, you need to export the template to an Excel file. To export your template, go to your template details page and select the Export to Excel button. Note When exporting a template you extended from a Compliance Manager template, the exported file will only contain the attributes you added to the template. The exported file won\u2019t include the original template data provided by Microsoft. To get such a report, you will need to export an assessment report. If you need to modify a template you\u2019ve already created, such as to add controls or to add or remove improvement actions, the process is like the template creation process. You\u2019ll need to upload a formatted Excel file with your template data; however, there are details to be aware of as you format your file with changes to existing template data. We recommend you review these instructions carefully to ensure you don\u2019t overwrite any existing data that you want to retain. Before starting it is always a good idea to have a backup/gold copy of the current assessment template before you make any changes. Considerations \u2693\ufe0e Using Compliance Manger is not a check mark or a guarantee that if the recommendations are followed, your organization is compliant. Use this guide along with the Compliance Manager quickstart guide to follow guidance on what items to do first to use the tool to its fullest. Compliance Manager leverages key elements in its management of activities. We recommend understanding controls, risk assessments, and grouping the controls into an assessment. We recommend that you start with deploying the built-in assessments before modifying to create a custom assessment. Compliance Manager auto scans the environment to update technical action status with the dashboard every 24 hours. For example, if you implement a control, the update will be visible the following day. When you open Compliance Manager for the first time you will see a baseline score for your organization. For further details on your score, review how your compliance score is calculated. Helpful Resources \u2693\ufe0e Compliance manager official Documentation - Microsoft Compliance Manager - Microsoft 365 Compliance | Microsoft Docs Microsoft Compliance Manager One stop shop - Microsoft Compliance Manager One Stop Shop Resource Page Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/ Review the FAQ for Compliance Manager to answer a question you might have about using Compliance Score in the past and how it is part of Compliance Manager solution. Knowledgebase from Customer Experience Engineering Team \u2693\ufe0e Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Join our Preview Program https://aka.ms/MIPC/JoinPreviews https://aka.ms/MIPC/Previews Visit all Community Resources https://aka.ms/MIPC/CommunityResources Learn from our webinar series and YouTube video series https://aka.ms/MIPC/Webinars and http://aka.ms/MIPC/YouTube Read our latest blog posts https://aka.ms/MIPblog and https://aka.ms/CompBlog Train End Users for adoption of labels: Sensitivity Labels Retention Labels Ask us on Yammer https://aka.ms/MIPC/AskMIPTeam Follow us on Twitter https://twitter.com/MIPnews using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com Appendix \u2693\ufe0e This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance. License Requirements \u2693\ufe0e Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change. Compliance Manager is available to organizations with Office 365 and Microsoft 365 licenses. Assessment availability and management capabilities depend on your licensing agreement.\u202f View service description details . Customers with Office 365 E1/A1/E3/A3/G3 and Microsoft 365 E1/A1/E3/A3/G3 licenses will be able to access the Data Protection Baseline assessment and be able to purchase premium assessments. Customers with Office 365 E5/A5/G5 and Microsoft 365 E5/A5/G5 licenses will be able to access Data Protection Baseline, GDPR, NIST 800-53 and ISO 27001 out-of-the-box assessments. They will also be able to create custom assessments. Starting July 1, 2021, all SKUs will be able to purchase premium assessments. In addition, for G5 customers will get additional Cybersecurity Maturity Model Certification (CMMC) Levels 1 through 5 out-of-the-box assessments. We do offer a trial SKU for Premium templates so you can try up to 25 out for 30 days. If you do not have the required license, you can add trial SKUs to try out the E5 or Premium assessments. To add premium assessments, you will want to add the Compliance Manager Premium Assessment Add-On Trial from your license, this will give you the opportunity to try out up to 25 premium assessments. Note Please email the CxE team with any suggestions related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"Compliance Manager"},{"location":"dag/cm/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle.","title":"Your Deployment Plan"},{"location":"dag/cm/#compliance-manager-overview","text":"Compliance Manager allows your organization to simplify compliance and start reducing risk by completing pre-built assessments targeting industries, standards, regulations or leveraging a custom assessment created by you\u202fand your organization. In addition to the assessments, this tool provides step-by-step guidance on open actions and displays\u202fa score for measuring\u202fyour\u202fcompliance posture. The tool focuses on identifying gaps and controls\u202fthat need to be addressed and\u202fprovides suggestions on how to improve these\u202fitems,\u202fdrawing elements from\u202fstandard Information Security and Compliance frameworks like GDPR, NIST etc.\u202f Compliance Manager provides:\u202f Built in assessments for common industry and regional standards and regulations, or custom assessments to meet your unique compliance needs. Flagged issues with detailed step-by-step guidance on suggested improvement actions to help you comply with the standards and regulations that are most relevant for your organization. \u202f Automated testing and validation to help you stay compliant with various regulations. \u202f An overall risk-based compliance score to help understand your compliance posture by measuring your progress in completing improvement actions. Frequent updates ensures that if a regulation or control changes, you are made aware of it to help you to continue to stay compliant.","title":"Compliance Manager Overview"},{"location":"dag/cm/#best-practices","text":"Below is a list of best practices we have gathered to help you take advantage of what Compliance Manager brings to your organization. Updates to an action propagate tenant wide. Our recommendation is to accept the updates so that you get the latest guidance and improvement actions to meet a requirement. \u202f\u202f Use correctly formatted Excel files when working with Compliance Manager to prevent errors with the import process. Export any existing assessment before deleting it in case you need to add it back through the import process. If you reassign an action that has a pending update, the direct link to the action in the reassignment email will break if the update is accepted after reassignment. You can fix this by reassigning the action to the user after the update is accepted.","title":"Best Practices"},{"location":"dag/cm/#prior-to-deployment-plan","text":"","title":"Prior to Deployment Plan"},{"location":"dag/cm/#understanding-your-current-organizational-landscape","text":"Before starting your compliance journey, it is important to understand what current regulations your organization needs to comply with so that you know what regulations you need to track and monitor your progress against. Compliance Manager offers over 330 regulation assessments that you can use to help your organization stay compliant. Most organizations are using some method to track these regulations, either with other tools or Excel spreadsheets. It is important to understand how your organization is managing this today, as Compliance Manager can standardize and centralize all of these into one location. If you are currently using other methods to track regulations, you can even bring your own controls into Compliance Manager. One of the primary values of using Compliance Manager is that we can provide actions items, assess, update, test and stay current with changes happening to the regulations. The pre-built assessments are being updated as regulations or technology changes, so that Microsoft can provide you the most up to date data in a central location. When thinking about compliance for your organization it is important to make sure you have the right stakeholders or technical decision makers (TDM) involved in your Compliance Manager journey. For most organizations this is not just the IT department, although they might have a role to play in the implementation of some of the action items. Below is a list of key personas we see using and being involved in Compliance Manager discussions.","title":"Understanding your current organizational landscape"},{"location":"dag/cm/#key-personas","text":"Compliance Manager personas at\u202fhigh\u202flevel can be put into one of these categories:","title":"Key personas"},{"location":"dag/cm/#assessors","text":"Assessors are compliance, security, privacy, and risk officers (Officers). They ensure that their organizational assets are compliant with applicable regulations, data is protected as per standards, and compliance / technology risks are managed as per their organizational policies. Assessors can also be auditors who maintain independent audit of assessment work performed by officers listed above. How assessors\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f They are most likely personas who create assessments as per their organizational compliance management needs. They will work with admins to ensure that assessment actions are implemented, tested, and completed. \u202f They will review assessment progress, compliance metrics, and risks with executive personas.","title":"Assessors:"},{"location":"dag/cm/#admins","text":"Admins are security, compliance, process, and IT administrators. These personas have the ability to make configurational changes to implement actions / controls. They are typically the people who need to pull evidence to showcase that actions / controls have been implemented and performing effectively. How admins\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f Admins will review actions assigned to them, implement these actions using S-C-M (security, compliance and management) solutions, and collect evidence for closing actions assigned to them. They may create IT risk / data protection related assessment on their own, as per their org maturity around IT / Technology risk management. They may participate in executive reviews.","title":"Admins:"},{"location":"dag/cm/#executives","text":"Chief Compliance, IT, Information Security, Privacy, Finance, HR and Risk officers. Depending upon how compliance, security, privacy, and risk management functions are structured within an organization, these executives have overall responsibility for compliance and risk management. How executives\u202fnormally\u202finteract with Compliance Manager:\u202f\u202f\u202f Set overall compliance and risk management policies and objectives for their organization. This will influence type and number of assessments created within Compliance Manager. They may review Compliance Manager dashboard on ongoing basis to track compliance management progress, blockers, and risks.","title":"Executives:"},{"location":"dag/cm/#permissions","text":"Compliance Manager is enabled in your tenant but only individuals with the right access can view scores, add assessments and work with the actions. Users will need at least the Compliance Manager reader role or Azure AD global reader role to access Compliance Manager. The Microsoft 365 global administrator for your organization will likely be the first user to access Compliance Manager. We recommend the global admin sign in and set user permissions as outlined below when visiting Compliance Manager for the first time. Additional details about permissions and role type are available here: https://docs.microsoft.com/en-us/microsoft-365/compliance/compliance-manager-setup?view=o365-worldwide#where-to-set-permissions","title":"Permissions"},{"location":"dag/cm/#deployment-plan","text":"This document offers guidance and steps that customer compliance executive and IT teams can utilize to adopt the service. This document is divided into three sections offering an overview approach for service adoption using General Data Protection Regulation (GDPR) as the assessment of choice. The sections are designed to represent the recommended deployment approach crawl-walk-run for Microsoft 365 Compliance Manager. Note GDPR assessment has been chosen as the assessment of choice to demonstrate the walk approach; however, you can choose any other regulatory assessment that is relevant to your organization.","title":"Deployment Plan"},{"location":"dag/cm/#crawl-core-service","text":"This is where you should start your compliance journey. This will set the foundation for using Compliance Manager to help your organization become and stay compliant. This will include tasks like: Becoming familiar with Compliance Manager, settings, and how to enable this service for your organization. Going through key service features and capabilities. Understanding your data protection baseline score.\u202f\u202f Setup automated testing and scoring Using the user history to audit who has what actions and reassign actions if needed.","title":"Crawl:\u202fCore\u202fService"},{"location":"dag/cm/#how-to-enable-this-service-for-your-organization","text":"Compliance Manager comes enabled by default for your organization. An initial score will be provided based on the Microsoft 365 data protection baseline. This baseline is a set of controls that includes key regulations and standards for data protection and general data governance. A great way to get started is to use this score to understand where your organization baseline is and ways to improve this by reviewing and taking actions outlined in your improvement actions. Also consider the concepts and process you use to correct and work with data baseline actions is the same process and concepts that apply to any other prebuilt or custom assessment you add to Compliance Manager.","title":"How to enable this service for your organization"},{"location":"dag/cm/#configure-permissions-and-adding-users-to-role-groups","text":"Compliance Manager uses a role-based access control (RBAC) permission model. Only users who are assigned a role may access Compliance Manager, and the actions allowed by each user are restricted by\u202f role type . Permissions can be configured in two (2) places: Azure Active Directory which allows you the ability to use PIMs (privileged identity management). There are four roles that can be used with Azure AD. The benefit of using PIMs is that you can enable just in time access. The drawback to this method is that currently, the available permission is not as granular as the permission in the security and compliance center. Security and Compliance center (Compliance Center). There are five roles that can be used to set permissions for Compliance Manager. You have the ability to be a bit more granular here when assigning access via roles, but this is standing access to the users added to the roles. Customers in US Government Community (GCC) High and Department of Defense (DoD) environments can only set user permissions and roles for Compliance Manager in Azure AD. See below for Azure AD instructions and role type definitions.","title":"Configure permissions and adding users to role groups"},{"location":"dag/cm/#role-types","text":"Users will need at least the Compliance Manager reader role, or Azure AD global reader role to access Compliance Manager.\u202f ROLE TYPES User can: Compliance Manager role Azure AD role Read but not edit data Compliance Manager Reader Azure AD Global reader, Security reader Edit data Compliance Manager Contribution Compliance Administrator Edit test results Compliance Manager Assessor Compliance Administrator Manage assessments, and template and tenant data Compliance Manager Administration Compliance Administrator, Compliance Data Administrator, Security Administrator Assign users Global Administrator Global Administrator","title":"Role Types"},{"location":"dag/cm/#add-users-to-compliance-manager-administrator-role-group","text":"A role group is a set of roles that allows users to perform their job across the Security & Compliance Center. For example, the Compliance Administrator role group includes (among other roles) the roles for Case Management, Content Search, and Organization Configuration (plus others), because someone who is a compliance admin will need the permissions for those tasks to perform their job. You can add role groups and achieve separation of roles and responsibilities by simply adding individual users as members to the role group . The role groups you want to create help to apply principle of least privilege by delegating tasks and functions that you'll need to assign users to.","title":"Add users to Compliance Manager administrator role group"},{"location":"dag/cm/#create-a-custom-role-group-for-auditors","text":"You can directly add users to a specific role group or create custom role groups to expand the portfolio of the team responsible for managing compliance in an organization. One of these custom groups you should consider is the compliance auditors . These are users who can review the compliance posture of your organization with read only access to Compliance Manager by using the Compliance Manager Reader role .","title":"Create a custom role group for auditors"},{"location":"dag/cm/#key-service-elements-features-and-capabilities","text":"Compliance Manager uses several data elements to help you manage your compliance activities. As you use Compliance Manager to assign, test, and monitor compliance activities, it\u2019s helpful to have a basic understanding of the key elements: controls, assessments, templates, and improvement actions. Controls : A control is a requirement of a regulation, standard, or policy. It defines how you assess and manage system configuration, organizational process, and people responsible for meeting a specific requirement of a regulation, standard, or policy. Compliance Manager tracks the following types of controls: Microsoft managed controls : controls for Microsoft cloud services, which Microsoft is responsible for implementing. Your controls : sometimes referred to as customer managed controls, these are controls implemented and managed by your organization. Shared Controls : sometimes referred to as customer managed controls, these are controls implemented and managed by your organization. Compliance Manager automatically scans through your Microsoft 365 environment and detects your system settings, continuously and automatically updating your technical action status. Microsoft Secure Score is the underlying engine that performs the monitoring. Your action status is updated on your dashboard every 24 hours. Once you follow a recommendation to implement a control, you\u2019ll typically see the control status updated the next day. Assessments :\u202fAn assessment is a grouping of controls from a specific regulation, standard, or policy. Completing the actions within an assessment help you meet the requirements of a standard, regulation, or law. Assessments have several components:\u202f In-scope services :\u202fthe specific set of Microsoft services applicable to the assessment Controls :\u202fMicrosoft managed, your controls and shared controls \u202f Assessment score :\u202fshows your progress in achieving total possible points from actions within the assessment that are managed by your organization and by Microsoft. Templates :\u202fTemplates to help you quickly create assessments. You can modify templates to create an assessment optimized for your needs. You can also build a custom assessment by creating a template with your own controls and actions (We will cover this in the Run section). Included and Premium Templates:\u202f Included templates \u202fare available for use as part of your organization\u2019s licensing agreement. Premium templates \u202fmust be purchased to create assessments from them. Once purchased, you may create as many assessments from a template as needed. You can also try these templates out before you buy them. (In the Appendix section we\u2019ll cover how to sign up for a trial.) Active and inactive templates\u202f\u202f A template is considered active once you create an assessment from that template. Your assessment page has a counter near the top which displays the number of templates in use vs the number of assessments you are licensed to use. For example, if you see 2/5 that means you have 2 active templates out of 5 that you are licensed for. If you see 5/2 this means you have exceeded the limits you are licensed for, and you need to remove or purchase more license. A template is considered inactive if your organization isn\u2019t using it for an assessment. Improvement actions : Improvement actions help centralize your compliance activities. Each improvement action provides recommended guidance that\u2019s intended to help you align with data protection regulations and standards. Improvement actions can be assigned to users in your organization to perform implementation and testing work. You can also store documentation, notes, and record status updates within the improvement action. Groups : When creating assessments, you\u2019ll assign them to a group. You can configure groups in whatever way is most logical for your organization. For example, you may group assessments by audit year, region, solution, teams within your organization, or some other way. Once you create groups, you can filter your Compliance Manager dashboard to view your score by one or more groups. It is important to note that the same action, if tenant scoped, can be in multiple groups. If this is the case, the action can be updated in one of the groups and it would be replicated to all groups that contain that action. For example, take MFA being required on Admin accounts. If this is enabled, it would be enabled for all groups that contain this action.","title":"Key service elements, features and capabilities"},{"location":"dag/cm/#understanding-your-data-protection-baseline-score","text":"Compliance Manager by default creates a data protection baseline that can be used to implement data protection controls and measure the control effectiveness against this baseline. It helps to establish and maintain technical, procedural, and people control for your organization. Data protection baseline is built by leveraging leading standards for data protection, information security, and privacy. Using guidance provided by data protection baseline, you can protect your data against insider, and malicious threats. By implementing actions that are part of data protection baseline, you can get ahead of compliance by being better prepared for new regulations coming. Setting up a good baseline also builds a strong foundation before adding additional regulatory specific assessments.","title":"Understanding your data protection baseline score"},{"location":"dag/cm/#set-up-automated-testing","text":"Some improvement actions in Compliance Manager are also monitored by Microsoft Secure Score. You can set up automated testing of actions that are jointly monitored, which means that when an action is tested and updated in Secure Score, those results sync with the same actions in Compliance Manager and count toward your compliance score. Automatic testing is turned on by default for organizations new to Compliance Manager. When you first deploy Microsoft 365 or Office 365, it takes approximately seven days for Secure Score to fully collect data and factor it into your compliance score. When automated testing is turned on, the action\u2019s test date won\u2019t be updated, but its test status will update. When new assessments are created, scores automatically include Microsoft control scores and Secure Score integration. If you want to change these setting it can be done by a global administrator at any time. You can turn off automated testing for common improvement actions or turn it on for individual actions.","title":"Set up automated testing"},{"location":"dag/cm/#user-history","text":"User history helps you quickly identify which users have worked with improvement actions in Compliance Manager. The identifiable user data associated with improvement actions includes any implementation and testing work done, documents uploaded, and any notes entered. Understanding and retrieving this type of data may be necessary for your organization\u2019s own compliance needs. You can use the search button to find a user who you are looking for, which can be useful when working with many users. You might find it useful to be able to export the data to an Excel file which will contain a list of improvement actions currently assigned to a user and any evidence files uploaded by that user. This information can help you reassign open improvement actions. It is important to note that the report reflects the improvement action\u2019s status as of its creation date. It\u2019s not a historical report of all previous changes to its status or assignment. If a user leaves the organization or their role changes, you might be required to reassign improvement actions from one user to another. This is possible to do in the Compliance Manager user history section. It is important to note that when you reassign an action, the document upload history doesn't change, but the name of the user who originally uploaded the documentation no longer appears within the improvement action.","title":"User history"},{"location":"dag/cm/#walk-working-with-an-assessment","text":"The Walk phase builds upon the components of the crawl phase and looks to add one or more regulatory assessments for your organization, such as GDPR. This would include tasks like: * How to choose a pre-built assessment * How to read and understand your score * How to read, implement, and test your improvement actions * Assigning tasks and managing controls * How to track your way to become compliant * Keeping the assessment actions updated The most important data elements for configuring Compliance Manager are Assessment Templates and Assessments. Compliance Manager provides a rich library of over 330 assessment\u202ftemplates, each of which represents a specific regulation, certification, or standard that aligns to an industrial, regional, and common data protection standard, such as GDPR or ISO 27001. These assessment templates contain all the control families and controls from the regulation or standard, and a set of actions that are mapped to these controls. These actions include both improvement actions for helping you meet the requirements of that regulation or standard, and Microsoft actions that have already been taken by Microsoft. Each action has points associated with it and these help determine your compliance score.","title":"Walk: Working with an assessment"},{"location":"dag/cm/#choose-a-pre-built-assessment","text":"To get started quickly, you can pick from one of over 330 assessments already set up and available to you in Compliance Manager. There is a wide selection of templates for regulations and certifications that align to industries, regions, and common data protection standards, such as GDPR and ISO 27001. Templates contain the controls and improvement actions for helping you meet the requirements of a particular certification. For a full list of templates available check out - Microsoft Compliance Manager templates list - Microsoft 365 Compliance | Microsoft Docs. Adding a pre-built assessment allows you to immediately begin to review actions items, make the required changes, test, and complete the action item. Within a few minutes, you can add multiple regulations that are important to your organization and start tracking your progress against meeting these regulations.","title":"Choose a pre-built assessment"},{"location":"dag/cm/#assessment-types","text":"Assessment templates are added to Compliance Manager as new laws and regulations are enacted. Compliance Manager updates its templates when the underlying laws or regulations change. Compliance Manager classifies assessment into two (2) categories. Included templates are templates included as part of your organization's licensing agreement. Premium templates display additional templates your organization may choose to obtain on additional credits Below is the included templates for the M365 A5/E5/G5 license. Visit the Compliance Manager templates list for the most up-to-date information on assessments. Microsoft Compliance Manager templates list - Microsoft 365 Compliance | Microsoft Docs Microsoft Data Protection Baseline European Union GDPR (Microsoft 365, Office 365, Intune) ISO 27001:2013 NIST 800-53 Rev.4 NIST 800-53 Rev.5 Cybersecurity Maturity Model Certification (CMMC) Levels 1 through 5 (G5 Only)","title":"Assessment Types"},{"location":"dag/cm/#understand-groups","text":"Before you create or modify assessments, it\u2019s important to understand how groups work. When you create an assessment, you\u2019ll need to assign it to a group during the process. This is an important step to plan out before you create assessments. Groups are containers that you can use to organize your assessments that are logical to you. Some examples might be by year, regulation, department, or geographies. An example of this might be: Assessments 2020 FFIEC IS GDPR US 2020 FFIEC IS FISMA United States of America Privacy Act Ohio 2021 Ohio Data Protection Act 2018 EU 2020 GDPR Directive 2006/24/EC It is important to understand how improvement actions work within a group and across groups. When two different assessments in the same group share improvement actions that are managed by you, any updates you make to an action's implementation details or status will automatically synchronize to the same action in any other assessment in the group. This synchronization allows you to implement one improvement action and meet several requirements across multiple regulations. If the improvement action is a tenant action, for example require MFA, there will only be one action for all groups. So, completing this in one group will apply the same status to all groups that have this action. While working within a group you can see all the actions for that group and a breakdown of the score for the group you are working on. While you can always see the score for the tenant, it is sometimes easier to focus in on a particular group.","title":"Understand groups"},{"location":"dag/cm/#what-to-know-when-working-with-groups","text":"There are some additional guidelines when working with groups that you should be aware of. Group names must be unique within your organization. At this time, groups cannot be deleted but they can be reused. Groups don't have security properties. All permissions are associated with assessments. Once you add an assessment to a group, the grouping can't be changed. Related assessment controls in different assessments within the same group automatically update when completed. If you add a new assessment to an existing group, common information from assessments in that group are copied to the new assessment. Groups can contain assessments for the same certification or regulation, but each group can only contain one assessment for a specific product-certification pair. For example, a group can't contain two assessments for Office 365 and NIST CSF. A group can contain multiple assessments for the same product only if the corresponding certification or regulation for each one is different. Deleting an assessment breaks the relationship between that assessment and the group. When a change is made to an improvement that appears in multiple groups, that change is reflected in all instances of that improvement action.","title":"What to know when working with groups"},{"location":"dag/cm/#pre-built-assessments","text":"Now that you know how to configure groups, it\u2019s time to get started by picking from one of the more than 330 assessments Compliance Manager offers out of the box. You\u2019ll be asked to choose an assessment template when you start\u202fbuilding an assessment. You can also create your own custom assessment template, which we will cover in the run phase. It can be quick and easy to use the templates we have built for you which also update automatically. Below is an example of the assessments page. It lists the assessments you select to track for your organization and your compliance score denominator is determined by all your tracked assessments. Thus, the more assessments you add, the more improvement actions you see on your improvement actions page, and the higher your score denominator is.","title":"Pre-built Assessments"},{"location":"dag/cm/#setting-up-an-assessment","text":"There are two starting points for creating an assessment from a Compliance Manager template. You can begin the process from your assessments page by selecting the Add assessment button and then working through the assessment creation wizard. You can also start from your assessment templates page by finding the template you want and selecting it from the list to arrive at its details page. On the template details page, select Create assessment. You\u2019ll then enter the wizard with your template already selected.","title":"Setting up an assessment"},{"location":"dag/cm/#assignment-and-tracking","text":"Improvement actions centralize your compliance activities. Each improvement action provides detailed implementation guidance to help you align with data protection regulations and standards. It is common that the Compliance Manager administrator is not always the person preforming the actions to implement the controls. Compliance Manager allows actions to be assigned to users in your organization to perform implementation and testing work. When you assign an action to someone, they get notified that they have been assigned and if they have the right permissions, they are able to see details about the action. Emails are not currently sent if you are in GCC High or a DOD environment","title":"Assignment and tracking"},{"location":"dag/cm/#implementation-and-testing","text":"The person or team who is assigned an action then uses the details of the action item to complete the work, conduct testing, upload evidence, and change the status of the action item. Once that has been completed, it is assigned to an assessor for validation. The assessor validates the work, examines the documentation, and selects the appropriate test status. If test status is set to \u201cPassed\u201d : the action is complete, and the points achieved shows the maximum points achieved. The points are then counted toward your overall compliance score. If test status is set to \u201cFailed\u201d : the action doesn't meet the requirements, and the assessor can update the notes and assign it back to the appropriate user for additional work.","title":"Implementation and testing"},{"location":"dag/cm/#keeping-the-assessment-actions-update","text":"One of the many values of Compliance Manager is that it is continuously updated to keep up with regulatory changes and changes in M365. When you see a pending update label next to its name on the improvement actions page and on the details page of its related assessments, you can either accept the update or defer it to a later date. You can get more details about the update before accepting it or deferring it. Updates normally occur on a quarterly cycle. An update occurs when there are changes related to scoring, automation, and/or scope. Changes may involve new guidance for improvement actions based on regulatory changes or could be because of product changes. Only the improvement actions managed by your organizations receive update notifications. We do not provide updates to the Microsoft managed actions. Accepting updates helps ensure that you have the most updated guidance on using solutions and taking appropriate improvement actions to help you meet the requirements of the certification at hand. There are times when you might want to defer an update if you\u2019re in the middle of completing an assessment that includes the improvement action. You may want to ensure you\u2019ve finished work on it before you accept the update. Accepted changes are permanent. When you accept an update to an action, you\u2019re also accepting updates to any other versions or instances of this action. Updates will propagate tenant-wide for technical actions and will propagate group-wide for non-technical actions.","title":"Keeping the assessment actions update"},{"location":"dag/cm/#how-to-track-your-way-to-become-compliant","text":"The Compliance Manager dashboard displays an overall compliance score. This score measures progress in completing recommended improvement actions within controls. Compliance score can help in understanding your current compliance posture. It can also help prioritize actions based on their potential to reduce risk. A score value is assigned at three (3) levels: Improvement action score: each action has a different impact on your score depending on the potential risk involved. Control score: this score is the sum of points earned by completing improvement actions within the control. This sum is applied in its entirety to your overall compliance score when the control meets both of the following conditions: Implementation Status \u202fequals\u202f Implemented \u202for\u202f Alternative Implementation , and Test Result \u202fequals\u202f Passed . Assessment score : this score is the sum of your control scores. It is calculated using action scores. Each Microsoft action and each improvement action managed by your organization is counted once, regardless of how often it is referenced in a control. The overall compliance score is calculated using action scores, where each Microsoft action is counted once, each technical action you manage is counted once, and each non-technical action you manage is counted once per group. This logic is designed to provide the most accurate accounting of how actions are implemented and tested in your organization. You may notice that this can cause your overall compliance score to differ from the average of your assessment scores. Read more below about \u202f how actions are scored .","title":"How to track your way to become compliant"},{"location":"dag/cm/#initial-score-based-on-microsoft-365-data-protection-baseline","text":"Compliance Manager gives you an initial score based on the Microsoft 365 data protection baseline . This baseline is a set of controls that includes key regulations and standards for data protection and general data governance. This baseline draws elements primarily from the National Institute of Standards and Technology Cybersecurity Framework ( NIST CSF ) and International Organization for Standardization ( ISO ), as well as from Federal Risk and Authorization Management Program ( FedRAMP ) and General Data Protection Regulation of the European Union ( GDPR ). Your initial score is calculated according to the default Data Protection Baseline assessment provided to all organizations. Upon your first visit, Compliance Manager is already collecting signals from your Microsoft 365 solutions. You will be able to see how your organization is performing relative to key data protection standards and regulations. You will be also able to see suggested improvement actions to take. Because every organization has specific needs, Compliance Manager relies on you to set up and manage assessments to help minimize and mitigate risk as comprehensively as possible.","title":"Initial score based on Microsoft 365 data protection baseline"},{"location":"dag/cm/#continuously-assesses-controls","text":"Compliance Manager automatically scans through your Microsoft 365 environment and detects your system settings, continuously and automatically updating your technical action status. Microsoft Secure Score is the underlying engine that performs the monitoring. Your action status is updated on your dashboard every 24 hours. Once you follow a recommendation to implement a control, you\u2019ll typically see the control status updated the next day. For example, if you turn on multi-factor authentication (MFA) in the Azure AD portal, Compliance Manager detects the setting and reflects it in the control access solution details. Conversely, if you didn\u2019t turn on MFA, Compliance Manager flags that as a recommended action for you to take. Learn more about \u202f Secure Score and how it works .","title":"Continuously assesses controls"},{"location":"dag/cm/#action-types-and-points","text":"Compliance Manager tracks two types of actions: Your improvement actions : actions that your organization manages. Microsoft actions : actions that Microsoft manages. Both types of actions have points that count toward your overall score when completed.","title":"Action types and points"},{"location":"dag/cm/#technical-and-non-technical-actions","text":"Actions are grouped by whether they are technical or non-technical in nature. The scoring impact of each action differs by type. Technical actions \u202fare implemented by interacting with the technology of a solution (for example, changing a configuration). The points for technical actions are granted once per action, regardless of how many groups it belongs to. Non-technical actions \u202fare managed by your organization and implemented in ways other than working with the technology of a solution. There are two types of non-technical actions:\u202f documentation \u202fand\u202f operational . The points for these actions are applied to your compliance score at a group level. This means that if an action exists in multiple groups, you will receive the action's point value each time you implement it within a group.","title":"Technical and non-technical actions"},{"location":"dag/cm/#example-of-how-technical-and-non-technical-actions-are-scored","text":"For example, you have a technical action worth 3 points that exists in 5 groups, and you have a non-technical action worth 3 points that exists in the same 5 groups. If you successfully implement the technical action, the total number of points you receive is 3. This is because you only need to implement the action once for your tenant. The implementation and test status for the technical action will show the same in all instances of that action, in every group it belongs to. This scoring logic is designed to provide the most accurate accounting of how actions are implemented and tested in your organization.","title":"Example of how technical and non-technical actions are scored"},{"location":"dag/cm/#score-value-determination","text":"Actions are assigned a score value based on whether they\u2019re mandatory or discretionary, and whether they\u2019re preventative, detective, or corrective.","title":"Score Value Determination"},{"location":"dag/cm/#mandatory-and-discretionary-actions","text":"Mandatory actions\u202fcan't be bypassed, either intentionally or accidentally. An example of a mandatory action is a centrally managed password policy that sets requirements for password length, complexity, and expiration. Users must follow these requirements to access the system. Discretionary actions\u202frely upon users to understand and adhere to a policy. For example, a policy requiring users to lock their computer when they leave it is a discretionary action because it relies on the user.","title":"Mandatory and discretionary actions"},{"location":"dag/cm/#preventative-detective-and-corrective-actions","text":"Preventative actions\u202faddress specific risks. For example, protecting information at rest using encryption is a preventative action against attacks and breaches. Separation of duties is a preventative action to manage conflict of interest and guard against fraud. Detective actions\u202factively monitor systems to identify irregular conditions or behaviors that represent risk, or that can be used to detect intrusions or breaches. Examples include system access auditing and privileged administrative actions. Regulatory compliance audits are a type of detective action used to find process issues. Corrective actions\u202ftry to keep the adverse effects of a security incident to a minimum, take corrective action to reduce the immediate effect, and reverse the damage if possible. Privacy incident response is a corrective action to limit damage and restore systems to an operational state after a breach. Each action has an assigned value in Compliance Manager based on the risk it represents:","title":"Preventative, detective, and corrective actions"},{"location":"dag/cm/#run-customize-and-expand-assessments","text":"Now that you have a strong foundation in Compliance Manager and you have worked with an out of box assessment template, we\u2019ll look at how you can build on this to create your own assessments, expand on the prebuilt assessments, or use Compliance Manager to assess 3rd party platforms or applications. This can really drive home the value of having a centrally managed location to track all your compliance management needs. We see customers using a mix of out of box assessment and adding their own custom assessments or expanding on the out of box assessments to meet their company\u2019s needs. This allows for a lot of flexibility. We know that most organizations, in addition to Microsoft software, will have presence of heterogenous software, multiple on-prem services either commercially purchased on home grown, and multiple SaaS services such as Salesforce, ServiceNow or others. For an organization, it is important to have compliance to assessments for all Microsoft & Non-Microsoft services. Let\u2019s look at how you can leverage Compliance Manager to complete 3rd party assessments or build bring-your own assessments to cover your entire organizational scope. This section will focus on how you can leverage Compliance Manager to expand and cover your entire organizational scope by taking advantage of: Extending a prebuilt assessment by adding your own controls and improvements How to create your own custom assessment","title":"Run: Customize and Expand Assessments"},{"location":"dag/cm/#extend-pre-built-assessment-templates","text":"First you might want to take what we give you with a prebuilt assessment and modify it to fit your organizational needs. You can do this by taking an out of the box assessment template and adding your own controls and improvement actions to the assessment template. This process is called \u201c extending a Microsoft template \u201d in Compliance Manager. When you extend an out of the box assessment template, it will continue to receive any updates released by Microsoft, which may happen when there are changes to the related regulation or product. The nice benefit of this is you can customize what we have given to you as a template to meet your organizational needs or expand to assess your 3rd party platforms. An example of this might be GDPR regulation that you need to take some type of action on your on-prem environment. You could use the GDPR template to monitor and track everything inside of O365 but then have additional actions to track items that need to happen with your on-prem environment. This keeps everything under the GDPR Assessment score and when looking at the actions to stay compliant it is all in one location. Let\u2019s discuss how this process works. You first need to assemble a specially formatted Excel spreadsheet to import the necessary template data. There are specific requirements for the\u202f formatted Excel files\u202fused in the extension process and some points to be aware of to prevent errors in the import process: Your spreadsheet should contain only the actions and controls you want to add to the assessment. The spreadsheet can not contain any of the controls or actions that already exist in the assessment you want to modify. Consider including \u201cextension\u201d in your template\u2019s title, for example, \u201cGDPR \u2013 [your company name] extension\u201d. This makes it easier to identify in the list on your\u202f assessment templates \u202fpage as distinct from the standard Microsoft-provided template or a custom template with a similar name.","title":"Extend pre-built assessment templates"},{"location":"dag/cm/#create-and-maintain-your-own-custom-assessments","text":"If expanding an existing template does not meet your needs, or you already have an assessment template you manage in excel or another platform, you can build your own assessments from scratch. We call this creating a custom assessment and this capability is available at the A5/E5/G5 SKUS. Creating a custom assessment in Compliance Manager requires you to create your own template. To create your own template, you\u2019ll first assemble a formatted Excel spreadsheet to import the necessary template data. A sample template can be found here: https://go.microsoft.com/fwlink/?linkid=2124865 . Begin by formatting your template data into an Excel spreadsheet using\u202f these instructions .","title":"Create and maintain your own custom assessments"},{"location":"dag/cm/#formatting-your-template-with-excel","text":"When you start with the Excel spreadsheet you will notice it contains four (4) tabs, three (3) of which are required: Template\u202f(required) ControlFamily\u202f(required) Actions\u202f(required) Dimensions\u202f(optional)","title":"Formatting your template with Excel"},{"location":"dag/cm/#template-tab-required","text":"The\u202f Template \u202ftab is required. The information in this tab provides metadata about the template. There are four (4) required columns. The columns must retain the order on the Excel sheet as listed below. You can add your own column\u202fafter\u202fthe four (4) columns to provide your own dimensions. If you do this, be sure to add them to the\u202fDimensions\u202ftab using the\u202finstructions below. title : This is the title for your template which must be unique. It can't share a name with another template you have in Compliance Manager, including your own templates or an out of the box template. product : This is a required dimension. List the product associated with the template. certification : This is the regulation you're using for the template. inScopeServices : These are the services within the product that this assessment addresses (for example, if you listed Office 365 as the product, Microsoft Teams could be an in-scope service). You can list multiple services separated by two (2) semi-colons.","title":"Template tab (required)"},{"location":"dag/cm/#controlfamily-tab-required","text":"The\u202f ControlFamily \u202ftab is required. The required columns in this tab, which must follow the order provided in the sample spreadsheet, are: controlName : This is the control name from the certification, standard, or regulation, which is typically some type of ID. Control names must be unique within a template. You can't have multiple controls with the same name in the spreadsheet. controlFamily : Provide a word or phrase for the controlFamily, which identifies a broad grouping of controls. A controlFamily doesn't have to be unique; it can be listed more than once in a spreadsheet. The same controlFamily can also be listed in multiple templates, though they have no relation to each other. Every controlFamily must be mapped to at least one control. controlTitle : Provide a title for the control. Whereas the controlName is a reference code, the title is a rich text format typically seen in the regulations. controlDescription : Provide a description of the control. controlActionTitle : This is the title of an action that you want to relate to this control. You can add multiple actions by separating with two semi-colons with no space in between. Every control you list must include at least one action, and the action must exist (which means you can list an action that you list on the\u202fActions\u202ftab of the same spreadsheet, an action that exists in a different template, or an action created by Microsoft). Different controls can reference the same action.","title":"ControlFamily tab (Required)"},{"location":"dag/cm/#actions-tab-required","text":"The\u202f Actions \u202ftab is required. It designates improvement actions managed by your organization and not those of Microsoft, which already exist in Compliance Manager. The required columns for this tab, which must follow the order provided in the sample spreadsheet, are: actionTitle : This is the title for your action and is a required field. The title you provide must be unique. Important note: if you reference an action that you own which already exists (such as in another template) and you modify any of its elements in the subsequent columns, those changes will propagate to the same action in other templates. implementationType : In this required field, list one of the three implementation types below: Operational \u202f- actions implemented by people and processes to protect the confidentiality, integrity, and availability of organizational systems, assets, data, and personnel (example: security awareness and training) Technical \u202f- actions completed using technology and mechanisms contained in the hardware, software, or firmware components of the information system to protect the confidentiality, integrity, and availability of organizational systems and data (example: multi-factor authentication) Documentation \u202f- actions implemented through documented policies and procedures establishing and defining the controls required to protect the confidentiality, integrity, and availability of organizational systems, assets, data, and personnel (example: an information security policy) ActionScore : Provide a score for the action between 1 and 99 \u2013 you may only use whole numbers. ActionDescription : Provide a description of the action, which will be shown under \u201cHow to Implement\u201d for the action\u2019s page in Compliance Manager. (Optional) Dimension fields \u2013 use syntax dimension-yourdimensionkey. Add any additional dimensions you wish to use to describe this action \u2013 if you are using a new DimensionKey or DimensionValue, you need to provide it in the Dimensions Tab, described in the next section below.","title":"Actions tab (Required)"},{"location":"dag/cm/#dimensions-tab-optional","text":"The\u202fDimensions\u202ftab is optional. However, if you reference a dimension elsewhere, you need to specify it here if it does not exist in the template, you've already created or in a Microsoft template. The columns for this tab are listed below: dimensionKey : list as \"product\", \"certifications,\" \"action purpose\" dimensionValue : examples: Office 365, HIPPA, Preventative, Detective You can view your existing dimensions by exporting an existing template. The exported spreadsheet will have the\u202fDimensions\u202ftab, which lists all the dimensions used in the template.","title":"Dimensions tab (Optional)"},{"location":"dag/cm/#maintain-your-assessments","text":"Over time you might need to modify or change the template you created. You can modify the template you created or extended. To start this process, you need to export the template to an Excel file. To export your template, go to your template details page and select the Export to Excel button. Note When exporting a template you extended from a Compliance Manager template, the exported file will only contain the attributes you added to the template. The exported file won\u2019t include the original template data provided by Microsoft. To get such a report, you will need to export an assessment report. If you need to modify a template you\u2019ve already created, such as to add controls or to add or remove improvement actions, the process is like the template creation process. You\u2019ll need to upload a formatted Excel file with your template data; however, there are details to be aware of as you format your file with changes to existing template data. We recommend you review these instructions carefully to ensure you don\u2019t overwrite any existing data that you want to retain. Before starting it is always a good idea to have a backup/gold copy of the current assessment template before you make any changes.","title":"Maintain your Assessments"},{"location":"dag/cm/#considerations","text":"Using Compliance Manger is not a check mark or a guarantee that if the recommendations are followed, your organization is compliant. Use this guide along with the Compliance Manager quickstart guide to follow guidance on what items to do first to use the tool to its fullest. Compliance Manager leverages key elements in its management of activities. We recommend understanding controls, risk assessments, and grouping the controls into an assessment. We recommend that you start with deploying the built-in assessments before modifying to create a custom assessment. Compliance Manager auto scans the environment to update technical action status with the dashboard every 24 hours. For example, if you implement a control, the update will be visible the following day. When you open Compliance Manager for the first time you will see a baseline score for your organization. For further details on your score, review how your compliance score is calculated.","title":"Considerations"},{"location":"dag/cm/#helpful-resources","text":"Compliance manager official Documentation - Microsoft Compliance Manager - Microsoft 365 Compliance | Microsoft Docs Microsoft Compliance Manager One stop shop - Microsoft Compliance Manager One Stop Shop Resource Page Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/ Review the FAQ for Compliance Manager to answer a question you might have about using Compliance Score in the past and how it is part of Compliance Manager solution.","title":"Helpful Resources"},{"location":"dag/cm/#knowledgebase-from-customer-experience-engineering-team","text":"Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Join our Preview Program https://aka.ms/MIPC/JoinPreviews https://aka.ms/MIPC/Previews Visit all Community Resources https://aka.ms/MIPC/CommunityResources Learn from our webinar series and YouTube video series https://aka.ms/MIPC/Webinars and http://aka.ms/MIPC/YouTube Read our latest blog posts https://aka.ms/MIPblog and https://aka.ms/CompBlog Train End Users for adoption of labels: Sensitivity Labels Retention Labels Ask us on Yammer https://aka.ms/MIPC/AskMIPTeam Follow us on Twitter https://twitter.com/MIPnews using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com","title":"Knowledgebase from Customer Experience Engineering Team"},{"location":"dag/cm/#appendix","text":"This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance.","title":"Appendix"},{"location":"dag/cm/#license-requirements","text":"Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change. Compliance Manager is available to organizations with Office 365 and Microsoft 365 licenses. Assessment availability and management capabilities depend on your licensing agreement.\u202f View service description details . Customers with Office 365 E1/A1/E3/A3/G3 and Microsoft 365 E1/A1/E3/A3/G3 licenses will be able to access the Data Protection Baseline assessment and be able to purchase premium assessments. Customers with Office 365 E5/A5/G5 and Microsoft 365 E5/A5/G5 licenses will be able to access Data Protection Baseline, GDPR, NIST 800-53 and ISO 27001 out-of-the-box assessments. They will also be able to create custom assessments. Starting July 1, 2021, all SKUs will be able to purchase premium assessments. In addition, for G5 customers will get additional Cybersecurity Maturity Model Certification (CMMC) Levels 1 through 5 out-of-the-box assessments. We do offer a trial SKU for Premium templates so you can try up to 25 out for 30 days. If you do not have the required license, you can add trial SKUs to try out the E5 or Premium assessments. To add premium assessments, you will want to add the Compliance Manager Premium Assessment Add-On Trial from your license, this will give you the opportunity to try out up to 25 premium assessments. Note Please email the CxE team with any suggestions related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"License Requirements"},{"location":"dag/dag-resources/","text":"Last updated: 05/10/2021 One Compliance Story \u2693\ufe0e Our Data Classification solution will play an important role in not only your information protection strategy but also your information governance and records management deployment. Content Explorer will allow you to scan your content before you create any policies with zero change management. You will be able to see what sensitive information types (SITs) exist in your environment and create your own. These SITs can be leveraged to auto-apply retention, record, and sensitivity labels as well as trigger DLP policies. Activity Explorer provides the ability to monitor what\u2019s being done with your labeled content which will allow you to see the impact that the retention and records labels are having in your environment to help assess your protection and governance policy needs. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your governance strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and sensitivity labels. If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. Things to note for both Insider Risk Management and Communication Compliance integration with Advanced eDiscovery: - The underlying content of the escalation from IRM/CC is automatically added to a review set in the case in Advanced eDiscovery. You can put data sources on hold or run further searches on the custodians and locations that you deem relevant and add results as per relevance to the same or different review sets. - For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to have the eDiscovery Manager/Administrator privilege. With information in many locations organization need an easy way to be able to audit then activities across many different services in Microsoft 365. Advanced Audit helps organizations to conduct forensic and compliance investigations by increasing audit log retention required to conduct an investigation, providing access to crucial events that help determine scope of compromise, and faster access to Office 365 Management Activity API. Useful Links \u2693\ufe0e Ready to get started with Microsoft E5 Compliance? https://techcommunity.microsoft.com/t5/security-privacy-and-compliance/ready-to-get-started-with-microsoft-365-e5-compliance-adopt-with/ba-p/989785 Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/ Knowledgebase from Customer Experience Engineering Team \u2693\ufe0e Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Get started today! Join our Preview Program: https://aka.ms/MIPC/JoinPreviews Visit all Community Resources Learn from our webinar series and YouTube video series: Webinars YouTube Read up on our latest blog posts: MIP Blogs Compliance Blogs Train End Users for adoption of labels: Sensitivity Labels Retention Labels Ask us on Yammer Follow us on Twitter using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com Note We encourage contacting the CxE team with any suggestions directly related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"Resources"},{"location":"dag/dag-resources/#one-compliance-story","text":"Our Data Classification solution will play an important role in not only your information protection strategy but also your information governance and records management deployment. Content Explorer will allow you to scan your content before you create any policies with zero change management. You will be able to see what sensitive information types (SITs) exist in your environment and create your own. These SITs can be leveraged to auto-apply retention, record, and sensitivity labels as well as trigger DLP policies. Activity Explorer provides the ability to monitor what\u2019s being done with your labeled content which will allow you to see the impact that the retention and records labels are having in your environment to help assess your protection and governance policy needs. Having a strong information governance and records management posture ensures that content that needs to be retained is retained in-place and content that does not need to be retained is deleted. The downstream effects of a strong information governance and records management posture should be considered for your governance strategy. Less data means less risk and lower litigation costs. Microsoft eDiscovery tools support items encrypted with Microsoft encryption technologies. These technologies include Office Message Encryption, Azure Rights Management, and sensitivity labels. If a file that is encrypted with a Microsoft encryption technology is attached to an email message or located on a SharePoint or OneDrive account, those encrypted items are decrypted when the search results are prepared for preview, added to a review set in Advanced eDiscovery, and exported. Should you need to further investigate messages identified by your communication compliance policy, you can use the Escalate for Investigation control to create a new Advanced eDiscovery case. You will provide a name and notes for the new case, and user who sent the message matching the policy is automatically assigned as the case custodian. Things to note for both Insider Risk Management and Communication Compliance integration with Advanced eDiscovery: - The underlying content of the escalation from IRM/CC is automatically added to a review set in the case in Advanced eDiscovery. You can put data sources on hold or run further searches on the custodians and locations that you deem relevant and add results as per relevance to the same or different review sets. - For the IRM or CC admin to have visibility to the case in Advanced eDiscovery, it is essential for them to have the eDiscovery Manager/Administrator privilege. With information in many locations organization need an easy way to be able to audit then activities across many different services in Microsoft 365. Advanced Audit helps organizations to conduct forensic and compliance investigations by increasing audit log retention required to conduct an investigation, providing access to crucial events that help determine scope of compromise, and faster access to Office 365 Management Activity API.","title":"One Compliance Story"},{"location":"dag/dag-resources/#useful-links","text":"Ready to get started with Microsoft E5 Compliance? https://techcommunity.microsoft.com/t5/security-privacy-and-compliance/ready-to-get-started-with-microsoft-365-e5-compliance-adopt-with/ba-p/989785 Microsoft 365 Roadmap Website - has public details about when new features are in development and when the features are targeted to launch or are available. To see details about a particular product, filter the check boxes to select what product/s you are interested in. https://www.microsoft.com/en-us/microsoft-365/roadmap Microsoft 365 Compliance Documentation https://docs.microsoft.com/en-us/microsoft-365/compliance/","title":"Useful Links"},{"location":"dag/dag-resources/#knowledgebase-from-customer-experience-engineering-team","text":"Ready to become the hero of your organization? Learn more about deploying Microsoft Information Protection & Compliance features with the resources below: Get started today! Join our Preview Program: https://aka.ms/MIPC/JoinPreviews Visit all Community Resources Learn from our webinar series and YouTube video series: Webinars YouTube Read up on our latest blog posts: MIP Blogs Compliance Blogs Train End Users for adoption of labels: Sensitivity Labels Retention Labels Ask us on Yammer Follow us on Twitter using the tag #MicrosoftIP Email us \u2013 mipsccxe@microsoft.com Note We encourage contacting the CxE team with any suggestions directly related to products, webinars, blogs, or ideas for additional training. All support issues should be directed through the appropriate channels of support or community forums.","title":"Knowledgebase from Customer Experience Engineering Team"},{"location":"dag/ir-cc/","text":"Last updated: 05/10/2021 In today\u2019s climate one of the top concerns for security and compliance are the data leakage from insider risks. Studies point to insider risk from specific user events and activities; protecting your organization may seem impossible if one does not have insight or a way to identify the risk but worse if you cannot mitigate the risk you do not know about. With this in mind, let\u2019s get started with Microsoft 365 Insider Risk Management (IRM) and Communication Compliance (CC) solutions. Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe. Communication Compliance \u2693\ufe0e Communication compliance is part of the new insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and take remediation actions for inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate communications in your organization that do not meet your standards, as identified through configurable rules, and take appropriate remediation actions to make sure that they are compliant with your organization's message standards. Communication compliance supports several company communications channels including those part of the Microsoft 365 solution such as Exchange email, Microsoft Teams, Yammer or Skype for Business, as well as a large number of third-party communication platforms integrated through available connectors such as Twitter, Facebook, and Bloomberg instant messages. More details on third-party connectors can be found here . Communication compliance policies in Microsoft 365 help you overcome many modern challenges associated with compliance and internal and external communications, including: Scanning increasing numbers of communication channels The increasing communication volumes Regulatory enforcement & the risk of fines Best Practices \u2693\ufe0e Let\u2019s establish some of the preparation that goes into start of execution of using communication compliance to help plan your deployment. Policy Definition \u2693\ufe0e While the usage of communication compliance is distinct to each organization and their business and regulatory requirements and the policies you define will need to be designed accordingly, the following criteria can be used to guide the initial creation of policies at most organizations. Decide whether your organization\u2019s use cases for the solution revolve around regulatory compliance, enforcing a code of conduct, preventing self-harm or harm to others, or monitoring external communications by specific employees (or more than one of these or other scenarios), and define policies based on this decision according to the following rules. For code of conduct policies: It is generally advised that you create policies that cover all employees. While code of conduct violations by employees in some roles may be more problematic than in other roles, a minimum set of rules must be met by all employees, so start with a single policy that is scoped to all employees. Code of conduct policies typically utilize the built-in classifiers for offensive language. Create a policy utilizing the classifiers for profanity, harassment, targeted harassment, adult images, gory images, and racy images (it is alternatively possible to create separate policies for some of these if you think they should be monitored by different auditors or the response time needed for different types of offenses may vary significantly). While it is possible to create your own trainable classifiers for handling specific offensive or non-compliant terms, it is generally easier to start with the built-in classifiers and only train or retrain your own classifiers if needed. In some organizations, it may not be necessary to detect all offenses, and configuring the policy to only create alerts to a given percentage of offensive language use may be effective enough, since if employees know their communications are being regularly monitoring that may be enough incentive for them to follow the rules. In other organizations where no exceptions can be allowed a 100% review percentage may be needed. It is possible to create overlapping rules for specific roles such as executives, people working with customers or people in special, external-facing roles, or policies targeting specific communication channels that can have higher exposure such as social media. Such roles can be more aggressive in their rules and have higher review percentages than rules for the general population. In most cases, for code of conduct policies you will want to monitor both internal and outbound communications. Monitoring inbound communications can also be useful for detecting potential sources of stress to your employees. For policies related to monitoring self-harm or threats to others, similar practices to the ones for offensive language apply, but it is generally advised to create a policy that is separate from offensive language, since this type of policy usually requires a quicker reaction time in order to avoid actual harm and you may want to monitor such alerts more diligently. You will also likely want to configure a 100% review for such policies. For meeting regulatory compliance requirements, you will typically create a custom policy with rules that are dictated by your regulatory requirements. Typically, you will create a policy starting with the regulatory compliance policy template and configure it with rules that utilize \u201cmessage (or attachment) contains any of these words\u201d and provide words or phrases frequently used in language that represents the type of risks you want to identify. For example, for detecting situations such as improper gifts you can define phrases like \u201ccomplimentary\u201d, \u201cgift\u201d, \u201cat no cost to you\u201d and \u201cour treat\u201d. For more complex requirements, you can create custom Sensitive Information Types (SIT) and use them in your policies. A custom SIT can use large dictionaries that are easier to maintain, combinations of different lists of words, complex conditions including operators (and/or/not) and near relationships between terms and more. Go to Data Classification page in M365 SCC, navigate to Sensitive Info Types tab. Click Create Info Type and use your dictionary to create a custom SIT. For more details, check this How to setup a keyword dictionary Go to Policies tab in Communication Compliance admin portal and click Create Policy. Choose Custom Policy from the drop-down menu and use custom create SIT in the Conditions And Percentages page of the New Policy Wizard along with other details as required. This method can require more effort to implement than a simple keyword list or a trainable classifier, so it is recommended that you start with the simpler option and assess your accuracy before committing to more complex policies based on sensitive info types. In most cases, regulatory compliance policies can be scoped to specific communications, in particular including only external communications or communications to/from specific organizations can significantly reduce the volume of alerts to review while keeping the relevant messages in scope. Communication compliance can also be used for monitoring communications through official channels (such as official communications by executives and PR people such as on Twitter feeds). While it is rare that an employee would intentionally commit policy violations in such channels, it is not as rare that an employee mixes up their personal account with the official one and send improper messages that way. Using Communication compliance to monitor such media can help rapidly detect potential offenses and delete the offending messages. In most cases you may want to utilize the built-in classifiers for offensive language, harassment, and the classifiers for gory, racy and adult images for these policies. If your organization is multi-national or have employees that communicate in multiple languages, contact Microsoft for access to the Offensive Language classifiers in different languages, currently in preview. If you do so, unless you know that all your auditors are fluent in all the languages in question, it is often recommended that you create separate policies for each of these languages, so you can assign in each policy reviewers that can read the language in question and properly assess the offenses. Since Communication compliance will attempt to detect the language in which a message is written and will use the right classifiers accordingly, it is generally not required to assign policies in specific languages to known speakers of those languages. Still, doing so can reduce false positives due to the fact that certain non-offensive words in some languages can be identical to offensive words in other languages, so if you have large known populations that communicate in specific languages (such as to people in specific countries where that language is the primary language in use) you can target such language-specific policies to those populations to make the solution more accurate. At this moment, Communication compliance gathers and analyzes messages on a 24-hour cycle, which starts at the moment a policy is enabled for the first time. You may want to plan the creation of policies that relate to time-sensitive matters (such as threats) so it completes at the same time when you expect your analysts to check daily for alerts, in order to minimize the delay in reviewing messages. For other types of policies some organizations prefer to align their creation with the end of the productive day for most employees so policies can be reviewed before the next day. While compliance alerts are often monitored by individuals specifically assigned to the role, assessment of noncompliance often requires escalation to other roles in the organization. It is recommended that before putting your policies in production you identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions and alerts triaging in communication compliance. Some recommended personas to include in the end-to-end investigation workflow are human resources, compliance/privacy and legal. You may also want to involve people that are fluent in specific languages or that are familiar with the culture of specific regions since there may be local nuances that change the meaning of some phrases. It is often useful to create groups in Office 365 or channels in Teams including these persons to make obtaining feedback about these types of situations more efficient (though for obvious reasons assessment of offensive language or images is typically better handled 1:1). Also, in order to allow these persons to have direct access to the Communication compliance console, assign the required role groups to these groups or individuals. Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating it in a test environment will require that you generate simulated user content to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. After creating a new policy, expect alerts to start arriving in 24 hours, though there may be additional delay in some cases. Investigating Alerts \u2693\ufe0e The first step to investigate issues detected by your policies is to review generated alerts in the Microsoft 365 compliance center. There are several areas in the compliance center to help you to quickly investigate alerts, depending on how you prefer to view alert grouping: Communication compliance home page : Here you will see: Alerts needing review listed from high to low severity. Select an alert to launch the alert details page and to start remediation actions. Recent policy matches listed by policy name. Resolved items listed by policy name. Escalations listed by policy name. Users with the most policy matches, listed from the most to the least number of matches. Alerts tab: Display alerts grouped by matched communication compliance policy. This view allows you to quickly see which communication compliance policies are generating the most alerts ordered by severity. Policies tab: Each policy listed includes the count of alerts that need review. Selecting a policy displays all the pending alerts for matches to the policy, select a specific alert to launch the policy details page and to start remediation actions. Considerations \u2693\ufe0e To make communication compliance available as a menu option in Microsoft 365 compliance center, you must be assigned the Supervisory Review Administrator role. You must create a new role group for reviewers with the Supervisory Review Administrator, Case Management, Compliance Administrator, and Review roles to investigate and remediate messages with policy matches. For communication compliance to be able to monitor user activity, you have to enable the Audit log in Office 365 . Helpful Resources \u2693\ufe0e For step-by-step instructions to begin setup of communication compliance, please follow guidance: Get started with communication compliance Stay up to date with the new announcements and features in communication compliance by following our latest blog posts: Foster a culture of inclusion and safety with Microsoft Teams and Communication Compliance Manage a broad range of communication risks efficiently Insider Risk Management \u2693\ufe0e Internal risks are often what keeps business leaders up at night \u2013 regardless of whether negligent or malicious, identifying and being able to take action on internal risks are critical. The ability to quickly identify and manage risks from insiders (employees or contractors with corporate access) and minimize the negative impact on corporate compliance, competitive business position and brand reputation is a priority for organizations worldwide. Insider risk management is a solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and take action on risky activities in your organization using signals from user activity, human resources (HR) systems and other sources that can provide rich context to enable accurate identification of potential threats. Custom policies allow you to detect and act on malicious and inadvertent risk activities in your organization, including escalating cases to Microsoft Advanced eDiscovery if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards. Best Practices \u2693\ufe0e Let\u2019s establish some of the preparation that goes into start of execution of using insider risk to help plan your deployment. Prior to Deployment Plan \u2693\ufe0e Identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions on insider risks. Some recommended personas to include in the end-to-end investigation workflow are compliance/privacy, security, HR, and legal. Insider risk management has role-based access control. You must be added or add users within your organization to the Insider Risk Management role group. Insider risk management uses audit logs for user insights and activities, it is a prerequisite to enable the Audit Log in Office 365. Deployment Test Plan \u2693\ufe0e Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating in a test environment will require that you generate simulated user actions and other signals in order to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. When you set up a policy in insider risk management, the type of the policy defines the type of action that will act as a trigger to put a user under observation. For example, in the Departing Employee Data Theft policy, the trigger that causes the system to start analyzing the user\u2019s behavior is a record indicating the departure date of an employee coming into the system through the HR connector, while for a Data Leak policy the analysis is triggered by a data loss prevention (DLP) alert being raised for the high severity DLP policy you designated during configuration. While you are testing the solution, you can monitor its progress in the evaluation of user activity by looking at the Users tab. When a user performs an action that matches the trigger conditions for a policy (e.g., announces their departure which is informed to the system through the HR connector) you will see the name of the user and the policy being triggered in the Users list. When you click on the user, you will see on the User Activity tab the list of all detected actions for the user along with their risk score. This will give you a view on what activity was detected and how it was quantified. There are multiple insider risk management policy templates available. For the Departing Employee Data Theft policy, you must setup the HR connector to leverage HR notice and termination dates as a signal to alert you of any user activity related to data theft among departing employees. Step-by-step instructions to setup the HR connector can be found here. The Data Leak policy will leverage a DLP policy configured for High severity alerts to alert you of any user activity related to a data leak of sensitive information. Production Deployment \u2693\ufe0e Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. Select dedicated Insider Risk analysts to monitor and review the alerts on a regular cadence in the Microsoft 365 compliance center. After creating a new policy, do not expect to see alerts coming up immediately. Insider risk is not a solution where you should see a lot of activity. In fact, most organizations see alerts being generated at a rate of a few per week or less, since the alerts should be highly relevant and represent in most cases actual instances of malicious behavior or an employee putting the organization at risk. Once the event that triggers analysis occurs, the user\u2019s activities are put under observation while the user\u2019s past and future activities are evaluated to determine if the user\u2019s behavior represents a risk, and if so, an alert is raised. Upon seeing an alert being raised, our recommendation is that there are dedicated analysts reviewing the alerts and can make decisions based on the information provided (e, g. if it needs to be turned into a case for investigation, escalated, or whether actions need to be taken.) While if you implement all the recommendations above you are set for a successful deployment of IRM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e Insider risk management focuses on the user instead of the individual actions and will raise alerts for users that its analysis indicates represent a risk to the organization. The risks are analyzed based on well-known patterns of behavior that are frequently observed in many organizations, such as employees taking sensitive data with them when they leave the company. This enables the solution to detect most instances of the risks being monitored while producing little or no noise. You may need to consider the regional privacy laws to monitor insider risk activities within your organization. We recommend privacy reviews with privacy and/or legal stakeholders to ensure you are complying with company policies and privacy standards. Helpful Resources \u2693\ufe0e To get started with insider risk management, please follow the step-by-step instructions here . You may find this Insider Risk Management evaluation guide useful for setting up and troubleshooting guidance. Stay up to date with the new announcements and features in Insider Risk Management by following our latest blog posts: Effectively managing insider risks with integrated collaboration solutions including Microsoft Teams Protecting against insider risks in an uncertain environment Appendix \u2693\ufe0e This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance. License Requirements \u2693\ufe0e Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change. Communication Compliance (CC) \u2693\ufe0e Before you get started with communication compliance, you should confirm your Microsoft 365 subscription and any add-ons. To access and use communication compliance, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions) Insider Risk Management (IRM) \u2693\ufe0e Before you get started with insider risk management policies, you should confirm your Microsoft 365 subscription and any add-ons. To access and use insider risk management policies, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Insider Risk Management and Communication Compliance"},{"location":"dag/ir-cc/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: \u2022 Compliance Manager \u2022 Microsoft Compliance Configuration Analyzer (MCCA) \u2022 Communication Compliance \u2022 Insider Risk Management The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe.","title":"Your Deployment Plan"},{"location":"dag/ir-cc/#communication-compliance","text":"Communication compliance is part of the new insider risk solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and take remediation actions for inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate communications in your organization that do not meet your standards, as identified through configurable rules, and take appropriate remediation actions to make sure that they are compliant with your organization's message standards. Communication compliance supports several company communications channels including those part of the Microsoft 365 solution such as Exchange email, Microsoft Teams, Yammer or Skype for Business, as well as a large number of third-party communication platforms integrated through available connectors such as Twitter, Facebook, and Bloomberg instant messages. More details on third-party connectors can be found here . Communication compliance policies in Microsoft 365 help you overcome many modern challenges associated with compliance and internal and external communications, including: Scanning increasing numbers of communication channels The increasing communication volumes Regulatory enforcement & the risk of fines","title":"Communication Compliance"},{"location":"dag/ir-cc/#best-practices","text":"Let\u2019s establish some of the preparation that goes into start of execution of using communication compliance to help plan your deployment.","title":"Best Practices"},{"location":"dag/ir-cc/#policy-definition","text":"While the usage of communication compliance is distinct to each organization and their business and regulatory requirements and the policies you define will need to be designed accordingly, the following criteria can be used to guide the initial creation of policies at most organizations. Decide whether your organization\u2019s use cases for the solution revolve around regulatory compliance, enforcing a code of conduct, preventing self-harm or harm to others, or monitoring external communications by specific employees (or more than one of these or other scenarios), and define policies based on this decision according to the following rules. For code of conduct policies: It is generally advised that you create policies that cover all employees. While code of conduct violations by employees in some roles may be more problematic than in other roles, a minimum set of rules must be met by all employees, so start with a single policy that is scoped to all employees. Code of conduct policies typically utilize the built-in classifiers for offensive language. Create a policy utilizing the classifiers for profanity, harassment, targeted harassment, adult images, gory images, and racy images (it is alternatively possible to create separate policies for some of these if you think they should be monitored by different auditors or the response time needed for different types of offenses may vary significantly). While it is possible to create your own trainable classifiers for handling specific offensive or non-compliant terms, it is generally easier to start with the built-in classifiers and only train or retrain your own classifiers if needed. In some organizations, it may not be necessary to detect all offenses, and configuring the policy to only create alerts to a given percentage of offensive language use may be effective enough, since if employees know their communications are being regularly monitoring that may be enough incentive for them to follow the rules. In other organizations where no exceptions can be allowed a 100% review percentage may be needed. It is possible to create overlapping rules for specific roles such as executives, people working with customers or people in special, external-facing roles, or policies targeting specific communication channels that can have higher exposure such as social media. Such roles can be more aggressive in their rules and have higher review percentages than rules for the general population. In most cases, for code of conduct policies you will want to monitor both internal and outbound communications. Monitoring inbound communications can also be useful for detecting potential sources of stress to your employees. For policies related to monitoring self-harm or threats to others, similar practices to the ones for offensive language apply, but it is generally advised to create a policy that is separate from offensive language, since this type of policy usually requires a quicker reaction time in order to avoid actual harm and you may want to monitor such alerts more diligently. You will also likely want to configure a 100% review for such policies. For meeting regulatory compliance requirements, you will typically create a custom policy with rules that are dictated by your regulatory requirements. Typically, you will create a policy starting with the regulatory compliance policy template and configure it with rules that utilize \u201cmessage (or attachment) contains any of these words\u201d and provide words or phrases frequently used in language that represents the type of risks you want to identify. For example, for detecting situations such as improper gifts you can define phrases like \u201ccomplimentary\u201d, \u201cgift\u201d, \u201cat no cost to you\u201d and \u201cour treat\u201d. For more complex requirements, you can create custom Sensitive Information Types (SIT) and use them in your policies. A custom SIT can use large dictionaries that are easier to maintain, combinations of different lists of words, complex conditions including operators (and/or/not) and near relationships between terms and more. Go to Data Classification page in M365 SCC, navigate to Sensitive Info Types tab. Click Create Info Type and use your dictionary to create a custom SIT. For more details, check this How to setup a keyword dictionary Go to Policies tab in Communication Compliance admin portal and click Create Policy. Choose Custom Policy from the drop-down menu and use custom create SIT in the Conditions And Percentages page of the New Policy Wizard along with other details as required. This method can require more effort to implement than a simple keyword list or a trainable classifier, so it is recommended that you start with the simpler option and assess your accuracy before committing to more complex policies based on sensitive info types. In most cases, regulatory compliance policies can be scoped to specific communications, in particular including only external communications or communications to/from specific organizations can significantly reduce the volume of alerts to review while keeping the relevant messages in scope. Communication compliance can also be used for monitoring communications through official channels (such as official communications by executives and PR people such as on Twitter feeds). While it is rare that an employee would intentionally commit policy violations in such channels, it is not as rare that an employee mixes up their personal account with the official one and send improper messages that way. Using Communication compliance to monitor such media can help rapidly detect potential offenses and delete the offending messages. In most cases you may want to utilize the built-in classifiers for offensive language, harassment, and the classifiers for gory, racy and adult images for these policies. If your organization is multi-national or have employees that communicate in multiple languages, contact Microsoft for access to the Offensive Language classifiers in different languages, currently in preview. If you do so, unless you know that all your auditors are fluent in all the languages in question, it is often recommended that you create separate policies for each of these languages, so you can assign in each policy reviewers that can read the language in question and properly assess the offenses. Since Communication compliance will attempt to detect the language in which a message is written and will use the right classifiers accordingly, it is generally not required to assign policies in specific languages to known speakers of those languages. Still, doing so can reduce false positives due to the fact that certain non-offensive words in some languages can be identical to offensive words in other languages, so if you have large known populations that communicate in specific languages (such as to people in specific countries where that language is the primary language in use) you can target such language-specific policies to those populations to make the solution more accurate. At this moment, Communication compliance gathers and analyzes messages on a 24-hour cycle, which starts at the moment a policy is enabled for the first time. You may want to plan the creation of policies that relate to time-sensitive matters (such as threats) so it completes at the same time when you expect your analysts to check daily for alerts, in order to minimize the delay in reviewing messages. For other types of policies some organizations prefer to align their creation with the end of the productive day for most employees so policies can be reviewed before the next day. While compliance alerts are often monitored by individuals specifically assigned to the role, assessment of noncompliance often requires escalation to other roles in the organization. It is recommended that before putting your policies in production you identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions and alerts triaging in communication compliance. Some recommended personas to include in the end-to-end investigation workflow are human resources, compliance/privacy and legal. You may also want to involve people that are fluent in specific languages or that are familiar with the culture of specific regions since there may be local nuances that change the meaning of some phrases. It is often useful to create groups in Office 365 or channels in Teams including these persons to make obtaining feedback about these types of situations more efficient (though for obvious reasons assessment of offensive language or images is typically better handled 1:1). Also, in order to allow these persons to have direct access to the Communication compliance console, assign the required role groups to these groups or individuals. Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating it in a test environment will require that you generate simulated user content to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. After creating a new policy, expect alerts to start arriving in 24 hours, though there may be additional delay in some cases.","title":"Policy Definition"},{"location":"dag/ir-cc/#investigating-alerts","text":"The first step to investigate issues detected by your policies is to review generated alerts in the Microsoft 365 compliance center. There are several areas in the compliance center to help you to quickly investigate alerts, depending on how you prefer to view alert grouping: Communication compliance home page : Here you will see: Alerts needing review listed from high to low severity. Select an alert to launch the alert details page and to start remediation actions. Recent policy matches listed by policy name. Resolved items listed by policy name. Escalations listed by policy name. Users with the most policy matches, listed from the most to the least number of matches. Alerts tab: Display alerts grouped by matched communication compliance policy. This view allows you to quickly see which communication compliance policies are generating the most alerts ordered by severity. Policies tab: Each policy listed includes the count of alerts that need review. Selecting a policy displays all the pending alerts for matches to the policy, select a specific alert to launch the policy details page and to start remediation actions.","title":"Investigating Alerts"},{"location":"dag/ir-cc/#considerations","text":"To make communication compliance available as a menu option in Microsoft 365 compliance center, you must be assigned the Supervisory Review Administrator role. You must create a new role group for reviewers with the Supervisory Review Administrator, Case Management, Compliance Administrator, and Review roles to investigate and remediate messages with policy matches. For communication compliance to be able to monitor user activity, you have to enable the Audit log in Office 365 .","title":"Considerations"},{"location":"dag/ir-cc/#helpful-resources","text":"For step-by-step instructions to begin setup of communication compliance, please follow guidance: Get started with communication compliance Stay up to date with the new announcements and features in communication compliance by following our latest blog posts: Foster a culture of inclusion and safety with Microsoft Teams and Communication Compliance Manage a broad range of communication risks efficiently","title":"Helpful Resources"},{"location":"dag/ir-cc/#insider-risk-management","text":"Internal risks are often what keeps business leaders up at night \u2013 regardless of whether negligent or malicious, identifying and being able to take action on internal risks are critical. The ability to quickly identify and manage risks from insiders (employees or contractors with corporate access) and minimize the negative impact on corporate compliance, competitive business position and brand reputation is a priority for organizations worldwide. Insider risk management is a solution in Microsoft 365 that helps minimize internal risks by enabling you to detect, investigate, and take action on risky activities in your organization using signals from user activity, human resources (HR) systems and other sources that can provide rich context to enable accurate identification of potential threats. Custom policies allow you to detect and act on malicious and inadvertent risk activities in your organization, including escalating cases to Microsoft Advanced eDiscovery if needed. Risk analysts in your organization can quickly take appropriate actions to make sure users are compliant with your organization's compliance standards.","title":"Insider Risk Management"},{"location":"dag/ir-cc/#best-practices_1","text":"Let\u2019s establish some of the preparation that goes into start of execution of using insider risk to help plan your deployment.","title":"Best Practices"},{"location":"dag/ir-cc/#prior-to-deployment-plan","text":"Identify the appropriate stakeholders and personas in your organization to collaborate for remediation actions on insider risks. Some recommended personas to include in the end-to-end investigation workflow are compliance/privacy, security, HR, and legal. Insider risk management has role-based access control. You must be added or add users within your organization to the Insider Risk Management role group. Insider risk management uses audit logs for user insights and activities, it is a prerequisite to enable the Audit Log in Office 365.","title":"Prior to Deployment Plan"},{"location":"dag/ir-cc/#deployment-test-plan","text":"Before enabling the solution broadly in your production environment, you may consider testing the policies with a small set of production users or in a test environment while waiting for the necessary privacy and legal reviews in your organization. Bear in mind that evaluating in a test environment will require that you generate simulated user actions and other signals in order to create alerts that can be triaged and processed, so testing with a small group of users in a production environment is usually preferred. When you set up a policy in insider risk management, the type of the policy defines the type of action that will act as a trigger to put a user under observation. For example, in the Departing Employee Data Theft policy, the trigger that causes the system to start analyzing the user\u2019s behavior is a record indicating the departure date of an employee coming into the system through the HR connector, while for a Data Leak policy the analysis is triggered by a data loss prevention (DLP) alert being raised for the high severity DLP policy you designated during configuration. While you are testing the solution, you can monitor its progress in the evaluation of user activity by looking at the Users tab. When a user performs an action that matches the trigger conditions for a policy (e.g., announces their departure which is informed to the system through the HR connector) you will see the name of the user and the policy being triggered in the Users list. When you click on the user, you will see on the User Activity tab the list of all detected actions for the user along with their risk score. This will give you a view on what activity was detected and how it was quantified. There are multiple insider risk management policy templates available. For the Departing Employee Data Theft policy, you must setup the HR connector to leverage HR notice and termination dates as a signal to alert you of any user activity related to data theft among departing employees. Step-by-step instructions to setup the HR connector can be found here. The Data Leak policy will leverage a DLP policy configured for High severity alerts to alert you of any user activity related to a data leak of sensitive information.","title":"Deployment Test Plan"},{"location":"dag/ir-cc/#production-deployment","text":"Use the anonymization feature in settings to pseudonymize display names for risky users to maintain privacy and prevent bias when reviewing alerts and taking appropriate actions within the tool. Select dedicated Insider Risk analysts to monitor and review the alerts on a regular cadence in the Microsoft 365 compliance center. After creating a new policy, do not expect to see alerts coming up immediately. Insider risk is not a solution where you should see a lot of activity. In fact, most organizations see alerts being generated at a rate of a few per week or less, since the alerts should be highly relevant and represent in most cases actual instances of malicious behavior or an employee putting the organization at risk. Once the event that triggers analysis occurs, the user\u2019s activities are put under observation while the user\u2019s past and future activities are evaluated to determine if the user\u2019s behavior represents a risk, and if so, an alert is raised. Upon seeing an alert being raised, our recommendation is that there are dedicated analysts reviewing the alerts and can make decisions based on the information provided (e, g. if it needs to be turned into a case for investigation, escalated, or whether actions need to be taken.) While if you implement all the recommendations above you are set for a successful deployment of IRM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production Deployment"},{"location":"dag/ir-cc/#considerations_1","text":"Insider risk management focuses on the user instead of the individual actions and will raise alerts for users that its analysis indicates represent a risk to the organization. The risks are analyzed based on well-known patterns of behavior that are frequently observed in many organizations, such as employees taking sensitive data with them when they leave the company. This enables the solution to detect most instances of the risks being monitored while producing little or no noise. You may need to consider the regional privacy laws to monitor insider risk activities within your organization. We recommend privacy reviews with privacy and/or legal stakeholders to ensure you are complying with company policies and privacy standards.","title":"Considerations"},{"location":"dag/ir-cc/#helpful-resources_1","text":"To get started with insider risk management, please follow the step-by-step instructions here . You may find this Insider Risk Management evaluation guide useful for setting up and troubleshooting guidance. Stay up to date with the new announcements and features in Insider Risk Management by following our latest blog posts: Effectively managing insider risks with integrated collaboration solutions including Microsoft Teams Protecting against insider risks in an uncertain environment","title":"Helpful Resources"},{"location":"dag/ir-cc/#appendix","text":"This section contains links to the information regarding license requirements and provides additional links to additional information related to Microsoft Information Protection & Compliance.","title":"Appendix"},{"location":"dag/ir-cc/#license-requirements","text":"Below contains the necessary licenses for specific solutions outlined in the Deployment Acceleration Guide. While this information is current as of the writing of this document, refer to Microsoft 365 Licensing Guidance for Security & Compliance for the latest information as it may change.","title":"License Requirements"},{"location":"dag/ir-cc/#communication-compliance-cc","text":"Before you get started with communication compliance, you should confirm your Microsoft 365 subscription and any add-ons. To access and use communication compliance, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Communication Compliance (CC)"},{"location":"dag/ir-cc/#insider-risk-management-irm","text":"Before you get started with insider risk management policies, you should confirm your Microsoft 365 subscription and any add-ons. To access and use insider risk management policies, your organization must have one of the following subscriptions or add-ons: Microsoft 365 E5 subscription Microsoft 365 E3 subscription + the Microsoft 365 E5 Compliance add-on Microsoft 365 E3 subscription + the Microsoft 365 E5 Insider risk management add-on Microsoft 365 A5 subscription Microsoft 365 A3 subscription + the Microsoft 365 A5 Compliance add-on Microsoft 365 A3 subscription + the Microsoft 365 A5 Insider risk management add-on Microsoft 365 G5 subscription Microsoft 365 G5 subscription + the Microsoft 365 G5 Compliance add-on Microsoft 365 G5 subscription + the Microsoft 365 G5 Insider risk management add-on Office 365 Enterprise E5 subscription Office 365 Enterprise E3 subscription + the Office 365 Advanced Compliance add-on (no longer available for new subscriptions)","title":"Insider Risk Management (IRM)"},{"location":"dag/mamd/","text":"What is Migration Assistant for Microsoft DLP? \u2693\ufe0e The Migration Assistant for Microsoft DLP tool is a Windows based desktop application that will migrate your DLP policies from other DLP platforms to our Unified DLP platform. Our tool takes you through a simple five-step migration process. It accepts Symantec DLP policy XML exports, performs mapping, and creates equivalent Unified DLP policies through PowerShell scripts. You can safely use the tool to create DLP policies in test mode, which does not affect your live data or interact with current environment. Migration tasks that Migration Assistant for Microsoft DLP performs are : \u2693\ufe0e This takes over many of the difficult or tedious tasks involved in a DLP migration project: In traditional migration scenario, you need to perform feasibility analysis between source & target DLP platforms, map features, migrate policies manually, and test and tweak DLP policies. Your migrated DLP policies can be up and running within minutes of starting the M365 DMA process. With this, you can scale up your migration project quickly from moving a single policy manually to multiple policies at the same time. This automatically identifies Sensitive Information Types (SITs) or Data Identifiers in source policies and creates Custom SITs in your Microsoft tenant moving over all your custom regular expressions and keywords in a few clicks. This detects which conditions, exclusions & actions are currently being used in source policies and automatically creates new rules with the same conditions, exclusions & actions. This provides you with a detailed migration report with policy wise migration status and recommendations. This ensures that your DLP policy migration project is completely private and takes place within the boundaries of your organization. This supports policy migration from Symantec Data Loss Prevention 15.7 or earlier. How does this works? \u2693\ufe0e During a given instance of migration, the M365 DLP Migration Assistant works in five phases: Input : This ingests one or more Symantec DLP policy XML files. Analyze : This interprets the files & identifies Symantec DLP policy constructs. Rationalize : This maps the identified Symantec DLP policy constructs to Unified DLP capabilities. It performs validations for Unified DLP platform limitations. Migrate : This executes PowerShell scripts for the DLP scenarios identified & supported by the UDLP platform. Reporting : This provides the user with a detailed migration report about which policies were migrated successfully, partially and/or not migrated. It also provides recommendations to improve the migration fidelity further. Download Process \u2693\ufe0e Use the GitHub link to download the tool and follow instructions for how to install, run and configure the tool. Provide Feedback & Report Bugs \u2693\ufe0e Please report errors, share feedback & any feature requests with us by opening a new issue in this Github repository .","title":"Migration Assistant for Microsoft Purview DLP"},{"location":"dag/mamd/#what-is-migration-assistant-for-microsoft-dlp","text":"The Migration Assistant for Microsoft DLP tool is a Windows based desktop application that will migrate your DLP policies from other DLP platforms to our Unified DLP platform. Our tool takes you through a simple five-step migration process. It accepts Symantec DLP policy XML exports, performs mapping, and creates equivalent Unified DLP policies through PowerShell scripts. You can safely use the tool to create DLP policies in test mode, which does not affect your live data or interact with current environment.","title":"What is Migration Assistant for Microsoft DLP?"},{"location":"dag/mamd/#migration-tasks-that-migration-assistant-for-microsoft-dlp-performs-are","text":"This takes over many of the difficult or tedious tasks involved in a DLP migration project: In traditional migration scenario, you need to perform feasibility analysis between source & target DLP platforms, map features, migrate policies manually, and test and tweak DLP policies. Your migrated DLP policies can be up and running within minutes of starting the M365 DMA process. With this, you can scale up your migration project quickly from moving a single policy manually to multiple policies at the same time. This automatically identifies Sensitive Information Types (SITs) or Data Identifiers in source policies and creates Custom SITs in your Microsoft tenant moving over all your custom regular expressions and keywords in a few clicks. This detects which conditions, exclusions & actions are currently being used in source policies and automatically creates new rules with the same conditions, exclusions & actions. This provides you with a detailed migration report with policy wise migration status and recommendations. This ensures that your DLP policy migration project is completely private and takes place within the boundaries of your organization. This supports policy migration from Symantec Data Loss Prevention 15.7 or earlier.","title":"Migration tasks that Migration Assistant for Microsoft DLP performs are :"},{"location":"dag/mamd/#how-does-this-works","text":"During a given instance of migration, the M365 DLP Migration Assistant works in five phases: Input : This ingests one or more Symantec DLP policy XML files. Analyze : This interprets the files & identifies Symantec DLP policy constructs. Rationalize : This maps the identified Symantec DLP policy constructs to Unified DLP capabilities. It performs validations for Unified DLP platform limitations. Migrate : This executes PowerShell scripts for the DLP scenarios identified & supported by the UDLP platform. Reporting : This provides the user with a detailed migration report about which policies were migrated successfully, partially and/or not migrated. It also provides recommendations to improve the migration fidelity further.","title":"How does this works?"},{"location":"dag/mamd/#download-process","text":"Use the GitHub link to download the tool and follow instructions for how to install, run and configure the tool.","title":"Download Process"},{"location":"dag/mamd/#provide-feedback-report-bugs","text":"Please report errors, share feedback & any feature requests with us by opening a new issue in this Github repository .","title":"Provide Feedback &amp; Report Bugs"},{"location":"dag/mcca/","text":"Last updated: 05/07/2021 Where does one start today with regards to being compliant with various standards and assessments? There are often multiple steps you need to take to safeguard your compliance posture. Often, you want to know if there is a starting point or recommended best practices as you get started on your journey of managing compliance requirements. Questions you may ask yourself are: \u2018How do I diagnose my compliance posture or ensure that I have the right configurations in place to protect my environment completely. These are largely manual processes which tend to be time consuming & allow for human error. Furthermore, with the evolving compliance landscape the risk of blind spots also increases along with compliance requirements needing to be changed or updated; the latest information will be included with MCCA tool without the need to update manually. Figure 1: Actionable Status Report Microsoft Compliance Configuration Analyzer (MCCA) is a diagnostic tool (seen in Figure 1 above) which generates a report to help M365 customers understand their current consumption of E5 compliance offerings. It surfaces improvement areas in a tenant\u2019s compliance configurations in achieving data protection guidelines and recommends best practices to follow. This tool can help you quickly see which improvement actions in Compliance Manger apply to your current Microsoft 365 environment. It is a PowerShell-based utility that will fetch your tenant\u2019s current configurations & validate these configurations against Microsoft 365 recommended best practices. These best practices are based on a set of controls that include key regulations and standards for data protection and general data governance. MCCA was built with the goals of helping you extract maximum value out of compliance offerings part of your M365 E5 licenses by creating awareness to your consumption of M365 compliance offerings. Today, MCCA will provide you recommendations for 8 Compliance solutions. We will keep adding more solutions & richer recommendations in future versions of this tool. Microsoft Information Protection Data Loss Prevention Microsoft Information Governance Records Management Insider Risk Management Communication Compliance Advanced Audit Advanced eDiscovery Use the GitHub link to download the tool and follow instructions for how to install, run and configure the tool for the about eight solutions. Also, you can download and install the PowerShell module for MCCA from the PowerShell Gallery . With MCCA you can: Quickly and automatically fetch your tenant\u2019s current configurations & validate these configurations against Microsoft 365 recommended best practices. Quickly diagnose your compliance posture & ensure that they have the right configurations in place to protect their environment completely. Reports allow you to focus efforts more on making the right configurations. Best Practices \u2693\ufe0e The reporting is based on the geolocations in your tenant as it accesses the SITs for each location to generate a report. We suggest running it for all geolocations and then using the correct input parameter to change location if need be. Our recommendation is to download via PowerShell Gallery because it has less steps and is hassle-free. Using the GitHub repo will need to be cloned & the module needs to load into PowerShell. We suggest this method for more advanced users and/or contributors who know have deeper experience with PowerShell. Considerations \u2693\ufe0e The MCCA report can be generated in its entirety by users with Global Admin or Global Reader privileges. Other roles within the organization may not be able to run the tool or they may be able to run the tool with limited information in the final report. Helpful Resources \u2693\ufe0e Review the FAQ section for MCCA tool to answer a question you might have about making changes, reviewing reports, or what status indicates for each solution.","title":"Microsoft Compliance Configuration Analyzer (MCCA)"},{"location":"dag/mcca/#best-practices","text":"The reporting is based on the geolocations in your tenant as it accesses the SITs for each location to generate a report. We suggest running it for all geolocations and then using the correct input parameter to change location if need be. Our recommendation is to download via PowerShell Gallery because it has less steps and is hassle-free. Using the GitHub repo will need to be cloned & the module needs to load into PowerShell. We suggest this method for more advanced users and/or contributors who know have deeper experience with PowerShell.","title":"Best Practices"},{"location":"dag/mcca/#considerations","text":"The MCCA report can be generated in its entirety by users with Global Admin or Global Reader privileges. Other roles within the organization may not be able to run the tool or they may be able to run the tool with limited information in the final report.","title":"Considerations"},{"location":"dag/mcca/#helpful-resources","text":"Review the FAQ section for MCCA tool to answer a question you might have about making changes, reviewing reports, or what status indicates for each solution.","title":"Helpful Resources"},{"location":"dag/mig-rm/","text":"Last updated: 05/10/2021 What is information governance and why should you worry about governing your data? The technical definition that you can find on the web is usually one that a records manager or compliance risk officer may read and say sure, but for some of us we still leave wanting a level 100 explanation. At a basic level, the goal is to balance the risk holding onto information presents with the value the information provides to the organization. You also need to consider which decisions are within your control as a company and which are driven by regulatory or industry requirements. It is important to remember that this is a strategy across all your information. That strategy should define who has the authority to make information related decisions. These individuals will be heavily involved in your retention policy, label taxonomy and file plan discussions. It also needs to account for how you will handle change management for your policies governing information as well as communication of your plan and training your users. Your information governance strategy should also establish the \u201cwhat\u201d, the requirements or how long, before actions need to be taken to retain or delete information, the \u201chow\u201d, by the technologies that will be used. In our case, the retention polices, and labels deployed through Microsoft Information Governance and Records Management . Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Data Loss Prevention (DLP) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Azure Information Protection (AIP) Scanner Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) Microsoft Information Governance (MIG) and Records Management (RM) Communication Compliance Insider Risk Management Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle. Microsoft Information Governance and Records Management \u2693\ufe0e Microsoft Information Governance (MIG) provides capabilities to manage the lifecycle of your content and govern your data for compliance or regulatory requirements. Records management (RM) manages high-value content for legal, business, or regulatory obligations, and adds advanced capabilities such as disposition review and file plans. Some organizations may have simple retention and deletion requirements were applying broad policies using the MIG features will meet your needs. Other organizations may have strict recordkeeping requirements including a formal file plan, disposition, or retention trigged by events which can be accomplished using the RM features. Best Practices \u2693\ufe0e The information governance needs from one organization to the next can differ greatly. While one organization has one simple retention policy that emails must be kept for 3 years, another can exist in a highly regulated industry and therefore have multiple requirements they need to meet based on different types of data. The approach below aims to provide guidance on how to approach deployment of the features available through information governance and records management, whether you have those basic needs or the more complex capabilities we offer. Let\u2019s establish some of the preparation that goes into being ready to start the execution of deploying retention policies, labels, and using your file plan to manage your records. Make sure that you understand the functions available in MIG and RM and what your requirements are so they may be aligned to drive the configuration during deployment. That should drive the plan whether it is a formal File Plan to be used in RM or simply a retention schedule that will categorize your information into retention and deletion periods. That plan will drive the number of labels you may need and their settings as well as the retention and publishing policies. Below are some questions to drive the conversation during this planning period. Will the built-in role groups covered in the considerations section align to your access governance or will you need to create custom role groups? If granular control is needed you can use the Security and Compliance center to create your custom role groups. Do you need to apply retention and deletion to broad buckets, such as all Teams chats and conversations or all Exchange email mailboxes? This is a good use case for retention policies. Do you store documents that may have different retention requirements in the same location such as a document library in SharePoint? This is a good use case for retention labels because they can be applied at the item level. Do you require a disposition review process at the end of the retention period? There is an option to require disposition of content when creating a label from the File Plan in RM. Do you need to trigger retention or deletion based on an event, such as the end of a fiscal year or employment end date or the end of a contract? When creating a label from the File Plan in RM you can choose one of the built-in event types or choose to create your own. If you need to manage content as formal records or have even stricter requirements for immutability, look at the information about declaring records with retention labels . Develop a solid test plan that defines what your scenarios and successful test outcomes will be. We recommend testing in a lower environment first to validate outcomes with shorter time periods for both the basic and more advanced configurations. Determine how long it will take to test all your scenarios and what approvals are needed and the timing of those to work backwards to set a deployment timeline and what your milestones will be. Such as deploying a simple retention policy to all of Exchange or having your file plan ready for import into Records Management. Now that we have touched on the preparation for deployment, below we outline the deployment and configurations when creating retention policies, creating and publishing retention labels, as well as creating labels through the file plan in records management to require stricter controls and reviews. Retention Policies \u2693\ufe0e Retention policies are best suited when targeting a location or container of information. Those locations can be one of the following in the list below, however Teams and Yammer locations need their own policies and cannot be combined with the other locations. Exchange email SharePoint site OneDrive accounts Microsoft 365 groups Skype for Business Exchange public folders Teams channel messages Teams chats Yammer community messages Yammer private messages Creation and management of policies will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. It is a good idea to start with the basic scenarios before moving on to the more advanced ones to gain a comfort level with the process and ensure you get the desired outcomes. In each example there are 3 consistent steps of the policy creation outlined below. With the common steps established we will focus how each example differs during the creation of the policy. You will need to give your policy a name and description that is meaningful for your organization. Note this name cannot be changed. You will need to choose if you want to retain content, delete it, or both and whether that should be based on created or modified date. The last step is to review your settings and create the policy. Once your policy is created after service completes the mechanisms policy engine in the various environments (Exchange Online, SharePoint Online, OneDrive, Yammer, Teams, etc..) it will take affect without any additional steps. Our experience is this completes in 7 days or sooner. Start Simple \u2693\ufe0e Deployment of a basic policy that sets the same retention settings to apply to the entire location(s). This approach is very straightforward. After the steps to name your policy and set retention settings above, you will choose the locations you want this policy to apply to. A basic policy will usually target an entire location and does not have inclusions or exclusions set. You will ensure that the location is toggle On and set to All. Remember that Teams and Yammer cannot be combined with the other locations. Next Steps \u2693\ufe0e Next, we cover deploying a policy that has inclusions or exclusions based on a need to apply different retention periods to content in the same location types such as different mailbox users, or SharePoint sites as an example. Choose the locations you want this policy to apply to. In this scenario you will ensure the status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in this policy. You will be required to know and enter the full path for SharePoint or OneDrive locations. Refer to the considerations section for policy limitations in this scenario. Advanced \u2693\ufe0e An advanced retention policy configuration is more suited for those that have a need to apply it based on what is in the content to target specific documents, such as sensitive information. Choose to Use Advanced Retention Settings. You can now either apply to content based on sensitive information present in the item using one of the built-in or custom sensitive information types (SITs), or you can apply to content that contains specific words or phrases. The choice to use the advanced settings above is going to limit the locations that you have as options to Exchange, SharePoint, and OneDrive. It will also default the Exchange location to include All. This cannot be changed. Retention, Record, and Regulatory labels and policies \u2693\ufe0e When you have a need to retain and delete content at the item level, use a retention label. Retention labels also provide some other capabilities that retention policies do not. Retention labels travel with the content as it moves within your tenant. They allow you to start the retention based on when the item is labeled. You can start the retention based on when an event occurs. An item can be automatically labeled based on a trainable classifier. An item can be labeled automatically if it matches a keyword query you create. You can set a default label on SharePoint lists and libraries. A disposition review can be required before something is permanently deleted. Labels allow you to mark content as a record or regulatory record. As you can see retention labels provide greater flexibility for when the retention period starts, what happens when the retention period ends, how that label is applied, and what can be done with the content once it has been labeled. These options allow for both a basic deployment strategy and a more advanced one. Many of the more advanced options also require the use of the File Plan feature in RM to create the labels. We will start with the label and policy creation from within the MIG solution, and then move to those that require using RM and the File Plan feature to create the more advanced labels and policies. Information Governance \u2693\ufe0e Creating labels and policies in Information Governance will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. In each example below we will be referring to the same steps to create a label that applies the retention period based on when an item is labeled. Label creation steps: * You will give your label a name based on your taxonomy and enter descriptions for both admins and your users that is meaningful for your organization. Remember this name cannot be changed. Toggle the Retention on and then choose whether you want to retain content, delete it, or both. In this example unique to labels, we will choose to take those actions based on When The Content Is Labeled. You are free to choose when created or modified as well. Review your settings and create the label. The label will now need a policy to publish the label to be manually applied by users, or to automatically apply it to content. When creating a policy to publish or apply the label, you should start with a simple approach and then add complexity. All policy creation has common steps to name the policy and review your settings. Each example will differ based on the locations we publish the label to or how that label is applied to content. Policy name and review steps: Give the policy a name and description that is meaningful. Remember, this name cannot be changed. Review your settings and either click publish labels or auto-apply to save your settings depending on the scenario. It can take up to 7 days for labels to appear and only for those mailboxes that have 10MB of data or more as noted above in the considerations. Start Simple \u2693\ufe0e In the basic example we will be publishing our label to all users and locations for them to apply manually. This publishing policy is very straightforward. Simply choose the default to publish this policy to all locations in the Choose Locations page within the Publish to users and groups step. Next Steps \u2693\ufe0e You may also have a need to create a label that needs to be published to a specific set of users or locations due to a department\u2019s unique requirements. When we create the policy to publish the label, we will be specifying inclusions or exclusions. In this scenario instead of all in the Choose Locations page, you will choose specific locations by ensuring the Status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in the policy. Refer to the considerations section for policy limitations in this scenario. During preparation you identify that you have a need to proactively address content that may have sensitive information in it. To avoid relying on your users to consistently label this content with a publish policy, you can choose to Auto-apply A Label instead based on SITs which are contained in the same list of templates as when you create a data loss prevention (DLP) policy. Make sure Apply Label To Content That Contains Sensitive Info is selected and pick one of the built-in templates or choose custom to either specify individual (SITs) or your own custom SIT. The SITs will have default instance count and match accuracy settings. If you would like to view them to confirm or modify, you will need to use the Edit button. You can also choose whether you want this policy to apply to All locations or specific locations. Using specific inclusions or exclusions here will also have the same policy limitation considerations mentioned above. Advanced \u2693\ufe0e If your organization has a mature information architecture in SharePoint online, you may want to leverage that data to use the condition Apply Label To Content That Contains Specific Words Or Phrases, Or Properties. The query-based auto-apply policies use the same search index as eDiscovery content search which means you can use any of the pre-defined SharePoint online managed properties as your criteria which are documented in the helpful resources section. You may want to start with out of the box properties first such as filetype or modified by before targeting your custom properties that have been mapped to a managed property. Once you have your criteria take care to enter it into the Keyword Query Editor correctly as it will not tell you if your query has bad syntax or is invalid. We also recommend always including the (AND, OR) operators to ensure that your query is interpreted correctly if you are combing more than one condition. During your planning for deployment of not only the MIG or RM solutions, but also Microsoft Information Protection (MIP) and Communications Compliance (CC), you may have decided that our trainable classifiers capability adds a lot of value based on your data estate. If that is the case, then you can create a policy with the condition Apply Label To Content That Matches A Trainable Classifier. You can find more information on trainable classifiers in the creating one compliance story section. Even if you have not built your own custom trainable classifier you can choose a built-in one from the list such as Source Code or Resumes. Trainable classifiers can label new and modified items and existing items from the last six months. Records Management \u2693\ufe0e Some may consider the concept of records management intimidating. The thought of having to categorize all your data and get agreement from the business on how long each category of information needs to be retained or how soon it needs to go can be daunting. We believe that both those already well down the path of the records management journey and those just getting started can take advantage of the features we offer in our solution. Unlike the information governance examples above where the progression of basic to advanced configurations usually involve how the label is applied, in records management the real power is in the information the label can have and what happens when the label is applied. This next section will touch on those configuration examples by starting with using File plan tool and the options we have when creating a label. When following the guidance below make sure that you log into the compliance center with an account that has the necessary Records Management permissions which we discussed in the considerations section earlier. Start Simple (File Plan) \u2693\ufe0e During planning you should determine if you have an existing retention schedule. Even if you do not have an existing retention schedule or a file plan, you can start to build one by creating your labels from within File Plan. The creation of the label using File Plan is similar to the steps from Information Governance. However, using File Plan provides the ability to add descriptors to your label. Start by adding your descriptors to provide additional information about each label, such as the business department the label is for, or the provision or citation that drives the configuration settings of the label. As you build your labels out you will be able to export this list to a .csv file which will contain the settings as well as those descriptors. You can pick from a list of values or create your own. If you create your own make sure the spelling and format is correct as you will not be able to modify or remove it once you save your changes. Next Steps (File Plan) \u2693\ufe0e You can also use the File Plan import option or the Export mentioned above to create your labels from the .csv file. This could be an empty template before any labels are created, or after some initial labels have been created to provide examples. This file can be used for planning and execution. We find this is extremely helpful for customers who prefer to fill the template out and then create their labels in bulk to save time. This method can also be used to bulk-modify existing labels. Advanced (File Plan) \u2693\ufe0e Your organization may already have retention schedule in place which includes a formal file plan. If so, the File Plan import can be used to download a blank template to import that plan and create your labels. You will need to map your current file plan to the fields available in the template. Each field can only have 64 characters. There is a validation during the import and if there are errors it will provide the line and row numbers that are causing issues. Keep in mind this import will create the labels only and those labels will have no impact until you create a policy to publish or automatically apply those labels. When creating your labels from File Plan you will notice there are some differences in the experiences as you step through each of the screens. While the retention settings are the same as in Information governance, the way they are presented may differ. All the examples below drive what settings are chosen from the Define Retention Settings screen. For label creation instructions please follow the steps here . Start Simple (Label Deployment) \u2693\ufe0e We mentioned above with records management, the power is in the label, one example of that is the option to require disposition when creating your label. You may identify certain information that may have a similar duration of retention as other material, but you need someone to formally review those items before they are removed. This is where disposition comes into play. We are covering this under records management because that solution contains the Disposition tab where the reviewers will go to evaluate the content that has reached its retention end date. Disposition can be required by selecting Trigger A Disposition Review under the At The End Of The Retention Period section. When choosing this option, you will need to select the users that you want to perform the review of the content. We recommend selecting more than one user. Mail-enabled security groups are supported. Microsoft 365 groups are not. Specifying a user here will not add them to the Disposition Management role, which is the minimum permissions needed. Content in Exchange, SharePoint, OneDrive, and Microsoft 365 groups is only deleted after a reviewer chooses to permanently delete the content. There is no undo button in the disposition workflow once that selection is made. Disposition for Exchange content requires that the target mailbox has at least 10MB of data. A reviewer can only use the link in the location column to view the content if they have permissions to that location and the content. If you have a need for the owners of the content to participate in the disposition process you can export the list of items needing review to a .csv file. Next Steps (Label Deployment) \u2693\ufe0e Disposition of content is a common requirement when declaring an item as a record. If your organization has identified certain types of information that are considered a record, you can apply the additional protections by choosing Mark Items As A Record during label creation. When this option is selected and the label is applied to emails, users will not be able to edit or delete those emails. Versioning is still possible by unlocking a record. The previous version is still considered a record and cannot be modified or deleted. When content labeled as a record in a SharePoint site or OneDrive is unlocked, a special Records folder is created in the Preservation Hold Library (PHL). Site Collection Administrators can still remove a record label from an item. Take that into consideration when evaluating who has those rights on your SharePoint site collections. The removal of a label as well as the lock and unlocking of a record are all activities that you can search for and view in the Audit solution. If an item was marked as a record and required disposition you will be able to provide a proof of records deletion. Advanced (Label Deployment) \u2693\ufe0e A common scenario we see is that organizations have a need to consider certain artifacts a record, but only after a certain event occurs such as the end of a customer engagement. Other organizations do not necessarily have the record requirement but have a need to keep certain information for a specific amount of time only after an event, like when an employee leaves the company. This can be accomplished by selecting one of the built-in event types or creating your own under the Start The Retention Period Based On option. Using this approach does take some planning. It requires that the items that have this label applied have the AssetID (SharePoint and OneDrive) populated by the user when they apply the label, or in the case of Exchange, have a consistent set of Keywords present in the email. Your organization may have other unique properties that you already apply to the documents related to your event type. For example, you may have an engagement number or contract number required for these documents. This can be used in place of the ComplianceAssetID property as long as it is entered in property:value pair format in the AssetID area when you create an event. Content search can be used to find the content that meets these criteria to validate which items will have their retention triggered. Because the labels are associated with event types, and the events you create are what trigger the retention, it is important to understand that the keywords and Asset ID values specified are what uniquely identify which set of labeled items the system should trigger the retention period on. It is important to understand that if you do not specify an asset ID or keywords for an event, all content with a retention label of that event type will have its retention period triggered by the event. If you plan to use labels that will trigger based on events, we highly recommend you consider automating this process. For more information on event types and how to automate this process please read Start retention when an event occurs . There are certain regulations that require strict immutability when it come to the content. While our existing Record capabilities satisfy most of our customer\u2019s needs, we did heard feedback from our highly regulated customers that we need to provide even stricter controls. In response, we have recently introduced a new option under Define Retention Settings when creating a label in Records Management to Mark Items As A Regulatory Record. The restrictions put in place once applied block any modification to the content. Careful thought and consideration need to go into determining if this is truly needed. Once applied the only actions that are allowed are read, copy, and move within container. Reference this table for a full breakdown. Once a regulatory record is applied to content, not even a global administrator, can remove the label. Because of these restrictions and irreversible actions, the option to Mark Items as a regulatory record is not available by default. You will first have to run the commands outline in Declare records by using retention labels . Once available you will also receive a warning when selecting this option. A label that marks content as a regulatory record cannot be applied automatically to content. We also recommend a strong education campaign for those users you publish these labels to. While if you implement all the recommendations above you are set for a successful deployment of MIG and RM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Now that we have covered the different basic to advanced deployment scenarios and best practices, take a minute to make sure you read the rest of this guide to understand how retention and records management integrate with the other compliance solutions and how they complement each other. We also provide you with some important considerations to keep in mind when it comes to your environment and how they may affect your deployment. There are some helpful resources as well that will point you to other articles, blog posts, or videos that provide important context or supplement the documentation for MIG and RM. Considerations \u2693\ufe0e To manage retention policies and labels, you will need to be added to the Compliance Administrator role group or for more targeted permissions, a new or existing role group can be assigned the Retention Management role. You can also grant read-only rights through the View-Only Retention Management role which can be added to a new or existing role group. Those responsible for records management in the organization should be added to the Records Management role group or for a read-only role, add the View-Only Record Management role to a new or existing role group. Important, when creating retention policies and labels, ensure that you are confident in your naming taxonomy. Once you create a policy or label it cannot be renamed. Only one retention label can be applied to content at any given time. If an item already has a label applied, automated labeling policies will not replace the existing label on the item. When creating a retention label or policy, be aware there is not a test mode or simulation mode as there is when creating a new MIP sensitivity label. Retention labels will only be available for users in Outlook client and Outlook web if their mailboxes have at least 10MB of data in them. Retention policies do not support list items, if you have a need to apply retention to items within lists you must use retention labels. Retention policies with specific inclusions or exclusions are subject to limits which you should be aware of. If you configure a retention policy with specific includes and then remove the last one, the configuration reverts to All for the location. Make sure this is the configuration that you intend before you save the policy. When considering applying retention or deletion policies to Teams channel messages, it is important to remember that private channel conversations are not included. Reactions to Teams messages are also not included. To retain content associated with a Team created from a Microsoft 365 group that is stored in the respective SharePoint site, a separate policy must also be applied to the related Microsoft 365 Group location. To retain email messages for Yammer you will also need a retention policy that applies to the Microsoft 365 groups location. You will also need a policy that targets the related SharePoint site or users OneDrive locations to retain the files shared in Yammer messages. When using retention policies for SharePoint sites, the settings do not apply to organization structures, system lists, or other items used to manage the system. Yammer items are retained and deleted for community messages and private messages but not reaction emoticons. Data Connectors can allow for the archival of third-party data which is stored in a users\u2019 Exchange Online mailbox and can have retention and records management applied to that data. (more here) Helpful Resources \u2693\ufe0e This list of retention policy and retention label capabilities can help you determine whether to use a retention policy or retention label to meet your requirements. It is important to understand the content that can be stored in an Exchange Online mailbox and the impact a retention policy applied to a mailbox may have on that data. It is also important to note that not all data will be preserved when a policy is applied at the mailbox level, such as Teams or Skype data. Those require their own policy specific to that workload. When content in an Exchange Online (EXO) mailbox is modified in some way and there is a retention policy targeting that mailbox or a label applied to the email, the original item is stored in a special location called the Recoverable Items folder for the mailbox. Where it is goes depends on the action taken and that is why we encourage you to have a good understanding of how the Recoverable items folder in Exchange Online works. This list of Third-party data connectors provides a table which indicates which third-party data can have retention and records management applied to it. SharePoint Online also has a special location to store items subject to retention called the Preservation Hold Library. There are also a 1st stage and 2nd stage recycle bin that come into play. To learn more about what happens to an item that someone deletes or reaches the end of its retention or deletion period, read Lifecycle of an item in SharePoint: Where does it go ? In the scenario where more than one retention policy and label may be applied to content, it is important to understand the principles of retention to gain insight into the outcome. Read U se retention labels to manage document lifecycles to understand how to leverage SharePoint information architecture to automatically apply retention labels to content. When targeting SharePoint locations for auto-apply labels, only the pre-defined managed properties are supported in the KQL query. See the list of crawled and managed properties in SharePoint server . Now that you can Use OneDrive for Business and SharePoint for Teams meeting recordings we have added support for you to use our automatic labeling capabilities to apply retention periods or immutability to those files. Read our online documentation for instructions regarding those recordings. You can use the steps for import retention labels into your file plan to guide you on how to map your existing retention schedule to the template to import into our Records Management solution. For a deeper understanding of the new Regulatory Record label for records management you can check out this video . While this guide focuses on the administrator activities for deployment, it is important to also train your end users to drive adoption. Use End User Training for Retention Labels in M365 as a good starting point.","title":"Data Lifecycle Management and Records Management"},{"location":"dag/mig-rm/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Data Loss Prevention (DLP) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) Azure Information Protection (AIP) Scanner Microsoft Cloud App Security (MCAS) Microsoft Information Protection (MIP) Microsoft Information Governance (MIG) and Records Management (RM) Communication Compliance Insider Risk Management Advanced eDiscovery Advanced Audit The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while governing your data by deciding what to keep, what to delete, what is a regulatory requirement, and using a workflow to manage the lifecycle.","title":"Your Deployment Plan"},{"location":"dag/mig-rm/#microsoft-information-governance-and-records-management","text":"Microsoft Information Governance (MIG) provides capabilities to manage the lifecycle of your content and govern your data for compliance or regulatory requirements. Records management (RM) manages high-value content for legal, business, or regulatory obligations, and adds advanced capabilities such as disposition review and file plans. Some organizations may have simple retention and deletion requirements were applying broad policies using the MIG features will meet your needs. Other organizations may have strict recordkeeping requirements including a formal file plan, disposition, or retention trigged by events which can be accomplished using the RM features.","title":"Microsoft Information Governance and Records Management"},{"location":"dag/mig-rm/#best-practices","text":"The information governance needs from one organization to the next can differ greatly. While one organization has one simple retention policy that emails must be kept for 3 years, another can exist in a highly regulated industry and therefore have multiple requirements they need to meet based on different types of data. The approach below aims to provide guidance on how to approach deployment of the features available through information governance and records management, whether you have those basic needs or the more complex capabilities we offer. Let\u2019s establish some of the preparation that goes into being ready to start the execution of deploying retention policies, labels, and using your file plan to manage your records. Make sure that you understand the functions available in MIG and RM and what your requirements are so they may be aligned to drive the configuration during deployment. That should drive the plan whether it is a formal File Plan to be used in RM or simply a retention schedule that will categorize your information into retention and deletion periods. That plan will drive the number of labels you may need and their settings as well as the retention and publishing policies. Below are some questions to drive the conversation during this planning period. Will the built-in role groups covered in the considerations section align to your access governance or will you need to create custom role groups? If granular control is needed you can use the Security and Compliance center to create your custom role groups. Do you need to apply retention and deletion to broad buckets, such as all Teams chats and conversations or all Exchange email mailboxes? This is a good use case for retention policies. Do you store documents that may have different retention requirements in the same location such as a document library in SharePoint? This is a good use case for retention labels because they can be applied at the item level. Do you require a disposition review process at the end of the retention period? There is an option to require disposition of content when creating a label from the File Plan in RM. Do you need to trigger retention or deletion based on an event, such as the end of a fiscal year or employment end date or the end of a contract? When creating a label from the File Plan in RM you can choose one of the built-in event types or choose to create your own. If you need to manage content as formal records or have even stricter requirements for immutability, look at the information about declaring records with retention labels . Develop a solid test plan that defines what your scenarios and successful test outcomes will be. We recommend testing in a lower environment first to validate outcomes with shorter time periods for both the basic and more advanced configurations. Determine how long it will take to test all your scenarios and what approvals are needed and the timing of those to work backwards to set a deployment timeline and what your milestones will be. Such as deploying a simple retention policy to all of Exchange or having your file plan ready for import into Records Management. Now that we have touched on the preparation for deployment, below we outline the deployment and configurations when creating retention policies, creating and publishing retention labels, as well as creating labels through the file plan in records management to require stricter controls and reviews.","title":"Best Practices"},{"location":"dag/mig-rm/#retention-policies","text":"Retention policies are best suited when targeting a location or container of information. Those locations can be one of the following in the list below, however Teams and Yammer locations need their own policies and cannot be combined with the other locations. Exchange email SharePoint site OneDrive accounts Microsoft 365 groups Skype for Business Exchange public folders Teams channel messages Teams chats Yammer community messages Yammer private messages Creation and management of policies will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. It is a good idea to start with the basic scenarios before moving on to the more advanced ones to gain a comfort level with the process and ensure you get the desired outcomes. In each example there are 3 consistent steps of the policy creation outlined below. With the common steps established we will focus how each example differs during the creation of the policy. You will need to give your policy a name and description that is meaningful for your organization. Note this name cannot be changed. You will need to choose if you want to retain content, delete it, or both and whether that should be based on created or modified date. The last step is to review your settings and create the policy. Once your policy is created after service completes the mechanisms policy engine in the various environments (Exchange Online, SharePoint Online, OneDrive, Yammer, Teams, etc..) it will take affect without any additional steps. Our experience is this completes in 7 days or sooner.","title":"Retention Policies"},{"location":"dag/mig-rm/#start-simple","text":"Deployment of a basic policy that sets the same retention settings to apply to the entire location(s). This approach is very straightforward. After the steps to name your policy and set retention settings above, you will choose the locations you want this policy to apply to. A basic policy will usually target an entire location and does not have inclusions or exclusions set. You will ensure that the location is toggle On and set to All. Remember that Teams and Yammer cannot be combined with the other locations.","title":"Start Simple"},{"location":"dag/mig-rm/#next-steps","text":"Next, we cover deploying a policy that has inclusions or exclusions based on a need to apply different retention periods to content in the same location types such as different mailbox users, or SharePoint sites as an example. Choose the locations you want this policy to apply to. In this scenario you will ensure the status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in this policy. You will be required to know and enter the full path for SharePoint or OneDrive locations. Refer to the considerations section for policy limitations in this scenario.","title":"Next Steps"},{"location":"dag/mig-rm/#advanced","text":"An advanced retention policy configuration is more suited for those that have a need to apply it based on what is in the content to target specific documents, such as sensitive information. Choose to Use Advanced Retention Settings. You can now either apply to content based on sensitive information present in the item using one of the built-in or custom sensitive information types (SITs), or you can apply to content that contains specific words or phrases. The choice to use the advanced settings above is going to limit the locations that you have as options to Exchange, SharePoint, and OneDrive. It will also default the Exchange location to include All. This cannot be changed.","title":"Advanced"},{"location":"dag/mig-rm/#retention-record-and-regulatory-labels-and-policies","text":"When you have a need to retain and delete content at the item level, use a retention label. Retention labels also provide some other capabilities that retention policies do not. Retention labels travel with the content as it moves within your tenant. They allow you to start the retention based on when the item is labeled. You can start the retention based on when an event occurs. An item can be automatically labeled based on a trainable classifier. An item can be labeled automatically if it matches a keyword query you create. You can set a default label on SharePoint lists and libraries. A disposition review can be required before something is permanently deleted. Labels allow you to mark content as a record or regulatory record. As you can see retention labels provide greater flexibility for when the retention period starts, what happens when the retention period ends, how that label is applied, and what can be done with the content once it has been labeled. These options allow for both a basic deployment strategy and a more advanced one. Many of the more advanced options also require the use of the File Plan feature in RM to create the labels. We will start with the label and policy creation from within the MIG solution, and then move to those that require using RM and the File Plan feature to create the more advanced labels and policies.","title":"Retention, Record, and Regulatory labels and policies"},{"location":"dag/mig-rm/#information-governance","text":"Creating labels and policies in Information Governance will require that you log into the compliance center with an account that has the necessary Retention Management permissions which we discussed in the considerations section earlier. In each example below we will be referring to the same steps to create a label that applies the retention period based on when an item is labeled. Label creation steps: * You will give your label a name based on your taxonomy and enter descriptions for both admins and your users that is meaningful for your organization. Remember this name cannot be changed. Toggle the Retention on and then choose whether you want to retain content, delete it, or both. In this example unique to labels, we will choose to take those actions based on When The Content Is Labeled. You are free to choose when created or modified as well. Review your settings and create the label. The label will now need a policy to publish the label to be manually applied by users, or to automatically apply it to content. When creating a policy to publish or apply the label, you should start with a simple approach and then add complexity. All policy creation has common steps to name the policy and review your settings. Each example will differ based on the locations we publish the label to or how that label is applied to content. Policy name and review steps: Give the policy a name and description that is meaningful. Remember, this name cannot be changed. Review your settings and either click publish labels or auto-apply to save your settings depending on the scenario. It can take up to 7 days for labels to appear and only for those mailboxes that have 10MB of data or more as noted above in the considerations.","title":"Information Governance"},{"location":"dag/mig-rm/#start-simple_1","text":"In the basic example we will be publishing our label to all users and locations for them to apply manually. This publishing policy is very straightforward. Simply choose the default to publish this policy to all locations in the Choose Locations page within the Publish to users and groups step.","title":"Start Simple"},{"location":"dag/mig-rm/#next-steps_1","text":"You may also have a need to create a label that needs to be published to a specific set of users or locations due to a department\u2019s unique requirements. When we create the policy to publish the label, we will be specifying inclusions or exclusions. In this scenario instead of all in the Choose Locations page, you will choose specific locations by ensuring the Status of the location is toggled On and then use the links to select specific recipients, sites, etc. to include or exclude in the policy. Refer to the considerations section for policy limitations in this scenario. During preparation you identify that you have a need to proactively address content that may have sensitive information in it. To avoid relying on your users to consistently label this content with a publish policy, you can choose to Auto-apply A Label instead based on SITs which are contained in the same list of templates as when you create a data loss prevention (DLP) policy. Make sure Apply Label To Content That Contains Sensitive Info is selected and pick one of the built-in templates or choose custom to either specify individual (SITs) or your own custom SIT. The SITs will have default instance count and match accuracy settings. If you would like to view them to confirm or modify, you will need to use the Edit button. You can also choose whether you want this policy to apply to All locations or specific locations. Using specific inclusions or exclusions here will also have the same policy limitation considerations mentioned above.","title":"Next Steps"},{"location":"dag/mig-rm/#advanced_1","text":"If your organization has a mature information architecture in SharePoint online, you may want to leverage that data to use the condition Apply Label To Content That Contains Specific Words Or Phrases, Or Properties. The query-based auto-apply policies use the same search index as eDiscovery content search which means you can use any of the pre-defined SharePoint online managed properties as your criteria which are documented in the helpful resources section. You may want to start with out of the box properties first such as filetype or modified by before targeting your custom properties that have been mapped to a managed property. Once you have your criteria take care to enter it into the Keyword Query Editor correctly as it will not tell you if your query has bad syntax or is invalid. We also recommend always including the (AND, OR) operators to ensure that your query is interpreted correctly if you are combing more than one condition. During your planning for deployment of not only the MIG or RM solutions, but also Microsoft Information Protection (MIP) and Communications Compliance (CC), you may have decided that our trainable classifiers capability adds a lot of value based on your data estate. If that is the case, then you can create a policy with the condition Apply Label To Content That Matches A Trainable Classifier. You can find more information on trainable classifiers in the creating one compliance story section. Even if you have not built your own custom trainable classifier you can choose a built-in one from the list such as Source Code or Resumes. Trainable classifiers can label new and modified items and existing items from the last six months.","title":"Advanced"},{"location":"dag/mig-rm/#records-management","text":"Some may consider the concept of records management intimidating. The thought of having to categorize all your data and get agreement from the business on how long each category of information needs to be retained or how soon it needs to go can be daunting. We believe that both those already well down the path of the records management journey and those just getting started can take advantage of the features we offer in our solution. Unlike the information governance examples above where the progression of basic to advanced configurations usually involve how the label is applied, in records management the real power is in the information the label can have and what happens when the label is applied. This next section will touch on those configuration examples by starting with using File plan tool and the options we have when creating a label. When following the guidance below make sure that you log into the compliance center with an account that has the necessary Records Management permissions which we discussed in the considerations section earlier.","title":"Records Management"},{"location":"dag/mig-rm/#start-simple-file-plan","text":"During planning you should determine if you have an existing retention schedule. Even if you do not have an existing retention schedule or a file plan, you can start to build one by creating your labels from within File Plan. The creation of the label using File Plan is similar to the steps from Information Governance. However, using File Plan provides the ability to add descriptors to your label. Start by adding your descriptors to provide additional information about each label, such as the business department the label is for, or the provision or citation that drives the configuration settings of the label. As you build your labels out you will be able to export this list to a .csv file which will contain the settings as well as those descriptors. You can pick from a list of values or create your own. If you create your own make sure the spelling and format is correct as you will not be able to modify or remove it once you save your changes.","title":"Start Simple (File Plan)"},{"location":"dag/mig-rm/#next-steps-file-plan","text":"You can also use the File Plan import option or the Export mentioned above to create your labels from the .csv file. This could be an empty template before any labels are created, or after some initial labels have been created to provide examples. This file can be used for planning and execution. We find this is extremely helpful for customers who prefer to fill the template out and then create their labels in bulk to save time. This method can also be used to bulk-modify existing labels.","title":"Next Steps (File Plan)"},{"location":"dag/mig-rm/#advanced-file-plan","text":"Your organization may already have retention schedule in place which includes a formal file plan. If so, the File Plan import can be used to download a blank template to import that plan and create your labels. You will need to map your current file plan to the fields available in the template. Each field can only have 64 characters. There is a validation during the import and if there are errors it will provide the line and row numbers that are causing issues. Keep in mind this import will create the labels only and those labels will have no impact until you create a policy to publish or automatically apply those labels. When creating your labels from File Plan you will notice there are some differences in the experiences as you step through each of the screens. While the retention settings are the same as in Information governance, the way they are presented may differ. All the examples below drive what settings are chosen from the Define Retention Settings screen. For label creation instructions please follow the steps here .","title":"Advanced (File Plan)"},{"location":"dag/mig-rm/#start-simple-label-deployment","text":"We mentioned above with records management, the power is in the label, one example of that is the option to require disposition when creating your label. You may identify certain information that may have a similar duration of retention as other material, but you need someone to formally review those items before they are removed. This is where disposition comes into play. We are covering this under records management because that solution contains the Disposition tab where the reviewers will go to evaluate the content that has reached its retention end date. Disposition can be required by selecting Trigger A Disposition Review under the At The End Of The Retention Period section. When choosing this option, you will need to select the users that you want to perform the review of the content. We recommend selecting more than one user. Mail-enabled security groups are supported. Microsoft 365 groups are not. Specifying a user here will not add them to the Disposition Management role, which is the minimum permissions needed. Content in Exchange, SharePoint, OneDrive, and Microsoft 365 groups is only deleted after a reviewer chooses to permanently delete the content. There is no undo button in the disposition workflow once that selection is made. Disposition for Exchange content requires that the target mailbox has at least 10MB of data. A reviewer can only use the link in the location column to view the content if they have permissions to that location and the content. If you have a need for the owners of the content to participate in the disposition process you can export the list of items needing review to a .csv file.","title":"Start Simple (Label Deployment)"},{"location":"dag/mig-rm/#next-steps-label-deployment","text":"Disposition of content is a common requirement when declaring an item as a record. If your organization has identified certain types of information that are considered a record, you can apply the additional protections by choosing Mark Items As A Record during label creation. When this option is selected and the label is applied to emails, users will not be able to edit or delete those emails. Versioning is still possible by unlocking a record. The previous version is still considered a record and cannot be modified or deleted. When content labeled as a record in a SharePoint site or OneDrive is unlocked, a special Records folder is created in the Preservation Hold Library (PHL). Site Collection Administrators can still remove a record label from an item. Take that into consideration when evaluating who has those rights on your SharePoint site collections. The removal of a label as well as the lock and unlocking of a record are all activities that you can search for and view in the Audit solution. If an item was marked as a record and required disposition you will be able to provide a proof of records deletion.","title":"Next Steps (Label Deployment)"},{"location":"dag/mig-rm/#advanced-label-deployment","text":"A common scenario we see is that organizations have a need to consider certain artifacts a record, but only after a certain event occurs such as the end of a customer engagement. Other organizations do not necessarily have the record requirement but have a need to keep certain information for a specific amount of time only after an event, like when an employee leaves the company. This can be accomplished by selecting one of the built-in event types or creating your own under the Start The Retention Period Based On option. Using this approach does take some planning. It requires that the items that have this label applied have the AssetID (SharePoint and OneDrive) populated by the user when they apply the label, or in the case of Exchange, have a consistent set of Keywords present in the email. Your organization may have other unique properties that you already apply to the documents related to your event type. For example, you may have an engagement number or contract number required for these documents. This can be used in place of the ComplianceAssetID property as long as it is entered in property:value pair format in the AssetID area when you create an event. Content search can be used to find the content that meets these criteria to validate which items will have their retention triggered. Because the labels are associated with event types, and the events you create are what trigger the retention, it is important to understand that the keywords and Asset ID values specified are what uniquely identify which set of labeled items the system should trigger the retention period on. It is important to understand that if you do not specify an asset ID or keywords for an event, all content with a retention label of that event type will have its retention period triggered by the event. If you plan to use labels that will trigger based on events, we highly recommend you consider automating this process. For more information on event types and how to automate this process please read Start retention when an event occurs . There are certain regulations that require strict immutability when it come to the content. While our existing Record capabilities satisfy most of our customer\u2019s needs, we did heard feedback from our highly regulated customers that we need to provide even stricter controls. In response, we have recently introduced a new option under Define Retention Settings when creating a label in Records Management to Mark Items As A Regulatory Record. The restrictions put in place once applied block any modification to the content. Careful thought and consideration need to go into determining if this is truly needed. Once applied the only actions that are allowed are read, copy, and move within container. Reference this table for a full breakdown. Once a regulatory record is applied to content, not even a global administrator, can remove the label. Because of these restrictions and irreversible actions, the option to Mark Items as a regulatory record is not available by default. You will first have to run the commands outline in Declare records by using retention labels . Once available you will also receive a warning when selecting this option. A label that marks content as a regulatory record cannot be applied automatically to content. We also recommend a strong education campaign for those users you publish these labels to. While if you implement all the recommendations above you are set for a successful deployment of MIG and RM, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Now that we have covered the different basic to advanced deployment scenarios and best practices, take a minute to make sure you read the rest of this guide to understand how retention and records management integrate with the other compliance solutions and how they complement each other. We also provide you with some important considerations to keep in mind when it comes to your environment and how they may affect your deployment. There are some helpful resources as well that will point you to other articles, blog posts, or videos that provide important context or supplement the documentation for MIG and RM.","title":"Advanced (Label Deployment)"},{"location":"dag/mig-rm/#considerations","text":"To manage retention policies and labels, you will need to be added to the Compliance Administrator role group or for more targeted permissions, a new or existing role group can be assigned the Retention Management role. You can also grant read-only rights through the View-Only Retention Management role which can be added to a new or existing role group. Those responsible for records management in the organization should be added to the Records Management role group or for a read-only role, add the View-Only Record Management role to a new or existing role group. Important, when creating retention policies and labels, ensure that you are confident in your naming taxonomy. Once you create a policy or label it cannot be renamed. Only one retention label can be applied to content at any given time. If an item already has a label applied, automated labeling policies will not replace the existing label on the item. When creating a retention label or policy, be aware there is not a test mode or simulation mode as there is when creating a new MIP sensitivity label. Retention labels will only be available for users in Outlook client and Outlook web if their mailboxes have at least 10MB of data in them. Retention policies do not support list items, if you have a need to apply retention to items within lists you must use retention labels. Retention policies with specific inclusions or exclusions are subject to limits which you should be aware of. If you configure a retention policy with specific includes and then remove the last one, the configuration reverts to All for the location. Make sure this is the configuration that you intend before you save the policy. When considering applying retention or deletion policies to Teams channel messages, it is important to remember that private channel conversations are not included. Reactions to Teams messages are also not included. To retain content associated with a Team created from a Microsoft 365 group that is stored in the respective SharePoint site, a separate policy must also be applied to the related Microsoft 365 Group location. To retain email messages for Yammer you will also need a retention policy that applies to the Microsoft 365 groups location. You will also need a policy that targets the related SharePoint site or users OneDrive locations to retain the files shared in Yammer messages. When using retention policies for SharePoint sites, the settings do not apply to organization structures, system lists, or other items used to manage the system. Yammer items are retained and deleted for community messages and private messages but not reaction emoticons. Data Connectors can allow for the archival of third-party data which is stored in a users\u2019 Exchange Online mailbox and can have retention and records management applied to that data. (more here)","title":"Considerations"},{"location":"dag/mig-rm/#helpful-resources","text":"This list of retention policy and retention label capabilities can help you determine whether to use a retention policy or retention label to meet your requirements. It is important to understand the content that can be stored in an Exchange Online mailbox and the impact a retention policy applied to a mailbox may have on that data. It is also important to note that not all data will be preserved when a policy is applied at the mailbox level, such as Teams or Skype data. Those require their own policy specific to that workload. When content in an Exchange Online (EXO) mailbox is modified in some way and there is a retention policy targeting that mailbox or a label applied to the email, the original item is stored in a special location called the Recoverable Items folder for the mailbox. Where it is goes depends on the action taken and that is why we encourage you to have a good understanding of how the Recoverable items folder in Exchange Online works. This list of Third-party data connectors provides a table which indicates which third-party data can have retention and records management applied to it. SharePoint Online also has a special location to store items subject to retention called the Preservation Hold Library. There are also a 1st stage and 2nd stage recycle bin that come into play. To learn more about what happens to an item that someone deletes or reaches the end of its retention or deletion period, read Lifecycle of an item in SharePoint: Where does it go ? In the scenario where more than one retention policy and label may be applied to content, it is important to understand the principles of retention to gain insight into the outcome. Read U se retention labels to manage document lifecycles to understand how to leverage SharePoint information architecture to automatically apply retention labels to content. When targeting SharePoint locations for auto-apply labels, only the pre-defined managed properties are supported in the KQL query. See the list of crawled and managed properties in SharePoint server . Now that you can Use OneDrive for Business and SharePoint for Teams meeting recordings we have added support for you to use our automatic labeling capabilities to apply retention periods or immutability to those files. Read our online documentation for instructions regarding those recordings. You can use the steps for import retention labels into your file plan to guide you on how to map your existing retention schedule to the template to import into our Records Management solution. For a deeper understanding of the new Regulatory Record label for records management you can check out this video . While this guide focuses on the administrator activities for deployment, it is important to also train your end users to drive adoption. Use End User Training for Retention Labels in M365 as a good starting point.","title":"Helpful Resources"},{"location":"dag/mip-dlp/","text":"Last updated: 05/10/2021 With information protection and sensitivity labels, you can intelligently classify and help protect your sensitive content, while making sure that your organization's productivity and ability to collaborate is not hindered. Combined with data loss prevention you can help prevent the accidental oversharing of the sensitive information in your organization. With this in mind, let\u2019s get started with understanding the capabilities which are available as part of Microsoft Information Protection (MIP) , how you discover sensitive information and protect it using the various provided tools provided by MIP and Data Loss Prevention (DLP) Your Deployment Plan \u2693\ufe0e The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Microsoft Information Protection (MIP) Data Loss Prevention (DLP) Microsoft Defender for Cloud Apps (MDCA) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe. Microsoft Information Protection \u2693\ufe0e Implement Microsoft Information Protection (MIP) to help you discover, classify, and protect sensitive information wherever it lives or travels. Contrary to popular opinion, MIP is not a single product but rather a suite of technologies supported by many aspects of the Microsoft 365 ecosystem. MIP capabilities are included with Microsoft 365 Compliance and give you the tools to know your data, protect your data, and prevent data loss. The main capabilities associated with MIP are as follows: Sensitive information types (SITs) Trainable Classifiers Data Classification Sensitivity Labels Azure Information Protection (AIP) unified labeling client Azure Information Protection (AIP) unified labeling Scanner Azure Purview Double Key Encryption (DKE) Office 365 Message Encryption (OME) Service encryption with Customer Key SharePoint Information Rights Management (IRM) Rights Management connector Microsoft Defender for Cloud Apps (MDCA) Microsoft Information Protection (MIP) SDK Data Loss Prevention (DLP) Learn more about MIP basics here . With MIP and a Sensitivity labels policy you can: Deploy your classification taxonomy to the company end user employees and give them the ability to apply these labels to documents and emails. Labels can also be applied automatically or in a recommended way based on sensitive information stored in the document or email. Leverage the applied sensitivity labels as a condition for data loss prevention use cases. Mark the document or email sensitivity with a header, footer and/or watermark. This will make the data sensitivity visible to anyone who consumes the document, within an app, via the web or as a hard copy. Apply sensitivity labels for SharePoint online, Teams sites and groups, providing another layer of control on the container level access within managed or un-managed devices, if it should be set for Public or Private access and/or external access. With encryption you can control who can consume content (for example: only company employees + approved partners) and what permissions he or she has (for example: Read but Do Not Print or Edit). Best Practices \u2693\ufe0e Defining the right label taxonomy and protection policies is the most critical step in a Microsoft Information Protection deployment. Labels will be the interface for users to understand content sensitivity, how it matches company policies, and will be the primary input for users to flag content that needs to be protected. A good label taxonomy needs to meet business and/or regulatory needs, be intuitively understandable by users, provide good policy tips and be easy to use. It should not prevent users from doing their jobs, while at the same time help prevent instances of data leakage or misuse and address compliance requirements. With these requirements in mind, the following best practices have proven to make deployment of information protection policies in many organizations easier, faster, and more successful. Prior to Deployment Plan \u2693\ufe0e Discover your sensitive information in your existing repositories. This is the first step we recommend as part of our best practice approach to detect the data you own and be ready to configure it as part of your sensitivity label configurations as well as data loss prevention policies later in this guide. Microsoft 365 cloud: Use Content Explorer in Microsoft 365 compliance center to discover data stored in Microsoft 365 (SharePoint, OneDrive), read more about it here . Non-Microsoft cloud repositories: Use Microsoft Defender for Cloud Apps to connect non-Microsoft applications and discover sensitive information beyond the Microsoft 365 services. Read more about it here . On-premises repositories: Use Azure Information Protection Scanner to discover data stored in your on-premises file shares, read more about it here . Azure resources: Use Azure Purview to identify sensitive information stored in Azure Repositories, read more about it here . Consider the methods in which users will interact with MIP labels and how you intend to implement this: Interactively within Microsoft 365 Apps via the Sensitivity Button. Read more about it in the \u201cMIP Client Consideration\u201d section. Natively for macOS, iOS and Android Native labeling vs AIP Client Container labeling for SharePoint Sites, Teams and Office 365 Groups Public vs Private access Unmanaged device access Sharing levels PowerBI Dashboards and PBIX assets Use label names for your labels that intuitively resonate with your users. Using company jargon that is well ingrained in the employee\u2019s culture is a valid approach, though care must be taken to ensure the labels are also meaningful to new employees. For example, using acronyms in label names is not ideal due to the opacity to new employees and the difficulty of visually recognizing them. Using short, meaningful words such as \u201cConfidential\u201d or \u201cSecret\u201d generally works best. Consider label order. Labels are sorted from lowest sensitivity to highest sensitivity, which means higher sensitivity labels represent an \u201cupgrade\u201d in the confidentiality of the information and usually have stronger protection measures. This order can be enforced by preventing users from downgrading sensitivity of a document unless they have the right privileges, and there are multiple scenarios in which it is important that the order of the labels is clear. It is important that the names you use reflect this order, ad you should avoid using terms that have no clear hierarchy. For example, not all users might agree on whether \u201cConfidential\u201d or \u201cSecret\u201d is the most sensitive label, so using something like \u201cConfidential\u201d vs. \u201cHighly confidential\u201d may be preferable. Use sublabels with intent. Labels are generally used to represent the actual sensitivity of the content that is labeled, while sublabels are typically used to represent variations in the protection or the scope of the content. For example, you might have a label taxonomy that includes \u201cGeneral Business\u201d, \u201cConfidential\u201d and \u201cHighly Confidential\u201d as top-level labels. Sublabels such as \u201cInternal\u201d or \u201cExternal\u201d designate specific types of data in some of those top-level categories that need to be controlled in specific ways. You might also have project/team specific sublabels or sublabels to address special requirements such as excluding the application of content markings for content that should not be modified. Keep it simple with no more than five top level labels and five sublabels. User experience research shows that with five or fewer labels, users can target the desired label directly in a single movement, whereas if there are more elements in the list the user will typically have to read through them each time, making mistakes more likely. The 5x5 approach is proven to keep things simple and help users choose the right labels, but if you can keep labels below those numbers, even better. Define labels that will last a long time. Since labels often become part of a company\u2019s culture and language, it is critical that they are not frequently altered, especially when it comes to the names and meanings of the top-level labels. The approach mentioned in the previous point makes this easy: using top-level labels to represent the sensitivity of the document means they will not change often. Sublabels, on the other hand, can be more dynamic, and while it is preferable to frame them in a way that follows a clear pattern that rarely changes, adding or changing sublabels as additional requirements such as new projects or divisions come up is usually not a problem if you follow a consistent pattern. Do not put sensitive information in a label\u2019s name or description. This might sound obvious, but it is common that IT departments are asked to create a label to protect information for a merger or acquisition or a label for a secret project that is not known to the general population in the company. Putting the name of the company or a word that reveals more about the project than what is public in the name of the label can reveal such data to all users, even if the label is scoped to a small team. While scoped labels are not made available to all users, metadata about the existence of such labels is carried within the policies all users get, so it is important that codenames or other non-disclosing keywords are used in such labels instead. Plan your auto-labeling strategy, MIP provide both Service and Client based auto-labeling for different use cases: Service-side auto labeling policies should be used for data at rest in SharePoint Online and OneDrive for Business and data in transit for Exchange Online when specific SITs need to be detected and labels applied automatically. This can be especially helpful when the data source is not controlled and might be that data is stored or sent without being labeled by the client solution. Also, it\u2019s a great option to label data that is already stored in SharePoint Online and OneDrive for Business. Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that is configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). This method supports recommending a label to a user, as well as automatically applying a label. But in both cases, the user decides whether to accept or reject the label, to help ensure the correct labeling of content. This client-side labeling has minimal delay for documents because the label can be applied even before the document is saved. However, not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office. If your organization operates in multiple languages, work with your localization teams to ensure the names chosen for the labels can be easily localized and are meaningful in all the required languages. Consider words that have a clear meaning in one language might be harder to localize or be ambiguous when translated. Examples of such words are \u201cPublic\u201d which can have nuanced meanings in some languages, and \u201cPersonal\u201d which can be easily confused in meaning to refer to private information. Consider the impact on usability. Forcing users to select labels too frequently can lead to users doing it reflexively without thinking about the label they should apply. Using a predefined default label is good practice in scenarios where manually labeling everything could be a burden - and where there is some \u201csafe\u201d sensitivity level that applies to most content. One such case is email, where for most users in most organizations labeling emails as \u201cInternal\u201d by default should be a safe option and reduce user effort considerably. Users can label emails as \u201cexternal\u201d, \u201cpublic\u201d or \u201cconfidential\u201d as needed. At the same time, most users do not create dozens of new documents per day, so asking them to individually label each document without providing a default is an acceptable requirement in most cases. MIP allows you to do this by using a different default label for emails and documents using the advanced option named \u201cOutlookDefaultLabel\u201d that specifies a default label for Outlook independently from what is set for documents. Compartmentalize data sparingly. Compartmentalization of data is essential in many businesses and using scoped sublabels that are shown and give rights to people in specific departments is a good practice, but you should use this capability in moderation. If you have a dozen critical projects that need to contain their data from being accessed by the general population of employees, creating sublabels specifically for them is beneficial. But if you have a thousand projects that demand the same treatment, the administrative burden imposed by such label taxonomy would be large and you will likely end up hitting a practical limit. The best practice is to define a clear rule for which kinds of teams, projects, divisions, or groups get their own sublabels which ensures only a small number of sublabels need to be created (a few dozen) - and stick with it. Consider what threats you are trying to prevent \u2013 not what users will be doing with the content. When defining protection policies some organizations start by thinking about what users need to do with their content, and define rights based on that. That often leads to frustration, since IT will rarely know everything every employee needs to do with the content. It can also lead to more protection than is necessary, and since there is a small overhead (for the computers and the humans) involved whenever accessing something is protected via encryption and rights enforcement, that is undesirable. Start instead with what threats you are trying to prevent: you might want to prevent your competitors from accessing your confidential plans, or from users accidentally putting sensitive data where unauthorized people can view it. Based on those requirements, define the minimal controls that must be there to ensure those scenarios do not happen and implement them. With time, as you gain more confidence on understanding what users need to do, you can adjust settings to implement tighter restrictions as needed. Involve different teams in the review of your proposed label taxonomy, including compliance, legal, public relations, end user education, etc. Defining labels is not an IT security task alone, and their early feedback will help you define a label taxonomy that will work for a long time and not need to be revised after deployment when those teams observe the labels you defined do not meet their needs or address their scenarios. Deployment Test Plan \u2693\ufe0e For the labeling client experience, consider your deployment methodology for Windows: Native labeling use Monthly Enterprise Channel or Monthly Channel for updates to Office 365 ProPlus. This will ensure you gain access to all MIP features immediately upon release. Semi-Annual Channel is strongly discouraged. AIP client should not be the default consideration and should only be used when needing specific functionality not yet available in the native client, or when you are using Office perpetual installation. For MAC we support the Native labeling in the office client. More details can be found here . For a comparison of update channels for M365, use this link . In some instances, a hybrid deployment of Native Labeling and AIP client may be appropriate. A good example is when File Explorer extension functionality is needed whilst wanting to keep the native experience as pristine as possible. In this case, the AIP client can be deployed along with an ADMX template to disable the Office Add-In components. Validate labels before deploying to users. Conduct a practical validation to see how accurate your users are at using these labels. One option is to create an email with fake sensitive information in the form of documents attached and send it to a subset of users asking them to open each document in turn and label it. They do not even need to report the results, since you will be able to see how they labeled each document in the Activity Explorer in the compliance center. You can alternatively do an offline activity, by setting baskets in the office\u2019s entrance, printing copies of a mix of pretend sensitive documents, and putting them in a pile at the entrance with a sign that says, \u201ctake one and put it in the corresponding basket\u201d. Users usually do this exercise consciously and it allows you to get a very representative idea of how well your users understand policies and labeling taxonomy. After you have done an exercise, you can validate the accuracy of user\u2019s actions and tune your labels and training materials accordingly. Socialize labels so they become part of the organization\u2019s natural language. While experience indicates the sensitivity label UI is simple enough that users do not need to be trained in its use, it is important to perform an awareness campaign in which the meaning of the different labels and the important of their use is highlighted (i.e., awareness emails, physical posters, etc.). The objective of such a campaign is that users incorporate the organization\u2019s labels as part of their natural language and that can intuitively assign documents to their corresponding label. The MIP CxE team has published several sample documents that can be used in this regard, referenced in the helpful links section above. Schedule multiple workshops with stakeholders during the testing phase to validate the label taxonomy is working effectively and catch any changes needed before wholesale deployment to production has occurred avoiding the need to reclassify large amounts of data in the future. Although we mention above that this validation should be done before deployment to users, it is inevitable that some changes will likely occur, and this should be expected by the project team. Ensure you have a well-documented test plan with clear tasks, testing scenarios and clear outcomes. Establish end user training and education. Measure their understanding of the organization information protection policies. Use \u201cknowledge measure questions\u201d if you can. Production Deployment \u2693\ufe0e Leverage the existing formal feedback mechanism from your end user-base to ensure that your label taxonomy remains effective and relevant to the organization. Making sure that established clear timelines for formal review and revision if necessary are followed. Monitor the classification activities. Using the \u201cActivity Explorer\u201d capability in the compliance center allows you to gain insights on how your users utilizing sensitivity labels (among other things). This will enable you to monitor how actively your users are following the organization policies and doing their due diligence when it comes to information labelling. Update the configuration, as necessary. Ensure all business units\u2019 requirements have been clearly addressed and document acceptance before rolling out to a wider end user base. While if you implement all the recommendations above you are set for a successful deployment of MIP, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially such as manual labels without protection, adding basic protection elements in a later stage (e.g. DLP controls to prevent highly confidential items from being accidentally sent outside, or encryption with very broad rights applied), and finally adding more restrictive permissions and tighter controls once you are confident in the use of the technology. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact. Considerations \u2693\ufe0e Let us start with classifying and protecting our unstructured data assets in documents and emails. Using the guidance above we can start with a classification taxonomy that makes sense to the business. This will allow us to take strides in protecting our data in place. Leveraging the work, we have completed in defining our tenant specific Sensitive Information Types (SITs) will allow us to marry these SITs against different classification categories to ensure protection gets baked into these assets at creation time, thus providing an additional layer of defense over and above that already afforded to us through our efforts up until now. This classification taxonomy can also be applied to data containers in our organization to ensure control over access and management of these areas. For more details on container labels please review the document here . When you create a sensitivity label, you can automatically assign that label to files and emails when it matches conditions that you specify. This ability to apply sensitivity labels to content automatically is important because: You don't need to train your users when to use each of your classifications. You don't need to rely on users to classify all content correctly. Users no longer need to know about your policies\u2014they can instead focus on their work. There are two different methods for automatically applying a sensitivity label to content in Microsoft 365: Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that's configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). Supports recommending a label to users or automatically applying a label. User decides whether to accept or reject the label, to help ensure the correct labeling of content. Minimal delay for documents because the label can be applied even before the document is saved. Not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office . For configuration instructions, see How to configure auto-labeling for Office apps on this page. Service-side auto labeling policies are a powerful way of applying labels to data at rest and in transit across several M365 workloads, however, it is important to be aware of the limitations imposed by these: Specific to auto-labelling for SharePoint Online and OneDrive for Business: Office files for Word, PowerPoint, and Excel are supported. - These files can be auto-labelled when they are not part of an active session and whether they have been created, uploaded, or changed since you created auto-labelling policies, or they are existing files that have not been changed since auto-labelling policies have been created. Maximum of 25,000 automatically labelled files in your tenant per day. Maximum of 10 auto-labelling policies per tenant, each targeting up to 10 sites (SharePoint Online or OneDrive for Business). Existing values for \u201cmodified\u201d, \u201cmodified by\u201d, and the \u201cdate\u201d are not changed because of auto-labelling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. Specific to auto-labelling for Exchange Online: Unlike manual labelling or auto-labelling with Office apps, Office attachments (Word, Excel, and PowerPoint files) and PDF attachments are also scanned for the conditions you specify in your auto-labelling policy. When there is a match, the email is labelled but not the attachment. For more details on this including what file types are supported please review the information here . If you have Exchange transport rules (ETRs) or data loss prevention (DLP) policies that apply Information Rights Management (IRM) encryption: When content is identified by these rules or policies and an auto-labelling policy, the label is applied. If that label applies encryption, the Information Rights Management settings from the Exchange transport rules or DLP policies are ignored. However, if that label doesn't apply encryption, the Information Rights Management settings from the transport rules or DLP policies are applied in addition to the label. Email that has Information Rights Management encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labelling. Incoming email is labelled when there is a match with your auto-labelling conditions. However, if the label is configured for encryption, that encryption is not applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. With these limitations in mind, Microsoft Defender for Cloud Apps (MDCA) can be used to apply labels for these services and several third-party SaaS applications also. MDCA has its own limitations and considerations which are discussed in this blog post . To protect and label structured data you should consider a solution like Azure Purview which among other things can allow you to Classify data using built-in and custom classifiers and Microsoft Information Protection sensitivity labels which allows you to label sensitive data consistently across SQL Server, Azure, Microsoft 365, and Power BI. To understand more about Azure Purview, check out this link . MIP Client Considerations \u2693\ufe0e When it comes to windows client you have two options, either a built-in client or a unified label client. Strategically, organizations should use the built-in client as it supports cross platform with a consistent experience. The built-in client does not need an add-in to deploy, or the need to be manage or keep up to date while providing a deeper integration with office products which includes performance improvement. While there are some feature gaps using the built-in client compared to the unified label client, we are working diligently to close that gap in the interim you can use the unified label client. To determine which features exist in the built-in client and which in the unified label client use the following table comparison . When it comes to MAC clients you can use the built-in client for office and Edge for viewing PDFs. Helpful Resources \u2693\ufe0e Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking End User Training for Sensitivity Labels in M365 \u2013 How to Accelerate Your Adoption Secure external collaboration using sensitivity labels Using Azure PIM for the AIP Super User feature management Data Loss Prevention \u2693\ufe0e To comply with business standards and industry regulations, organizations must protect sensitive information and prevent its inadvertent disclosure. Sensitive information can include financial data or personally identifiable information (PII) such as credit card numbers, social security numbers, or health records. With a data loss prevention (DLP) policy in the M365 SCC, you can identify, monitor, and automatically protect sensitive information across multiple Microsoft 365 workloads. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams, Windows 10 Devices, Microsoft Defender for Cloud Apps. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word applications. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Help users learn how to stay compliant without interrupting their workflow. You can educate your users about DLP policies and help them remain compliant without blocking their work. For example, if a user tries to share a document containing sensitive information, a DLP policy can both send them an email notification and show them a policy tip in the context of the document library that allows them to override the policy if they have a business justification. The same policy tips also appear in Outlook on the web (OWA), Outlook, Excel, PowerPoint, and Word Office clients. View DLP alerts and reports showing content that matches your organization\u2019s DLP policies. To view alerts and metadata related to your DLP policies you can use the DLP Alerts Management Dashboard. You can also view policy match reports to assess how your organization is complying with a DLP policy. If a DLP policy allows users to override a policy tip and report a false positive, you can also view what users have reported. You create and manage DLP policies on the Data Loss Prevention page in the Microsoft 365 compliance center. Learn about how DLP policies are structured . Best Practices \u2693\ufe0e Prior to Deployment Plan \u2693\ufe0e Identify the appropriate stakeholders and personas in your organization to collaborate for the design of DLP policies and workloads to be monitored. Some recommended personas to include compliance/privacy, security, human resources, and legal. Identify the types of information you need to protect and where this information is stored. Consider using the Data Classification page in the M365 SCC to help with this identification. Are there any types of information that will require the creation of custom Sensitive Information Types to detect? Where is the information stored in terms of workloads? Use the DLP Playbook to answer these questions and more. Currently, DLP supports the following workloads for protection: Exchange Online SharePoint Online OneDrive for Business Microsoft Teams Devices Microsoft Defender for Cloud Apps (acting as a proxy for creation of MDCA policy within the tenant Currently only global full or view only permissions are available for alerts at this time and cannot be further carved into areas of responsibility based on such as departments, locations etc. All designs should take this limitation into account before deployment is undertaken. If this capability is an absolute requirement, consider establishing a feed of all DLP alerts and activities into Azure Sentinel and configuring access rights accordingly within the solution.. Existing Exchange Online mail flow and DLP rules created in the Exchange Admin Center (EAC) will need to be gradually migrated to the M365 SCC, but will continue to function together with new policies created in the M365 SCC as documented here . Consider creating equivalent rules and disabling old rules in EAC while testing your new ones, then deleting the old rules when no longer needed. Using the presence of Sensitivity labels as a condition in your DLP policy should be closely considered as a standard in your organization. A sensitivity label is more likely to represent security sensitive information than a simple pattern match from a SIT, especially if you are using manual or recommended labeling, as the data is likely to have been deliberately classified by and end user as a match for certain sensitive information. Additionally, labels applied automatically via a trainable classifier are far more likely to be accurately classified than from pattern matching. Deployment Test Plan \u2693\ufe0e Always create DLP policies initially in test mode as this gives you an opportunity to determine not only if the policy is alerting correctly via email (nothing will flow through to the DLP reports in audit mode by design) but this will also allow you to determine if the thresholds you have configured for each rule are appropriate. For example, suppose you have configured your rule to trigger when more than 5 credit card numbers have detected. During testing you realize that it would be more appropriate to trigger the rule on 1 credit card number, so you edit the rule to make this change and then enable the policy to allow for the population of alerts in the reports. Use the DLP policy templates initially to see whether they make sense for your organization. These templates are preconfigured with certain Sensitive Information Types to monitor based on the regulatory compliance frameworks you need to monitor broken down by vertical organization type and country. This can drastically reduce the amount of time needed to create and test policies during your deployment test. If your licensing plan allows, consider using alerts based on volume thresholds rather than sending alerts each time a rule is matched. This allows for more targeted alert behavior based on when certain thresholds are exceeded or when the number of activities are above a certain number, which is more likely to be representative of suspicious behavior and leads to fewer alerts being ignored as \u201cnoise\u201d. When creating DLP policies, consider separate policies per workload. For example, you might have a policy named \u201cPCI-DSS-ExchangeOnline\u201d and one named \u201cPCI-DSS-SharePointOnline\u201d. The reason for this is that when combining workloads, the DLP rules interface will only show conditions common to each workload chosen, which can lead to many options missing when incompatibilities occur. Consider a case where a policy is choosing Exchange Online and SharePoint Online as workloads. The below figures show the DLP Rules Wizard conditions when the policy chooses Exchange Online in isolation versus in conjunction with SharePoint Online. Figure 2: Policy Wizard with single workload for Exchange Online Figure 3: Policy Wizard with multiple workloads When adding files to SharePoint Online and OneDrive for Business, there is an expected lag time between when the file is added and indexing occurs, a necessary process that must complete before DLP policies can be enforced. For more on how this works use this link . This leads to an opportunity for data leakage while waiting for this process to occur. Consider configuring SharePoint sensitive by default functionality to ensure this does not become an issue. Ensure that you have fully documented your policies and their expected outcomes for end users as part of your user acceptance and training procedures. Not all aspects of the user experience are identical across all platforms and this should be considered so as not to generate unnecessary help desk calls. A good example of this is policy tips and their behavior across the various OS platforms. You should expect to see Policy Tips in Office Online and Windows, but not macOS for instance. Ensure you have a well-documented and functional test plan, with clear tasks and outcomes. Production Deployment \u2693\ufe0e DLP reports should be scheduled and emailed to appropriate stakeholders based on the report types (schedules and recipients can be defined directly from the report itself in the Security and Compliance report viewer at https://protection.office.com ). Note currently you cannot schedule the following reports in the new Compliance portal (you can still do this in the older security and compliance center): DLP Policy Matches DLP Incidents Consider allowing users to mark items as false positives or provide an exception with justification. This will allow you to track what is being shared out and not slow business process down. These should be reviewed carefully to see if a policy needs to be adjusted or changed. Define exceptions to your DLP rules that are based on sensitivity labels. MIP labels are highly synergistic with traditional DLP. The biggest challenge with DLP is handling incidents such as false positives and exceptions, which generally disrupt user work and often require reactive actions taken by IT to unblock productivity and labels can help with that. For example, you can define a DLP rule that blocks Personally identifiable information (PII) from being shared outside of the organization, but make an exception for low-count PII (e.g., <2 credit card numbers) if the content is labeled as \u201cNon-business\u201d to allow for employees to share their personal information with family members when needed, and also exempt moderate counts of PII (e.g. <10 credit card numbers) if it is in protected form. You can even create a blanket exception for a label such as \u201cExecutive Sharing Exception\u201d which bypasses all DLP filters, but that is only available to specific people that are trusted to deal with this information, and that they must explicitly choose for the sensitive content they need to share. Use of such labels can be closely monitored and reported. When you are setting up a policy for Teams as a workload you should consider combining this with SharePoint Online and OneDrive for Business to maintain complete coverage. It is important to understand that \u201cTeams\u201d as a DLP workload only covers private chat and channel messages. Files shared in channels and chat are served from SharePoint and OneDrive, respectively. Ideally Onboarding devices to Endpoint DLP should be done automatically within a Mobile Device Management (MDM) when possible, such as Microsoft Intune or System Center Configuration Manager. If Microsoft Defender for Endpoint is already deployed in the organization, there is nothing further to do for this onboarding to occur. Otherwise, you can onboard devices with a script, Group Policy or VDI onboarding scripts. More details can be found here . Considerations \u2693\ufe0e While DLP might be a very important part of your compliance configuration you may want to consider reviewing the assessments that are available in from Compliance Manager, there is a significant chance that some control objectives require you to establish not only data loss prevention strategies, but also procedures to follow if information spillage does occur in the organization. Figure 1 below shows the improvement actions within a given tenant for an example compliance assessment. Figure 1: Improvement actions showing potential DLP requirement It is important to take these into consideration not only when planning your DLP strategy, but also updating these improvement actions upon completion of deployment will feed into an overall audit package to be provided to auditors when necessary for these regulatory compliance reporting periods. Consider using the out of the box (OOTB) SITs policy templates first, then start customizing the OOTB as you need if necessary. Sensitive Information Types (SITs) creation is likely to be a large factor of your initial deployment work. When using Regular Expressions (RegEx) for SIT definition, use websites such as regex101.com or regexr.com to help construct the RegEx\u2019s to be used. Be aware that the RegEx engine used in Microsoft DLP is Boost.Regex 5.1.3 so care should be taken to ensure all expressions conform to this standard. Some aspects of RegEx construction can create performance issues in the service, therefore it is also important to be aware of any potential validation issues . When creating a DLP policy in test mode, be aware that while incident emails will be generated, NO alerts will be created in the DLP reports within the Security and Compliance center. This is an expected outcome to avoid polluting the reports with false alerts. When working with Endpoint DLP, be aware that content is evaluated when created or modified. Existing content at rest on the device is not scanned at this time. When considering applying DLP policies to Teams, it is important to remember that the Teams \u201cworkload\u201d as shown in the wizard refers to chat and channel messages only. Files within Teams will be resident in either SharePoint Online or OneDrive for Business, therefore a comprehensive Teams protection strategy should also take these workloads into account when planning your policies. All DLP reports can show data from the most recent four-month period. The most recent data can take up to 24 hours to appear in the reports. Helpful Resources \u2693\ufe0e When testing SITs and Endpoint DLP actions, it can be useful to have a library of links to assist in this testing: https://filebin.net \u2013 excellent for testing HTTP post/upload actions https://dlptest.com \u2013 provides several testing options as well as samples for common restricted items such as credit card numbers, SSN, etc. https://fauxid.com/ - Provides you with data that can be used to generate SSN, credit card numbers etc. Migrating from Exchange Transport Rules to Unified DLP - The complete playbook Train End Users for adoption of sensitivity labels","title":"Information Protection and Data Loss Prevention"},{"location":"dag/mip-dlp/#your-deployment-plan","text":"The objective is to create a deployment plan that follows the progression of crawl-walk-run methodology while highlighting the user and administrator experience at each stage. Your focus should be on the end user result and the security controls you achieve with each implemented stage. Solutions or tools covered in this guide for deployment consideration are: Microsoft Information Protection (MIP) Data Loss Prevention (DLP) Microsoft Defender for Cloud Apps (MDCA) Compliance Manager Microsoft Compliance Configuration Analyzer (MCCA) The DAG is not inclusive of all requirements or architectures needed for successful implementation of Microsoft 365\u2019 but rather a focus on security and compliance as it relates to solutions included as part of Microsoft information Protection & Compliance licenses. See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with focus on cross technologies. Crawl Stage - The first stage is about starting to evaluate where your organization is today regarding the information security and compliance with your goal of defining a strategic direction for your organization. Using this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for product education, defining requirements, and evaluation or testing. Walk Stage - The second stage builds the foundation for a successful, scalable, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or a proof of concept with a selected group of users or locations. Run Stage - The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Following the above approach will lead to successful adoption and deployment of each solution while protecting your intellectual property, stopping fraud or insider trading, plugging the sensitive data leaks, along with making the workplace safe.","title":"Your Deployment Plan"},{"location":"dag/mip-dlp/#microsoft-information-protection","text":"Implement Microsoft Information Protection (MIP) to help you discover, classify, and protect sensitive information wherever it lives or travels. Contrary to popular opinion, MIP is not a single product but rather a suite of technologies supported by many aspects of the Microsoft 365 ecosystem. MIP capabilities are included with Microsoft 365 Compliance and give you the tools to know your data, protect your data, and prevent data loss. The main capabilities associated with MIP are as follows: Sensitive information types (SITs) Trainable Classifiers Data Classification Sensitivity Labels Azure Information Protection (AIP) unified labeling client Azure Information Protection (AIP) unified labeling Scanner Azure Purview Double Key Encryption (DKE) Office 365 Message Encryption (OME) Service encryption with Customer Key SharePoint Information Rights Management (IRM) Rights Management connector Microsoft Defender for Cloud Apps (MDCA) Microsoft Information Protection (MIP) SDK Data Loss Prevention (DLP) Learn more about MIP basics here . With MIP and a Sensitivity labels policy you can: Deploy your classification taxonomy to the company end user employees and give them the ability to apply these labels to documents and emails. Labels can also be applied automatically or in a recommended way based on sensitive information stored in the document or email. Leverage the applied sensitivity labels as a condition for data loss prevention use cases. Mark the document or email sensitivity with a header, footer and/or watermark. This will make the data sensitivity visible to anyone who consumes the document, within an app, via the web or as a hard copy. Apply sensitivity labels for SharePoint online, Teams sites and groups, providing another layer of control on the container level access within managed or un-managed devices, if it should be set for Public or Private access and/or external access. With encryption you can control who can consume content (for example: only company employees + approved partners) and what permissions he or she has (for example: Read but Do Not Print or Edit).","title":"Microsoft Information Protection"},{"location":"dag/mip-dlp/#best-practices","text":"Defining the right label taxonomy and protection policies is the most critical step in a Microsoft Information Protection deployment. Labels will be the interface for users to understand content sensitivity, how it matches company policies, and will be the primary input for users to flag content that needs to be protected. A good label taxonomy needs to meet business and/or regulatory needs, be intuitively understandable by users, provide good policy tips and be easy to use. It should not prevent users from doing their jobs, while at the same time help prevent instances of data leakage or misuse and address compliance requirements. With these requirements in mind, the following best practices have proven to make deployment of information protection policies in many organizations easier, faster, and more successful.","title":"Best Practices"},{"location":"dag/mip-dlp/#prior-to-deployment-plan","text":"Discover your sensitive information in your existing repositories. This is the first step we recommend as part of our best practice approach to detect the data you own and be ready to configure it as part of your sensitivity label configurations as well as data loss prevention policies later in this guide. Microsoft 365 cloud: Use Content Explorer in Microsoft 365 compliance center to discover data stored in Microsoft 365 (SharePoint, OneDrive), read more about it here . Non-Microsoft cloud repositories: Use Microsoft Defender for Cloud Apps to connect non-Microsoft applications and discover sensitive information beyond the Microsoft 365 services. Read more about it here . On-premises repositories: Use Azure Information Protection Scanner to discover data stored in your on-premises file shares, read more about it here . Azure resources: Use Azure Purview to identify sensitive information stored in Azure Repositories, read more about it here . Consider the methods in which users will interact with MIP labels and how you intend to implement this: Interactively within Microsoft 365 Apps via the Sensitivity Button. Read more about it in the \u201cMIP Client Consideration\u201d section. Natively for macOS, iOS and Android Native labeling vs AIP Client Container labeling for SharePoint Sites, Teams and Office 365 Groups Public vs Private access Unmanaged device access Sharing levels PowerBI Dashboards and PBIX assets Use label names for your labels that intuitively resonate with your users. Using company jargon that is well ingrained in the employee\u2019s culture is a valid approach, though care must be taken to ensure the labels are also meaningful to new employees. For example, using acronyms in label names is not ideal due to the opacity to new employees and the difficulty of visually recognizing them. Using short, meaningful words such as \u201cConfidential\u201d or \u201cSecret\u201d generally works best. Consider label order. Labels are sorted from lowest sensitivity to highest sensitivity, which means higher sensitivity labels represent an \u201cupgrade\u201d in the confidentiality of the information and usually have stronger protection measures. This order can be enforced by preventing users from downgrading sensitivity of a document unless they have the right privileges, and there are multiple scenarios in which it is important that the order of the labels is clear. It is important that the names you use reflect this order, ad you should avoid using terms that have no clear hierarchy. For example, not all users might agree on whether \u201cConfidential\u201d or \u201cSecret\u201d is the most sensitive label, so using something like \u201cConfidential\u201d vs. \u201cHighly confidential\u201d may be preferable. Use sublabels with intent. Labels are generally used to represent the actual sensitivity of the content that is labeled, while sublabels are typically used to represent variations in the protection or the scope of the content. For example, you might have a label taxonomy that includes \u201cGeneral Business\u201d, \u201cConfidential\u201d and \u201cHighly Confidential\u201d as top-level labels. Sublabels such as \u201cInternal\u201d or \u201cExternal\u201d designate specific types of data in some of those top-level categories that need to be controlled in specific ways. You might also have project/team specific sublabels or sublabels to address special requirements such as excluding the application of content markings for content that should not be modified. Keep it simple with no more than five top level labels and five sublabels. User experience research shows that with five or fewer labels, users can target the desired label directly in a single movement, whereas if there are more elements in the list the user will typically have to read through them each time, making mistakes more likely. The 5x5 approach is proven to keep things simple and help users choose the right labels, but if you can keep labels below those numbers, even better. Define labels that will last a long time. Since labels often become part of a company\u2019s culture and language, it is critical that they are not frequently altered, especially when it comes to the names and meanings of the top-level labels. The approach mentioned in the previous point makes this easy: using top-level labels to represent the sensitivity of the document means they will not change often. Sublabels, on the other hand, can be more dynamic, and while it is preferable to frame them in a way that follows a clear pattern that rarely changes, adding or changing sublabels as additional requirements such as new projects or divisions come up is usually not a problem if you follow a consistent pattern. Do not put sensitive information in a label\u2019s name or description. This might sound obvious, but it is common that IT departments are asked to create a label to protect information for a merger or acquisition or a label for a secret project that is not known to the general population in the company. Putting the name of the company or a word that reveals more about the project than what is public in the name of the label can reveal such data to all users, even if the label is scoped to a small team. While scoped labels are not made available to all users, metadata about the existence of such labels is carried within the policies all users get, so it is important that codenames or other non-disclosing keywords are used in such labels instead. Plan your auto-labeling strategy, MIP provide both Service and Client based auto-labeling for different use cases: Service-side auto labeling policies should be used for data at rest in SharePoint Online and OneDrive for Business and data in transit for Exchange Online when specific SITs need to be detected and labels applied automatically. This can be especially helpful when the data source is not controlled and might be that data is stored or sent without being labeled by the client solution. Also, it\u2019s a great option to label data that is already stored in SharePoint Online and OneDrive for Business. Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that is configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). This method supports recommending a label to a user, as well as automatically applying a label. But in both cases, the user decides whether to accept or reject the label, to help ensure the correct labeling of content. This client-side labeling has minimal delay for documents because the label can be applied even before the document is saved. However, not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office. If your organization operates in multiple languages, work with your localization teams to ensure the names chosen for the labels can be easily localized and are meaningful in all the required languages. Consider words that have a clear meaning in one language might be harder to localize or be ambiguous when translated. Examples of such words are \u201cPublic\u201d which can have nuanced meanings in some languages, and \u201cPersonal\u201d which can be easily confused in meaning to refer to private information. Consider the impact on usability. Forcing users to select labels too frequently can lead to users doing it reflexively without thinking about the label they should apply. Using a predefined default label is good practice in scenarios where manually labeling everything could be a burden - and where there is some \u201csafe\u201d sensitivity level that applies to most content. One such case is email, where for most users in most organizations labeling emails as \u201cInternal\u201d by default should be a safe option and reduce user effort considerably. Users can label emails as \u201cexternal\u201d, \u201cpublic\u201d or \u201cconfidential\u201d as needed. At the same time, most users do not create dozens of new documents per day, so asking them to individually label each document without providing a default is an acceptable requirement in most cases. MIP allows you to do this by using a different default label for emails and documents using the advanced option named \u201cOutlookDefaultLabel\u201d that specifies a default label for Outlook independently from what is set for documents. Compartmentalize data sparingly. Compartmentalization of data is essential in many businesses and using scoped sublabels that are shown and give rights to people in specific departments is a good practice, but you should use this capability in moderation. If you have a dozen critical projects that need to contain their data from being accessed by the general population of employees, creating sublabels specifically for them is beneficial. But if you have a thousand projects that demand the same treatment, the administrative burden imposed by such label taxonomy would be large and you will likely end up hitting a practical limit. The best practice is to define a clear rule for which kinds of teams, projects, divisions, or groups get their own sublabels which ensures only a small number of sublabels need to be created (a few dozen) - and stick with it. Consider what threats you are trying to prevent \u2013 not what users will be doing with the content. When defining protection policies some organizations start by thinking about what users need to do with their content, and define rights based on that. That often leads to frustration, since IT will rarely know everything every employee needs to do with the content. It can also lead to more protection than is necessary, and since there is a small overhead (for the computers and the humans) involved whenever accessing something is protected via encryption and rights enforcement, that is undesirable. Start instead with what threats you are trying to prevent: you might want to prevent your competitors from accessing your confidential plans, or from users accidentally putting sensitive data where unauthorized people can view it. Based on those requirements, define the minimal controls that must be there to ensure those scenarios do not happen and implement them. With time, as you gain more confidence on understanding what users need to do, you can adjust settings to implement tighter restrictions as needed. Involve different teams in the review of your proposed label taxonomy, including compliance, legal, public relations, end user education, etc. Defining labels is not an IT security task alone, and their early feedback will help you define a label taxonomy that will work for a long time and not need to be revised after deployment when those teams observe the labels you defined do not meet their needs or address their scenarios.","title":"Prior to Deployment Plan"},{"location":"dag/mip-dlp/#deployment-test-plan","text":"For the labeling client experience, consider your deployment methodology for Windows: Native labeling use Monthly Enterprise Channel or Monthly Channel for updates to Office 365 ProPlus. This will ensure you gain access to all MIP features immediately upon release. Semi-Annual Channel is strongly discouraged. AIP client should not be the default consideration and should only be used when needing specific functionality not yet available in the native client, or when you are using Office perpetual installation. For MAC we support the Native labeling in the office client. More details can be found here . For a comparison of update channels for M365, use this link . In some instances, a hybrid deployment of Native Labeling and AIP client may be appropriate. A good example is when File Explorer extension functionality is needed whilst wanting to keep the native experience as pristine as possible. In this case, the AIP client can be deployed along with an ADMX template to disable the Office Add-In components. Validate labels before deploying to users. Conduct a practical validation to see how accurate your users are at using these labels. One option is to create an email with fake sensitive information in the form of documents attached and send it to a subset of users asking them to open each document in turn and label it. They do not even need to report the results, since you will be able to see how they labeled each document in the Activity Explorer in the compliance center. You can alternatively do an offline activity, by setting baskets in the office\u2019s entrance, printing copies of a mix of pretend sensitive documents, and putting them in a pile at the entrance with a sign that says, \u201ctake one and put it in the corresponding basket\u201d. Users usually do this exercise consciously and it allows you to get a very representative idea of how well your users understand policies and labeling taxonomy. After you have done an exercise, you can validate the accuracy of user\u2019s actions and tune your labels and training materials accordingly. Socialize labels so they become part of the organization\u2019s natural language. While experience indicates the sensitivity label UI is simple enough that users do not need to be trained in its use, it is important to perform an awareness campaign in which the meaning of the different labels and the important of their use is highlighted (i.e., awareness emails, physical posters, etc.). The objective of such a campaign is that users incorporate the organization\u2019s labels as part of their natural language and that can intuitively assign documents to their corresponding label. The MIP CxE team has published several sample documents that can be used in this regard, referenced in the helpful links section above. Schedule multiple workshops with stakeholders during the testing phase to validate the label taxonomy is working effectively and catch any changes needed before wholesale deployment to production has occurred avoiding the need to reclassify large amounts of data in the future. Although we mention above that this validation should be done before deployment to users, it is inevitable that some changes will likely occur, and this should be expected by the project team. Ensure you have a well-documented test plan with clear tasks, testing scenarios and clear outcomes. Establish end user training and education. Measure their understanding of the organization information protection policies. Use \u201cknowledge measure questions\u201d if you can.","title":"Deployment Test Plan"},{"location":"dag/mip-dlp/#production-deployment","text":"Leverage the existing formal feedback mechanism from your end user-base to ensure that your label taxonomy remains effective and relevant to the organization. Making sure that established clear timelines for formal review and revision if necessary are followed. Monitor the classification activities. Using the \u201cActivity Explorer\u201d capability in the compliance center allows you to gain insights on how your users utilizing sensitivity labels (among other things). This will enable you to monitor how actively your users are following the organization policies and doing their due diligence when it comes to information labelling. Update the configuration, as necessary. Ensure all business units\u2019 requirements have been clearly addressed and document acceptance before rolling out to a wider end user base. While if you implement all the recommendations above you are set for a successful deployment of MIP, the process to implement is equally important. We highly recommend a \u201cCrawl-Walk-Run\u201d approach, in which the technology is introduced in stages, focusing on things that cause minimal disruption initially such as manual labels without protection, adding basic protection elements in a later stage (e.g. DLP controls to prevent highly confidential items from being accidentally sent outside, or encryption with very broad rights applied), and finally adding more restrictive permissions and tighter controls once you are confident in the use of the technology. You can also introduce these changes in waves across your organization, focusing on limited sets of end users first and expanding to broader audiences. This will allow you to deploy quickly without causing disruption, and help you get a baseline of user behavior before introducing tight restrictions. It will also help you identify early potential conflicts or compatibility issues between different tools so you can address them before they have significant impact.","title":"Production Deployment"},{"location":"dag/mip-dlp/#considerations","text":"Let us start with classifying and protecting our unstructured data assets in documents and emails. Using the guidance above we can start with a classification taxonomy that makes sense to the business. This will allow us to take strides in protecting our data in place. Leveraging the work, we have completed in defining our tenant specific Sensitive Information Types (SITs) will allow us to marry these SITs against different classification categories to ensure protection gets baked into these assets at creation time, thus providing an additional layer of defense over and above that already afforded to us through our efforts up until now. This classification taxonomy can also be applied to data containers in our organization to ensure control over access and management of these areas. For more details on container labels please review the document here . When you create a sensitivity label, you can automatically assign that label to files and emails when it matches conditions that you specify. This ability to apply sensitivity labels to content automatically is important because: You don't need to train your users when to use each of your classifications. You don't need to rely on users to classify all content correctly. Users no longer need to know about your policies\u2014they can instead focus on their work. There are two different methods for automatically applying a sensitivity label to content in Microsoft 365: Client-side labeling when users edit documents or compose (also reply or forward) emails: Use a label that's configured for auto-labeling for files and emails (includes Word, Excel, PowerPoint, and Outlook). Supports recommending a label to users or automatically applying a label. User decides whether to accept or reject the label, to help ensure the correct labeling of content. Minimal delay for documents because the label can be applied even before the document is saved. Not all client apps support auto-labeling. This capability is supported by the Azure Information Protection unified labeling client, and some versions of Office . For configuration instructions, see How to configure auto-labeling for Office apps on this page. Service-side auto labeling policies are a powerful way of applying labels to data at rest and in transit across several M365 workloads, however, it is important to be aware of the limitations imposed by these: Specific to auto-labelling for SharePoint Online and OneDrive for Business: Office files for Word, PowerPoint, and Excel are supported. - These files can be auto-labelled when they are not part of an active session and whether they have been created, uploaded, or changed since you created auto-labelling policies, or they are existing files that have not been changed since auto-labelling policies have been created. Maximum of 25,000 automatically labelled files in your tenant per day. Maximum of 10 auto-labelling policies per tenant, each targeting up to 10 sites (SharePoint Online or OneDrive for Business). Existing values for \u201cmodified\u201d, \u201cmodified by\u201d, and the \u201cdate\u201d are not changed because of auto-labelling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. Specific to auto-labelling for Exchange Online: Unlike manual labelling or auto-labelling with Office apps, Office attachments (Word, Excel, and PowerPoint files) and PDF attachments are also scanned for the conditions you specify in your auto-labelling policy. When there is a match, the email is labelled but not the attachment. For more details on this including what file types are supported please review the information here . If you have Exchange transport rules (ETRs) or data loss prevention (DLP) policies that apply Information Rights Management (IRM) encryption: When content is identified by these rules or policies and an auto-labelling policy, the label is applied. If that label applies encryption, the Information Rights Management settings from the Exchange transport rules or DLP policies are ignored. However, if that label doesn't apply encryption, the Information Rights Management settings from the transport rules or DLP policies are applied in addition to the label. Email that has Information Rights Management encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labelling. Incoming email is labelled when there is a match with your auto-labelling conditions. However, if the label is configured for encryption, that encryption is not applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. With these limitations in mind, Microsoft Defender for Cloud Apps (MDCA) can be used to apply labels for these services and several third-party SaaS applications also. MDCA has its own limitations and considerations which are discussed in this blog post . To protect and label structured data you should consider a solution like Azure Purview which among other things can allow you to Classify data using built-in and custom classifiers and Microsoft Information Protection sensitivity labels which allows you to label sensitive data consistently across SQL Server, Azure, Microsoft 365, and Power BI. To understand more about Azure Purview, check out this link .","title":"Considerations"},{"location":"dag/mip-dlp/#mip-client-considerations","text":"When it comes to windows client you have two options, either a built-in client or a unified label client. Strategically, organizations should use the built-in client as it supports cross platform with a consistent experience. The built-in client does not need an add-in to deploy, or the need to be manage or keep up to date while providing a deeper integration with office products which includes performance improvement. While there are some feature gaps using the built-in client compared to the unified label client, we are working diligently to close that gap in the interim you can use the unified label client. To determine which features exist in the built-in client and which in the unified label client use the following table comparison . When it comes to MAC clients you can use the built-in client for office and Edge for viewing PDFs.","title":"MIP Client Considerations"},{"location":"dag/mip-dlp/#helpful-resources","text":"Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking End User Training for Sensitivity Labels in M365 \u2013 How to Accelerate Your Adoption Secure external collaboration using sensitivity labels Using Azure PIM for the AIP Super User feature management","title":"Helpful Resources"},{"location":"dag/mip-dlp/#data-loss-prevention","text":"To comply with business standards and industry regulations, organizations must protect sensitive information and prevent its inadvertent disclosure. Sensitive information can include financial data or personally identifiable information (PII) such as credit card numbers, social security numbers, or health records. With a data loss prevention (DLP) policy in the M365 SCC, you can identify, monitor, and automatically protect sensitive information across multiple Microsoft 365 workloads. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams, Windows 10 Devices, Microsoft Defender for Cloud Apps. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word applications. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Help users learn how to stay compliant without interrupting their workflow. You can educate your users about DLP policies and help them remain compliant without blocking their work. For example, if a user tries to share a document containing sensitive information, a DLP policy can both send them an email notification and show them a policy tip in the context of the document library that allows them to override the policy if they have a business justification. The same policy tips also appear in Outlook on the web (OWA), Outlook, Excel, PowerPoint, and Word Office clients. View DLP alerts and reports showing content that matches your organization\u2019s DLP policies. To view alerts and metadata related to your DLP policies you can use the DLP Alerts Management Dashboard. You can also view policy match reports to assess how your organization is complying with a DLP policy. If a DLP policy allows users to override a policy tip and report a false positive, you can also view what users have reported. You create and manage DLP policies on the Data Loss Prevention page in the Microsoft 365 compliance center. Learn about how DLP policies are structured .","title":"Data Loss Prevention"},{"location":"dag/mip-dlp/#best-practices_1","text":"","title":"Best Practices"},{"location":"dag/mip-dlp/#prior-to-deployment-plan_1","text":"Identify the appropriate stakeholders and personas in your organization to collaborate for the design of DLP policies and workloads to be monitored. Some recommended personas to include compliance/privacy, security, human resources, and legal. Identify the types of information you need to protect and where this information is stored. Consider using the Data Classification page in the M365 SCC to help with this identification. Are there any types of information that will require the creation of custom Sensitive Information Types to detect? Where is the information stored in terms of workloads? Use the DLP Playbook to answer these questions and more. Currently, DLP supports the following workloads for protection: Exchange Online SharePoint Online OneDrive for Business Microsoft Teams Devices Microsoft Defender for Cloud Apps (acting as a proxy for creation of MDCA policy within the tenant Currently only global full or view only permissions are available for alerts at this time and cannot be further carved into areas of responsibility based on such as departments, locations etc. All designs should take this limitation into account before deployment is undertaken. If this capability is an absolute requirement, consider establishing a feed of all DLP alerts and activities into Azure Sentinel and configuring access rights accordingly within the solution.. Existing Exchange Online mail flow and DLP rules created in the Exchange Admin Center (EAC) will need to be gradually migrated to the M365 SCC, but will continue to function together with new policies created in the M365 SCC as documented here . Consider creating equivalent rules and disabling old rules in EAC while testing your new ones, then deleting the old rules when no longer needed. Using the presence of Sensitivity labels as a condition in your DLP policy should be closely considered as a standard in your organization. A sensitivity label is more likely to represent security sensitive information than a simple pattern match from a SIT, especially if you are using manual or recommended labeling, as the data is likely to have been deliberately classified by and end user as a match for certain sensitive information. Additionally, labels applied automatically via a trainable classifier are far more likely to be accurately classified than from pattern matching.","title":"Prior to Deployment Plan"},{"location":"dag/mip-dlp/#deployment-test-plan_1","text":"Always create DLP policies initially in test mode as this gives you an opportunity to determine not only if the policy is alerting correctly via email (nothing will flow through to the DLP reports in audit mode by design) but this will also allow you to determine if the thresholds you have configured for each rule are appropriate. For example, suppose you have configured your rule to trigger when more than 5 credit card numbers have detected. During testing you realize that it would be more appropriate to trigger the rule on 1 credit card number, so you edit the rule to make this change and then enable the policy to allow for the population of alerts in the reports. Use the DLP policy templates initially to see whether they make sense for your organization. These templates are preconfigured with certain Sensitive Information Types to monitor based on the regulatory compliance frameworks you need to monitor broken down by vertical organization type and country. This can drastically reduce the amount of time needed to create and test policies during your deployment test. If your licensing plan allows, consider using alerts based on volume thresholds rather than sending alerts each time a rule is matched. This allows for more targeted alert behavior based on when certain thresholds are exceeded or when the number of activities are above a certain number, which is more likely to be representative of suspicious behavior and leads to fewer alerts being ignored as \u201cnoise\u201d. When creating DLP policies, consider separate policies per workload. For example, you might have a policy named \u201cPCI-DSS-ExchangeOnline\u201d and one named \u201cPCI-DSS-SharePointOnline\u201d. The reason for this is that when combining workloads, the DLP rules interface will only show conditions common to each workload chosen, which can lead to many options missing when incompatibilities occur. Consider a case where a policy is choosing Exchange Online and SharePoint Online as workloads. The below figures show the DLP Rules Wizard conditions when the policy chooses Exchange Online in isolation versus in conjunction with SharePoint Online. Figure 2: Policy Wizard with single workload for Exchange Online Figure 3: Policy Wizard with multiple workloads When adding files to SharePoint Online and OneDrive for Business, there is an expected lag time between when the file is added and indexing occurs, a necessary process that must complete before DLP policies can be enforced. For more on how this works use this link . This leads to an opportunity for data leakage while waiting for this process to occur. Consider configuring SharePoint sensitive by default functionality to ensure this does not become an issue. Ensure that you have fully documented your policies and their expected outcomes for end users as part of your user acceptance and training procedures. Not all aspects of the user experience are identical across all platforms and this should be considered so as not to generate unnecessary help desk calls. A good example of this is policy tips and their behavior across the various OS platforms. You should expect to see Policy Tips in Office Online and Windows, but not macOS for instance. Ensure you have a well-documented and functional test plan, with clear tasks and outcomes.","title":"Deployment Test Plan"},{"location":"dag/mip-dlp/#production-deployment_1","text":"DLP reports should be scheduled and emailed to appropriate stakeholders based on the report types (schedules and recipients can be defined directly from the report itself in the Security and Compliance report viewer at https://protection.office.com ). Note currently you cannot schedule the following reports in the new Compliance portal (you can still do this in the older security and compliance center): DLP Policy Matches DLP Incidents Consider allowing users to mark items as false positives or provide an exception with justification. This will allow you to track what is being shared out and not slow business process down. These should be reviewed carefully to see if a policy needs to be adjusted or changed. Define exceptions to your DLP rules that are based on sensitivity labels. MIP labels are highly synergistic with traditional DLP. The biggest challenge with DLP is handling incidents such as false positives and exceptions, which generally disrupt user work and often require reactive actions taken by IT to unblock productivity and labels can help with that. For example, you can define a DLP rule that blocks Personally identifiable information (PII) from being shared outside of the organization, but make an exception for low-count PII (e.g., <2 credit card numbers) if the content is labeled as \u201cNon-business\u201d to allow for employees to share their personal information with family members when needed, and also exempt moderate counts of PII (e.g. <10 credit card numbers) if it is in protected form. You can even create a blanket exception for a label such as \u201cExecutive Sharing Exception\u201d which bypasses all DLP filters, but that is only available to specific people that are trusted to deal with this information, and that they must explicitly choose for the sensitive content they need to share. Use of such labels can be closely monitored and reported. When you are setting up a policy for Teams as a workload you should consider combining this with SharePoint Online and OneDrive for Business to maintain complete coverage. It is important to understand that \u201cTeams\u201d as a DLP workload only covers private chat and channel messages. Files shared in channels and chat are served from SharePoint and OneDrive, respectively. Ideally Onboarding devices to Endpoint DLP should be done automatically within a Mobile Device Management (MDM) when possible, such as Microsoft Intune or System Center Configuration Manager. If Microsoft Defender for Endpoint is already deployed in the organization, there is nothing further to do for this onboarding to occur. Otherwise, you can onboard devices with a script, Group Policy or VDI onboarding scripts. More details can be found here .","title":"Production Deployment"},{"location":"dag/mip-dlp/#considerations_1","text":"While DLP might be a very important part of your compliance configuration you may want to consider reviewing the assessments that are available in from Compliance Manager, there is a significant chance that some control objectives require you to establish not only data loss prevention strategies, but also procedures to follow if information spillage does occur in the organization. Figure 1 below shows the improvement actions within a given tenant for an example compliance assessment. Figure 1: Improvement actions showing potential DLP requirement It is important to take these into consideration not only when planning your DLP strategy, but also updating these improvement actions upon completion of deployment will feed into an overall audit package to be provided to auditors when necessary for these regulatory compliance reporting periods. Consider using the out of the box (OOTB) SITs policy templates first, then start customizing the OOTB as you need if necessary. Sensitive Information Types (SITs) creation is likely to be a large factor of your initial deployment work. When using Regular Expressions (RegEx) for SIT definition, use websites such as regex101.com or regexr.com to help construct the RegEx\u2019s to be used. Be aware that the RegEx engine used in Microsoft DLP is Boost.Regex 5.1.3 so care should be taken to ensure all expressions conform to this standard. Some aspects of RegEx construction can create performance issues in the service, therefore it is also important to be aware of any potential validation issues . When creating a DLP policy in test mode, be aware that while incident emails will be generated, NO alerts will be created in the DLP reports within the Security and Compliance center. This is an expected outcome to avoid polluting the reports with false alerts. When working with Endpoint DLP, be aware that content is evaluated when created or modified. Existing content at rest on the device is not scanned at this time. When considering applying DLP policies to Teams, it is important to remember that the Teams \u201cworkload\u201d as shown in the wizard refers to chat and channel messages only. Files within Teams will be resident in either SharePoint Online or OneDrive for Business, therefore a comprehensive Teams protection strategy should also take these workloads into account when planning your policies. All DLP reports can show data from the most recent four-month period. The most recent data can take up to 24 hours to appear in the reports.","title":"Considerations"},{"location":"dag/mip-dlp/#helpful-resources_1","text":"When testing SITs and Endpoint DLP actions, it can be useful to have a library of links to assist in this testing: https://filebin.net \u2013 excellent for testing HTTP post/upload actions https://dlptest.com \u2013 provides several testing options as well as samples for common restricted items such as credit card numbers, SSN, etc. https://fauxid.com/ - Provides you with data that can be used to generate SSN, credit card numbers etc. Migrating from Exchange Transport Rules to Unified DLP - The complete playbook Train End Users for adoption of sensitivity labels","title":"Helpful Resources"},{"location":"enduser/dlpenduser/","text":"Microsoft DLP User Education & User Experience \u2693\ufe0e Purpose \u2693\ufe0e The purpose of this document is to educate end users on the end user experience across O365 DLP when a violation occurs. Context \u2693\ufe0e Based on the service consumed by the user, a user might be blocked from doing certain action on the various channels covered by O365 DLP, the purpose of this document is to educate on how to react in case a violation occurred, and an action is required, by doing this user will be familiar with the procedure and will get educated. Channels Covered by O365 DLP Device (Your corporate desktop) Exchange Online (Your mailbox) SharePoint / OneDrive (your corporate shared / personal storage) Teams (Your corporate collaboration platform) Notifications on your desktop when using or reproducing sensitive content: Based on your activities on the device, you (the end user), might violate a corporate policy for certain content of data being exfiltrated based on various activities on the endpoint, the list of activities that might trigger an action are the following: Upload to cloud service domains or access by unallowed browsers Copy to Clipboard Copy to a USB removable media. Copy to network share. Access by unallowed apps Print Transfer via Bluetooth Remote Desktop Services Based on the corporate policy some actions from the above list may trigger an audit action, block restriction, or block with an option to override. To get familiar with the look and feel the Block & Block with override activities the following Toast message (right low corner) will pop up when a violation occurs. Block with no override option When blocked without an option to override, a user violating a policy will get the following a popup message (toast message): Figure 1: Toast message: Block no override. Block with override option When blocked with an option to override, an administrator might allow you to pick from a pre-defined list of options with an option to input a customized text: Figure 2: Toast message: Block with override. Figure 3: Toast message: Block with override, Business justification options. Figure 4: Toast message: Block with override, business justification options, notes. Notifications on your outlook when sharing sensitive content \u2693\ufe0e When sending an email with sensitive data, this email might be rejected from being sent out to the recipient. Based on the policy setting, you may get a message prior the sent out with a Policy Tip notifying that your about to violate a DLP policy and it might be blocked. Figure 5: Email with policy time. Figure 6: Send block notification. In some use cases you might be able to send the message and you will get blocked on post send, by configuration a user might get a notification that details the violating message and action taken with an explanation (configured by the corporate administrator). Figure 7: DLP email notification of violation. Notification on Microsoft Teams when sharing sensitive content \u2693\ufe0e A DLP policy helps organizations prevent data loss. It also helps users to make better decisions when sending Sensitive Information Types knowingly or unknowingly. Currently, Teams-DLP supports protecting data while sharing a message or a file that contains sensitive information via 1-1 Chat or through channel messages. Protecting Sensitive Information in Messages: If someone is trying to share a chat message that contains sensitive information to an external user/guest, based on the creation of DLP-Rule for the Teams workload, the message will be blocked within seconds. Both the sender and receiver see the message blocked notification. User Experience Sender\u2019s Screen: The Sender is attempting to send credit card information to the newly created federation user via 1-1 chat: Figure 8: Sending Teams Message. Figure 9: Message blocked on sender. The message is blocked as the DLP rule is activated and the sender is notified: Receiver Screen: Figure 10: Message blocked and removed on receiver. The receiver gets a blank blocked message, as shown below. Please note that there will be a delay of a few seconds in blocking the message and which is normal behavior (passive DLP). Teams DLP end user experience - Video Protecting Sensitive Information in Documents Sharing: \u2693\ufe0e If a user attempts to share a document that contains sensitive information with external users/guests in a Microsoft Teams Channel or chat, the DLP rule prevents opening the document by the external user. Note that, in this case, the DLP policy must include SharePoint and OneDrive locations for protection to be in place. SharePoint / OneDrive Online In SharePoint and OneDrive Online as a user you might share files and documents with internal and external entities, based on your organizational settings you might violate corporate policy with an action of notifying or blocking your documents / files from being shared. In case of a policy violation, you might receive an email + Policy Tip detailing the violation and the desired course of action. For example, a red triangle will appear near to a file that violated a policy (Argentina National identity number) Figure 11: Document with violation. An email explaining the violation might be sent to you as a user. Figure 12: Email of policy violation. And a policy tip might appear as well. Figure 13: Policy tip. In some cases your admin might configure the ability to override a violating file / document, in such scenario before overriding the violating file will appear with the red triangle. Figure 14: Document with violation. And after overriding the red triangle notification will be removed. Figure 15: Document after override. To override you need to select \u201cOverride the policy if you have a business justification, all policy overrides are recorded\u201d. Figure 16: Policy tip with override. In more severe cases your admin might set a policy that will block you from sharing a file containing sensitive content, in such case you will get a message stating that the file cant be shared and a \u201cNo entry\u201d sign. Figure 17: Document with block icon. On sharing dialog: Figure 18: Sharing dialog box. And a policy tip stating: Figure 19: Policy tip.","title":"DLP User Education & User Experience"},{"location":"enduser/dlpenduser/#microsoft-dlp-user-education-user-experience","text":"","title":"Microsoft DLP User Education &amp; User Experience"},{"location":"enduser/dlpenduser/#purpose","text":"The purpose of this document is to educate end users on the end user experience across O365 DLP when a violation occurs.","title":"Purpose"},{"location":"enduser/dlpenduser/#context","text":"Based on the service consumed by the user, a user might be blocked from doing certain action on the various channels covered by O365 DLP, the purpose of this document is to educate on how to react in case a violation occurred, and an action is required, by doing this user will be familiar with the procedure and will get educated. Channels Covered by O365 DLP Device (Your corporate desktop) Exchange Online (Your mailbox) SharePoint / OneDrive (your corporate shared / personal storage) Teams (Your corporate collaboration platform) Notifications on your desktop when using or reproducing sensitive content: Based on your activities on the device, you (the end user), might violate a corporate policy for certain content of data being exfiltrated based on various activities on the endpoint, the list of activities that might trigger an action are the following: Upload to cloud service domains or access by unallowed browsers Copy to Clipboard Copy to a USB removable media. Copy to network share. Access by unallowed apps Print Transfer via Bluetooth Remote Desktop Services Based on the corporate policy some actions from the above list may trigger an audit action, block restriction, or block with an option to override. To get familiar with the look and feel the Block & Block with override activities the following Toast message (right low corner) will pop up when a violation occurs. Block with no override option When blocked without an option to override, a user violating a policy will get the following a popup message (toast message): Figure 1: Toast message: Block no override. Block with override option When blocked with an option to override, an administrator might allow you to pick from a pre-defined list of options with an option to input a customized text: Figure 2: Toast message: Block with override. Figure 3: Toast message: Block with override, Business justification options. Figure 4: Toast message: Block with override, business justification options, notes.","title":"Context"},{"location":"enduser/dlpenduser/#notifications-on-your-outlook-when-sharing-sensitive-content","text":"When sending an email with sensitive data, this email might be rejected from being sent out to the recipient. Based on the policy setting, you may get a message prior the sent out with a Policy Tip notifying that your about to violate a DLP policy and it might be blocked. Figure 5: Email with policy time. Figure 6: Send block notification. In some use cases you might be able to send the message and you will get blocked on post send, by configuration a user might get a notification that details the violating message and action taken with an explanation (configured by the corporate administrator). Figure 7: DLP email notification of violation.","title":"Notifications on your outlook when sharing sensitive content"},{"location":"enduser/dlpenduser/#notification-on-microsoft-teams-when-sharing-sensitive-content","text":"A DLP policy helps organizations prevent data loss. It also helps users to make better decisions when sending Sensitive Information Types knowingly or unknowingly. Currently, Teams-DLP supports protecting data while sharing a message or a file that contains sensitive information via 1-1 Chat or through channel messages. Protecting Sensitive Information in Messages: If someone is trying to share a chat message that contains sensitive information to an external user/guest, based on the creation of DLP-Rule for the Teams workload, the message will be blocked within seconds. Both the sender and receiver see the message blocked notification. User Experience Sender\u2019s Screen: The Sender is attempting to send credit card information to the newly created federation user via 1-1 chat: Figure 8: Sending Teams Message. Figure 9: Message blocked on sender. The message is blocked as the DLP rule is activated and the sender is notified: Receiver Screen: Figure 10: Message blocked and removed on receiver. The receiver gets a blank blocked message, as shown below. Please note that there will be a delay of a few seconds in blocking the message and which is normal behavior (passive DLP). Teams DLP end user experience - Video","title":"Notification on Microsoft Teams when sharing sensitive content"},{"location":"enduser/dlpenduser/#protecting-sensitive-information-in-documents-sharing","text":"If a user attempts to share a document that contains sensitive information with external users/guests in a Microsoft Teams Channel or chat, the DLP rule prevents opening the document by the external user. Note that, in this case, the DLP policy must include SharePoint and OneDrive locations for protection to be in place. SharePoint / OneDrive Online In SharePoint and OneDrive Online as a user you might share files and documents with internal and external entities, based on your organizational settings you might violate corporate policy with an action of notifying or blocking your documents / files from being shared. In case of a policy violation, you might receive an email + Policy Tip detailing the violation and the desired course of action. For example, a red triangle will appear near to a file that violated a policy (Argentina National identity number) Figure 11: Document with violation. An email explaining the violation might be sent to you as a user. Figure 12: Email of policy violation. And a policy tip might appear as well. Figure 13: Policy tip. In some cases your admin might configure the ability to override a violating file / document, in such scenario before overriding the violating file will appear with the red triangle. Figure 14: Document with violation. And after overriding the red triangle notification will be removed. Figure 15: Document after override. To override you need to select \u201cOverride the policy if you have a business justification, all policy overrides are recorded\u201d. Figure 16: Policy tip with override. In more severe cases your admin might set a policy that will block you from sharing a file containing sensitive content, in such case you will get a message stating that the file cant be shared and a \u201cNo entry\u201d sign. Figure 17: Document with block icon. On sharing dialog: Figure 18: Sharing dialog box. And a policy tip stating: Figure 19: Policy tip.","title":"Protecting Sensitive Information in Documents Sharing:"},{"location":"enduser/retention/","text":"End User Training for Retention Labels \u2693\ufe0e The following training is provided to help educate end users during the adoption of retention labels. Please note that ' Munson's Pickles and Preserves Farm ' is a fictitious company name and angle brackets \" <> \" with RED text enable the training to be updated for deployment, adoption and education for each industry or regulatory compliance. In summary, this training will help to: Drive adoption & awareness for organizational change of using retention labels Understand the need for classification and governance of items. Develop an awareness for regulatory compliance of items. Ensure a consistent knowledge of retention labels. Find resources to support the implementation of retention labels. Email messaging \u2693\ufe0e Link File Type Topic Download .msg Awarness retention labels and what is governance Download .msg Please help drive adoption of governing items at work Download .msg Take action! Start using Microsoft Information Governance Cubicle posters \u2693\ufe0e Link File Type Topic Download .pptx Munson\u2019s Pickles and Preserves Farm Gamification Quiz Posters Download .pptx Munson\u2019s Pickles and Preserves Farm Retention_Campaign_DigitalSignage Download .pptx Munson's Pickles and Preserves Farm Know your retention Training materials \u2693\ufe0e Link File Type Topic Download .docm Munson's Pickles and Preserves Farm-Getting started with retention labels Download .docm Munson's Pickles and Preserves Farm-Help and Support Resources retention labels Download .docx Munson's Pickles and Preserves retention & Examples All files download \u2693\ufe0e Download the full Retention Labeling End User Training documentation from here","title":"Retention Labels"},{"location":"enduser/retention/#end-user-training-for-retention-labels","text":"The following training is provided to help educate end users during the adoption of retention labels. Please note that ' Munson's Pickles and Preserves Farm ' is a fictitious company name and angle brackets \" <> \" with RED text enable the training to be updated for deployment, adoption and education for each industry or regulatory compliance. In summary, this training will help to: Drive adoption & awareness for organizational change of using retention labels Understand the need for classification and governance of items. Develop an awareness for regulatory compliance of items. Ensure a consistent knowledge of retention labels. Find resources to support the implementation of retention labels.","title":"End User Training for Retention Labels"},{"location":"enduser/retention/#email-messaging","text":"Link File Type Topic Download .msg Awarness retention labels and what is governance Download .msg Please help drive adoption of governing items at work Download .msg Take action! Start using Microsoft Information Governance","title":"Email messaging"},{"location":"enduser/retention/#cubicle-posters","text":"Link File Type Topic Download .pptx Munson\u2019s Pickles and Preserves Farm Gamification Quiz Posters Download .pptx Munson\u2019s Pickles and Preserves Farm Retention_Campaign_DigitalSignage Download .pptx Munson's Pickles and Preserves Farm Know your retention","title":"Cubicle posters"},{"location":"enduser/retention/#training-materials","text":"Link File Type Topic Download .docm Munson's Pickles and Preserves Farm-Getting started with retention labels Download .docm Munson's Pickles and Preserves Farm-Help and Support Resources retention labels Download .docx Munson's Pickles and Preserves retention & Examples","title":"Training materials"},{"location":"enduser/retention/#all-files-download","text":"Download the full Retention Labeling End User Training documentation from here","title":"All files download"},{"location":"enduser/sensitivity/","text":"End User Training for Sensitivity Labels \u2693\ufe0e The following training is provided to help educate end users during the adoption of sensitivity labels. Please note that ' Munson's Pickles and Preserves Farm ' is a fictitious company name and angle brackets \" <> \" with RED text enable the training to be updated for deployment, adoption and education for each industry or regulatory compliance. In summary, this training will help to: Drive adoption & awareness for organizational change of using sensitivity labels Understand the need for classification and protection of documents. Develop an awareness for regulatory compliance of documents. Ensure a consistent knowledge of sensitivity labels. Find resources to support the implementation of sensitivity labels Email messaging \u2693\ufe0e Link Type Topic Download .msg Awareness Data labels and what is sensitive information Download .msg Please help drive adoption of labeling sensitive data Download .msg Take action! Start using Microsoft Information Protection Cubicle posters \u2693\ufe0e Link Type Topic Download .pptx Munson\u2019s Pickles and Preserves Farm Data_Class_Campaign_DigitalSignage Download .pptx Munson\u2019s Pickles and Preserves Farm Gamification Quiz Posters Download .pptx Munson's Pickles and Preserves Farm Know your labels Training materials \u2693\ufe0e Link Type Topic Download .docx Munson's Pickles and Preserves Farm Data Labels & Examples Download .docm Munson's Pickles and Preserves Farm-Getting started with data labels Download .docm Munson's Pickles and Preserves Farm-Help and Support Resources data labels All files download \u2693\ufe0e Sensitivity Labeling End User Training documentation from here","title":"Sensitivity Labels"},{"location":"enduser/sensitivity/#end-user-training-for-sensitivity-labels","text":"The following training is provided to help educate end users during the adoption of sensitivity labels. Please note that ' Munson's Pickles and Preserves Farm ' is a fictitious company name and angle brackets \" <> \" with RED text enable the training to be updated for deployment, adoption and education for each industry or regulatory compliance. In summary, this training will help to: Drive adoption & awareness for organizational change of using sensitivity labels Understand the need for classification and protection of documents. Develop an awareness for regulatory compliance of documents. Ensure a consistent knowledge of sensitivity labels. Find resources to support the implementation of sensitivity labels","title":"End User Training for Sensitivity Labels"},{"location":"enduser/sensitivity/#email-messaging","text":"Link Type Topic Download .msg Awareness Data labels and what is sensitive information Download .msg Please help drive adoption of labeling sensitive data Download .msg Take action! Start using Microsoft Information Protection","title":"Email messaging"},{"location":"enduser/sensitivity/#cubicle-posters","text":"Link Type Topic Download .pptx Munson\u2019s Pickles and Preserves Farm Data_Class_Campaign_DigitalSignage Download .pptx Munson\u2019s Pickles and Preserves Farm Gamification Quiz Posters Download .pptx Munson's Pickles and Preserves Farm Know your labels","title":"Cubicle posters"},{"location":"enduser/sensitivity/#training-materials","text":"Link Type Topic Download .docx Munson's Pickles and Preserves Farm Data Labels & Examples Download .docm Munson's Pickles and Preserves Farm-Getting started with data labels Download .docm Munson's Pickles and Preserves Farm-Help and Support Resources data labels","title":"Training materials"},{"location":"enduser/sensitivity/#all-files-download","text":"Sensitivity Labeling End User Training documentation from here","title":"All files download"},{"location":"jumpstarts/adaptive-exchange/","text":"Adaptive Policy Scopes - Exchange Workload \u2693\ufe0e The JumpStart series is intended to help companies start with a simple approach to governing data residing in the M365 platform by reducing the complexity of knowing where to start, taking the first steps to reduce risk, and complying with laws on how the data is governed. Great, but what if I don\u2019t know what I don\u2019t know. Developing an organisational policy takes time given the number of business roles involved. What data are we supposed to protect? How much data should we retain? Sadly, if you\u2019re not governing anything now, you have no way to ensure that data isn\u2019t being deleted by a disgruntled employee or someone with malicious intent while that policy gets developed. The below guidance helps you to begin gathering an understanding of the potentially sensitive data within the Exchange workload and provides helpful insights that you can use to determine what actions are needed to effectively govern this data over the next few months. The mindset behind this approach allows the start of classifying content that then can be reviewed in activity explorer and content explorer. Using content explorer Getting started with content explorer allows a quick point in time view of how the label is applied to items in M365 before acting on the data and predicts outcome for organizational compliance with regulation. Activity explorer Getting started with activity explorer builds on content explorer displaying the history of how the data is labeled. We detail a single common method for applying a retention policy that can cover the specific country/region or city, etc.. within your organization. For more of an in-depth guide to Information Governance, refer to Deployment Accelerator Guide . Do know the below step-by-step will be a cumulative activity that starts as a building block for your company's governance strategy. The first step is putting a retention policy in place to apply a base level of data governance before deciding on the labels to apply. Getting Started \u2693\ufe0e Start by using user data that contians country or region attributes Creating scopes \u2693\ufe0e Log into the Microsoft 365 compliance center at compliance.microsoft.com Select Information Governance from the left pane Figure 1: Home page of Microsoft 365 compliance center Under the Adaptive Scopes tab, click Create Scope . Figure 2: Adaptive scopes tab on Information Governance page with Create Scope action selected On the Name Your Adaptive Policy Scope page of the Create Adaptive Scope wizard, add a name for the scope and a description. Click Next to continue. Figure 3: Name Your Adaptive Policy Scope page with Name box and Description box selected User scope \u2693\ufe0e On the What Type Of Scope Do You Want To Create? Page, select Users as the scope. Click Next to continue. Figure 4: What Type Of Scope Do You Want To Create page with Users radio button selected Region attribute \u2693\ufe0e On the Create The Query To Define Users page under User Attributes section, select Country Or Region from the drop down. Figure 5: Create The Query To Define Users page with Attribute dropdown box selected Figure 6: Within the Attribute dropdown box, Country Or Region is selected In the Value box enter the name of region for the scope this applies to. Click Next to continue. Figure 7: Value text box populated with region equal to US Tip If needing to add more regions, simply click Add Attribute then repeat steps 6 & 7. You can also add City, Office, Department or Job Title attributes as well during this step. On the Review And Finish page, edit any information that maybe incorrect then click Submit. Create retention policy using scope \u2693\ufe0e Return to the Information Governance landing page and click Retention Policies tab. Figure 8: Information Governance main page with Retention Policies selected Select New Retention Policy . Figure 9: Information Governance main page with New Retention Policy selected On the Name Your Retention Policy page, add a name for the retention policy and a description. Click Next to continue. Figure 10: Name Your Retention Policy page with Name and Description fields shown Adaptive scope policy \u2693\ufe0e On the Choose The Type Of Retention Policy To Create page, select Adaptive and click Next . Figure 11: Choosing the type of retention policy with Adaptive radio button selected On the Choose Adaptive Policy Scopes And Locations page, click Add Scopes . Figure 12: Choosing the adaptive policy scope and location with Add Scopes selected On the Choose Adaptive Policy Scopes dialog box, choose the scope created earlier in step x. Click Add to continue. Figure 13: Choosing the adaptive policy scope with Email Only Region selected Adding Exchange workload \u2693\ufe0e Under the Choose Locations To Apply The Policy section, verify the only Status set to On is Exchange Email . Click Next to continue. Figure 14: Chosing the adaptive policy scope with Exchange Email Status set to On Configuring retention period \u2693\ufe0e On the Decide If You Want To Retain Content, Delete It, Or Both page, leave the radio button Retain Items For A Specific Period selected, choose Custom from the dropdown menu then adjust the retention to 1 year and finally select the Do Nothing radio button. Click Next to continue. Figure 15: Configuring retention period to 1 year and at the end of this period Do Nothing enabled Lastly, review settings and make changes if need be then click Submit . On behalf of the G overnance, e Discovery, A udit, R ecords -GEAR engineering team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP, Compliance SME","title":"Exchange Workload"},{"location":"jumpstarts/adaptive-exchange/#adaptive-policy-scopes-exchange-workload","text":"The JumpStart series is intended to help companies start with a simple approach to governing data residing in the M365 platform by reducing the complexity of knowing where to start, taking the first steps to reduce risk, and complying with laws on how the data is governed. Great, but what if I don\u2019t know what I don\u2019t know. Developing an organisational policy takes time given the number of business roles involved. What data are we supposed to protect? How much data should we retain? Sadly, if you\u2019re not governing anything now, you have no way to ensure that data isn\u2019t being deleted by a disgruntled employee or someone with malicious intent while that policy gets developed. The below guidance helps you to begin gathering an understanding of the potentially sensitive data within the Exchange workload and provides helpful insights that you can use to determine what actions are needed to effectively govern this data over the next few months. The mindset behind this approach allows the start of classifying content that then can be reviewed in activity explorer and content explorer. Using content explorer Getting started with content explorer allows a quick point in time view of how the label is applied to items in M365 before acting on the data and predicts outcome for organizational compliance with regulation. Activity explorer Getting started with activity explorer builds on content explorer displaying the history of how the data is labeled. We detail a single common method for applying a retention policy that can cover the specific country/region or city, etc.. within your organization. For more of an in-depth guide to Information Governance, refer to Deployment Accelerator Guide . Do know the below step-by-step will be a cumulative activity that starts as a building block for your company's governance strategy. The first step is putting a retention policy in place to apply a base level of data governance before deciding on the labels to apply.","title":"Adaptive Policy Scopes - Exchange Workload"},{"location":"jumpstarts/adaptive-exchange/#getting-started","text":"Start by using user data that contians country or region attributes","title":"Getting Started"},{"location":"jumpstarts/adaptive-exchange/#creating-scopes","text":"Log into the Microsoft 365 compliance center at compliance.microsoft.com Select Information Governance from the left pane Figure 1: Home page of Microsoft 365 compliance center Under the Adaptive Scopes tab, click Create Scope . Figure 2: Adaptive scopes tab on Information Governance page with Create Scope action selected On the Name Your Adaptive Policy Scope page of the Create Adaptive Scope wizard, add a name for the scope and a description. Click Next to continue. Figure 3: Name Your Adaptive Policy Scope page with Name box and Description box selected","title":"Creating scopes"},{"location":"jumpstarts/adaptive-exchange/#user-scope","text":"On the What Type Of Scope Do You Want To Create? Page, select Users as the scope. Click Next to continue. Figure 4: What Type Of Scope Do You Want To Create page with Users radio button selected","title":"User scope"},{"location":"jumpstarts/adaptive-exchange/#region-attribute","text":"On the Create The Query To Define Users page under User Attributes section, select Country Or Region from the drop down. Figure 5: Create The Query To Define Users page with Attribute dropdown box selected Figure 6: Within the Attribute dropdown box, Country Or Region is selected In the Value box enter the name of region for the scope this applies to. Click Next to continue. Figure 7: Value text box populated with region equal to US Tip If needing to add more regions, simply click Add Attribute then repeat steps 6 & 7. You can also add City, Office, Department or Job Title attributes as well during this step. On the Review And Finish page, edit any information that maybe incorrect then click Submit.","title":"Region attribute"},{"location":"jumpstarts/adaptive-exchange/#create-retention-policy-using-scope","text":"Return to the Information Governance landing page and click Retention Policies tab. Figure 8: Information Governance main page with Retention Policies selected Select New Retention Policy . Figure 9: Information Governance main page with New Retention Policy selected On the Name Your Retention Policy page, add a name for the retention policy and a description. Click Next to continue. Figure 10: Name Your Retention Policy page with Name and Description fields shown","title":"Create retention policy using scope"},{"location":"jumpstarts/adaptive-exchange/#adaptive-scope-policy","text":"On the Choose The Type Of Retention Policy To Create page, select Adaptive and click Next . Figure 11: Choosing the type of retention policy with Adaptive radio button selected On the Choose Adaptive Policy Scopes And Locations page, click Add Scopes . Figure 12: Choosing the adaptive policy scope and location with Add Scopes selected On the Choose Adaptive Policy Scopes dialog box, choose the scope created earlier in step x. Click Add to continue. Figure 13: Choosing the adaptive policy scope with Email Only Region selected","title":"Adaptive scope policy"},{"location":"jumpstarts/adaptive-exchange/#adding-exchange-workload","text":"Under the Choose Locations To Apply The Policy section, verify the only Status set to On is Exchange Email . Click Next to continue. Figure 14: Chosing the adaptive policy scope with Exchange Email Status set to On","title":"Adding Exchange workload"},{"location":"jumpstarts/adaptive-exchange/#configuring-retention-period","text":"On the Decide If You Want To Retain Content, Delete It, Or Both page, leave the radio button Retain Items For A Specific Period selected, choose Custom from the dropdown menu then adjust the retention to 1 year and finally select the Do Nothing radio button. Click Next to continue. Figure 15: Configuring retention period to 1 year and at the end of this period Do Nothing enabled Lastly, review settings and make changes if need be then click Submit . On behalf of the G overnance, e Discovery, A udit, R ecords -GEAR engineering team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP, Compliance SME","title":"Configuring retention period"},{"location":"jumpstarts/kql-exchange/","text":"AutoApply with KQL - Exchange Workload \u2693\ufe0e The JumpStart series is intended to help companies start with a simple approach to governing data residing in the M365 platform by reducing the complexity of knowing where to start, taking the first steps to reduce risk, and complying with laws on how the data is governed. Great, but what if I don\u2019t know what I don\u2019t know. Developing an organisational policy takes time given the number of business roles involved. What data are we supposed to protect? How much data should we retain? Sadly, if you\u2019re not governing anything now, you have no way to ensure that data isn\u2019t being deleted by a disgruntled employee or someone with malicious intent while that policy gets developed. The below guidance helps you to begin gathering an understanding of the potentially sensitive data within the Exchange workload and provides helpful insights that you can use to determine what actions are needed to effectively govern this data over the next few months. The mindset behind this approach allows the start of classifying content that then can be reviewed in activity explorer and content explorer. Using content explorer Getting started with content explorer allows a quick point in time view of how the label is applied to items in M365 before acting on the data and predicts outcome for organizational compliance with regulation. Activity explorer Getting started with activity explorer builds on content explorer displaying the history of how the data is labeled. We detail a single common method for auto applying a retention label that queries emails between certian time periods within your organization. For more of an in-depth guide to Information Governance, refer to Deployment Accelerator Guide . Do know the below step-by-step will be a cumulative activity that starts as a building block for your company's governance strategy. The first step is putting a retention policy in place to apply a base level of data governance before deciding on the labels to apply. Getting Started \u2693\ufe0e Start by configuring retention label that retains only Creating retention label \u2693\ufe0e Log into the Microsoft 365 compliance center at compliance.microsoft.com Select Information Governance from the left pane Figure 1: Home page of Microsoft 365 compliance center On the main page of Information Governance , click Labels tab then click Create A Label . Figure 2: Labels tab on Information Governance page with Create A Label selected On the Name Your Retention Label page of the Create Retention Label wizard, add a name for the label and a description. Click Next to continue. Figure 3: Name Your Retention Label page with Name box and Description box selected On the Define Retention Settings page, leave the radio button Retain Items For A Specific Period selected, choose Custom from the dropdown menu then adjust the retention to 3 years and finally select Do Nothing radio buttons. Click Next to continue. Figure 4: Configuring retention period to 3 years and at the end of this period Do Nothing enabled Lastly, review settings and make changes if need be then click Create Label . Auto-applying a label using KQL query \u2693\ufe0e On the Information Governance page, under the Label Policies tab click Auto-apply A Label . Figure 5: Labels Policies tab on Information Governance page with Auto-apply A Label selected On the Let's Get Started page of the Create Auto-labeling Policy add a name for the label and a description. Click Next to continue. Figure 6: Let's Get Started page with Name box and Description box selected On the Choose The Type Of Content You Want To Apply This Label To page, select Apply Label To Content That Contains Specific Words Or Phrases, Or Properties radio button. Click Next to continue. Figure 7: Selecting the type of content to apply label to Adding KQL query criteria \u2693\ufe0e On the Apply Label To Content Matching This Query page, enter the KQL query in the Conditions box as shown below. Click Next to continue. Figure 8: Inputing KQL query into the Conditions box for content that mataches query Static Scope \u2693\ufe0e On the Choose The Type Of Retenetion Policy To Create page, select Static as the scope and then click Next to continue. Figure 9: Selecting Static scope Adding Exchange workload \u2693\ufe0e On the Choose Locations To Apply The Policy page, ensure the Status for Exchange Email is set to On only and then click Next to continue. Figure 10: Choosing Exchange Email workload only to apply policy location to Adding retention label to policy \u2693\ufe0e On the Choose A Label To Auto-apply page, click Add Label then choose the label you created earlier. Click Add and click Next . Figure 11: Selecting retention label for auto-apply policy Lastly, review settings and make changes if need be then click Submit . On behalf of the G overnance, e Discovery, A udit, R ecords -GEAR engineering team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP, Compliance SME","title":"Using KQL Exchange Workload"},{"location":"jumpstarts/kql-exchange/#autoapply-with-kql-exchange-workload","text":"The JumpStart series is intended to help companies start with a simple approach to governing data residing in the M365 platform by reducing the complexity of knowing where to start, taking the first steps to reduce risk, and complying with laws on how the data is governed. Great, but what if I don\u2019t know what I don\u2019t know. Developing an organisational policy takes time given the number of business roles involved. What data are we supposed to protect? How much data should we retain? Sadly, if you\u2019re not governing anything now, you have no way to ensure that data isn\u2019t being deleted by a disgruntled employee or someone with malicious intent while that policy gets developed. The below guidance helps you to begin gathering an understanding of the potentially sensitive data within the Exchange workload and provides helpful insights that you can use to determine what actions are needed to effectively govern this data over the next few months. The mindset behind this approach allows the start of classifying content that then can be reviewed in activity explorer and content explorer. Using content explorer Getting started with content explorer allows a quick point in time view of how the label is applied to items in M365 before acting on the data and predicts outcome for organizational compliance with regulation. Activity explorer Getting started with activity explorer builds on content explorer displaying the history of how the data is labeled. We detail a single common method for auto applying a retention label that queries emails between certian time periods within your organization. For more of an in-depth guide to Information Governance, refer to Deployment Accelerator Guide . Do know the below step-by-step will be a cumulative activity that starts as a building block for your company's governance strategy. The first step is putting a retention policy in place to apply a base level of data governance before deciding on the labels to apply.","title":"AutoApply with KQL - Exchange Workload"},{"location":"jumpstarts/kql-exchange/#getting-started","text":"Start by configuring retention label that retains only","title":"Getting Started"},{"location":"jumpstarts/kql-exchange/#creating-retention-label","text":"Log into the Microsoft 365 compliance center at compliance.microsoft.com Select Information Governance from the left pane Figure 1: Home page of Microsoft 365 compliance center On the main page of Information Governance , click Labels tab then click Create A Label . Figure 2: Labels tab on Information Governance page with Create A Label selected On the Name Your Retention Label page of the Create Retention Label wizard, add a name for the label and a description. Click Next to continue. Figure 3: Name Your Retention Label page with Name box and Description box selected On the Define Retention Settings page, leave the radio button Retain Items For A Specific Period selected, choose Custom from the dropdown menu then adjust the retention to 3 years and finally select Do Nothing radio buttons. Click Next to continue. Figure 4: Configuring retention period to 3 years and at the end of this period Do Nothing enabled Lastly, review settings and make changes if need be then click Create Label .","title":"Creating retention label"},{"location":"jumpstarts/kql-exchange/#auto-applying-a-label-using-kql-query","text":"On the Information Governance page, under the Label Policies tab click Auto-apply A Label . Figure 5: Labels Policies tab on Information Governance page with Auto-apply A Label selected On the Let's Get Started page of the Create Auto-labeling Policy add a name for the label and a description. Click Next to continue. Figure 6: Let's Get Started page with Name box and Description box selected On the Choose The Type Of Content You Want To Apply This Label To page, select Apply Label To Content That Contains Specific Words Or Phrases, Or Properties radio button. Click Next to continue. Figure 7: Selecting the type of content to apply label to","title":"Auto-applying a label using KQL query"},{"location":"jumpstarts/kql-exchange/#adding-kql-query-criteria","text":"On the Apply Label To Content Matching This Query page, enter the KQL query in the Conditions box as shown below. Click Next to continue. Figure 8: Inputing KQL query into the Conditions box for content that mataches query","title":"Adding KQL query criteria"},{"location":"jumpstarts/kql-exchange/#static-scope","text":"On the Choose The Type Of Retenetion Policy To Create page, select Static as the scope and then click Next to continue. Figure 9: Selecting Static scope","title":"Static Scope"},{"location":"jumpstarts/kql-exchange/#adding-exchange-workload","text":"On the Choose Locations To Apply The Policy page, ensure the Status for Exchange Email is set to On only and then click Next to continue. Figure 10: Choosing Exchange Email workload only to apply policy location to","title":"Adding Exchange workload"},{"location":"jumpstarts/kql-exchange/#adding-retention-label-to-policy","text":"On the Choose A Label To Auto-apply page, click Add Label then choose the label you created earlier. Click Add and click Next . Figure 11: Selecting retention label for auto-apply policy Lastly, review settings and make changes if need be then click Submit . On behalf of the G overnance, e Discovery, A udit, R ecords -GEAR engineering team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP, Compliance SME","title":"Adding retention label to policy"},{"location":"notes/ComplianceEdu/","text":"Info Please contribute suggestions or additional scenarios. Overview \u2693\ufe0e These notes from the field is designed to help our education customers understand some use case scenarios for using the Microsoft compliance products in their environment. This is not meant to be a full list of scenarios or designed to be a deep guidance on how to directly implement these. This is more of some common scenarios and examples we see at K-12 education customers to help give you our customers some ideas and insights of what is possible. Communication Compliance \u2693\ufe0e Overview \u2693\ufe0e Communication compliance is a solution that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate scanned email, Microsoft Teams, Yammer, or third-party communications in your organization and take appropriate actions to make sure they're compliant with your organization's message standards. Scenario \u2693\ufe0e To see how a school might approach communication compliance, consider the following example: A local high school has issued their students laptops for school use. To mitigate student harassment within the school\u2019s network, the IT team created communication compliance policies. Since students communicate mainly via Teams, they created a policy to monitor Teams for any profanity or harassment. With the policy in place, teachers of specific classes and school admin will be notified when the system flags harmful messages. Teachers and admins can then investigate the issues and even have the capabilities to work with IT to remove messages to limit exposure. Additional Resources \u2693\ufe0e Learn more about Communication Compliance by reading the Compliance CxE Playbook Visit Communication compliance in Microsoft 365 - Microsoft Docs to learn more about Communication Compliance configuration Information Barriers \u2693\ufe0e Overview \u2693\ufe0e With information barriers, you can define policies that are designed to prevent certain segments of users from communicating with each other or allow specific segments to communicate only with certain other segments. Information barrier policies can help your organization maintain compliance with relevant industry standards and regulations and avoid potential conflicts of interest. Scenario \u2693\ufe0e To see how a school might approach defining segments and policies, consider the following example: A local district has four elementary schools. To minimize distractions, students from different schools are not allowed to interact with each other on Teams. To enable this, the districts IT team will have to create a segment for each elementary school and assign students to their respective school. Then, IT will have to create a policy for each school designed to prevent communication between them. With the segments and policies defined, the IT team will then apply the policies and barriers will be in place to prevent communication between the elementary schools in the district. Additional Resources \u2693\ufe0e Learn more about Information Barriers by reading the Compliance CxE Playbook Visit Microsoft 365 Compliance Information Barriers - Microsoft Docs to learn more about Information Barriers configuration Data Loss Prevention \u2693\ufe0e Overview \u2693\ufe0e Data loss prevention is an important issue for an organization\u2019s message systems because of the extensive use of communication channels that includes sensitive data. In order to enforce compliance requirements for such data, and manage its use in communication channels, without hindering the productivity of workers, Data Loss Prevention features make managing sensitive data easier than ever before. Scenario \u2693\ufe0e To see how a school might approach Data Loss Prevention, consider the following example: School districts rely on 3rd party organizations to help with classroom curriculum, improve student outcomes, and evaluate the effectiveness of the school programs. Student scores will be shared to help with the efforts but to ensure personal student information isn\u2019t shared outside of the district, the school district\u2019s IT department needs to create Data Loss Prevention policies for student information. The configured policies will protect student data from being shared outside of their respective schools. If there is an attempt to share information with anyone outside of the school, the rule will go into effect and interaction will be flagged. IT has the ability to block access to the records being shared and is some cases prevent the initial communication containing the personal records from being delivered. Additional Resources \u2693\ufe0e Learn more about Data Loss Prevention by reading the Compliance CxE Playbook Visit Data loss prevention - Microsoft Docs to learn more about Data Loss Prevention configuration Microsoft Information Protection \u2693\ufe0e Overview \u2693\ufe0e Microsoft Information Protection helps organizations discover, classify, and protect sensitive data wherever it lives and travels. It provides the tools to understand your data, protect it, and prevent data loss. Scenario \u2693\ufe0e To see how a school might approach Information Protection, consider the following example: A local middle school wants to ensure that staff aren\u2019t accessing sensitive school resources on devices that are not managed by the school (home machines). To ensure that the school\u2019s data is protected, the IT department leverages Microsoft Information Protection to protect sensitive student information such as student records from being accessed on unmanaged devices. If a staff member tries logging onto their school account from a personal device and try accessing their records, access to the records will be denied because of the protection set up around the sensitive data. The IT department can set up similar protections for other applications and sensitive data from unmanaged devices. Additional Resources \u2693\ufe0e Learn more about Information Protection by reading the Compliance CxE Playbook Visit Microsoft Information Protection - Microsoft Docs to learn more about data protection Advanced eDiscovery and Advanced Audit \u2693\ufe0e Overview \u2693\ufe0e Advanced eDiscovery provides an end-to-end workflow to preserve, collect, analyze, review, and export content that's responsive to your organization's internal and external investigations. Advanced Audit helps organizations conduct forensic and compliance investigations by increasing audit log retention and providing access to events related to the investigation. Scenario \u2693\ufe0e To see how a school might approach Advanced eDiscovery and Advanced Audit, consider the following example: A local high school launched an investigation into a bullying incident. The communication compliance flagged communications for harassment between two 11th grade students. By leveraging Advanced eDiscovery, the IT department and admins were able to pull all of the communication interactions between the two students. Records showed that there were several harmful messages between the students. As the school launched an investigation, they used Advanced Audit to retain records of the interactions past the 90-day retention period in order aid the investigation until it\u2019s completion. Additional Resources \u2693\ufe0e Learn more about Advanced eDiscovery and Advanced Audit by reading the Compliance CxE Playbook Visit Advanced eDiscovery solution in Microsoft 365 - Microsoft Docs to learn more about Advanced eDiscovery configuration Visit Advanced Audit in Microsoft 365 - Microsoft Docs to learn more about Advanced Audit configuration","title":"Compliance in K-12 Education"},{"location":"notes/ComplianceEdu/#overview","text":"These notes from the field is designed to help our education customers understand some use case scenarios for using the Microsoft compliance products in their environment. This is not meant to be a full list of scenarios or designed to be a deep guidance on how to directly implement these. This is more of some common scenarios and examples we see at K-12 education customers to help give you our customers some ideas and insights of what is possible.","title":"Overview"},{"location":"notes/ComplianceEdu/#communication-compliance","text":"","title":"Communication Compliance"},{"location":"notes/ComplianceEdu/#overview_1","text":"Communication compliance is a solution that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so they can be examined by designated reviewers. Reviewers can investigate scanned email, Microsoft Teams, Yammer, or third-party communications in your organization and take appropriate actions to make sure they're compliant with your organization's message standards.","title":"Overview"},{"location":"notes/ComplianceEdu/#scenario","text":"To see how a school might approach communication compliance, consider the following example: A local high school has issued their students laptops for school use. To mitigate student harassment within the school\u2019s network, the IT team created communication compliance policies. Since students communicate mainly via Teams, they created a policy to monitor Teams for any profanity or harassment. With the policy in place, teachers of specific classes and school admin will be notified when the system flags harmful messages. Teachers and admins can then investigate the issues and even have the capabilities to work with IT to remove messages to limit exposure.","title":"Scenario"},{"location":"notes/ComplianceEdu/#additional-resources","text":"Learn more about Communication Compliance by reading the Compliance CxE Playbook Visit Communication compliance in Microsoft 365 - Microsoft Docs to learn more about Communication Compliance configuration","title":"Additional Resources"},{"location":"notes/ComplianceEdu/#information-barriers","text":"","title":"Information Barriers"},{"location":"notes/ComplianceEdu/#overview_2","text":"With information barriers, you can define policies that are designed to prevent certain segments of users from communicating with each other or allow specific segments to communicate only with certain other segments. Information barrier policies can help your organization maintain compliance with relevant industry standards and regulations and avoid potential conflicts of interest.","title":"Overview"},{"location":"notes/ComplianceEdu/#scenario_1","text":"To see how a school might approach defining segments and policies, consider the following example: A local district has four elementary schools. To minimize distractions, students from different schools are not allowed to interact with each other on Teams. To enable this, the districts IT team will have to create a segment for each elementary school and assign students to their respective school. Then, IT will have to create a policy for each school designed to prevent communication between them. With the segments and policies defined, the IT team will then apply the policies and barriers will be in place to prevent communication between the elementary schools in the district.","title":"Scenario"},{"location":"notes/ComplianceEdu/#additional-resources_1","text":"Learn more about Information Barriers by reading the Compliance CxE Playbook Visit Microsoft 365 Compliance Information Barriers - Microsoft Docs to learn more about Information Barriers configuration","title":"Additional Resources"},{"location":"notes/ComplianceEdu/#data-loss-prevention","text":"","title":"Data Loss Prevention"},{"location":"notes/ComplianceEdu/#overview_3","text":"Data loss prevention is an important issue for an organization\u2019s message systems because of the extensive use of communication channels that includes sensitive data. In order to enforce compliance requirements for such data, and manage its use in communication channels, without hindering the productivity of workers, Data Loss Prevention features make managing sensitive data easier than ever before.","title":"Overview"},{"location":"notes/ComplianceEdu/#scenario_2","text":"To see how a school might approach Data Loss Prevention, consider the following example: School districts rely on 3rd party organizations to help with classroom curriculum, improve student outcomes, and evaluate the effectiveness of the school programs. Student scores will be shared to help with the efforts but to ensure personal student information isn\u2019t shared outside of the district, the school district\u2019s IT department needs to create Data Loss Prevention policies for student information. The configured policies will protect student data from being shared outside of their respective schools. If there is an attempt to share information with anyone outside of the school, the rule will go into effect and interaction will be flagged. IT has the ability to block access to the records being shared and is some cases prevent the initial communication containing the personal records from being delivered.","title":"Scenario"},{"location":"notes/ComplianceEdu/#additional-resources_2","text":"Learn more about Data Loss Prevention by reading the Compliance CxE Playbook Visit Data loss prevention - Microsoft Docs to learn more about Data Loss Prevention configuration","title":"Additional Resources"},{"location":"notes/ComplianceEdu/#microsoft-information-protection","text":"","title":"Microsoft Information Protection"},{"location":"notes/ComplianceEdu/#overview_4","text":"Microsoft Information Protection helps organizations discover, classify, and protect sensitive data wherever it lives and travels. It provides the tools to understand your data, protect it, and prevent data loss.","title":"Overview"},{"location":"notes/ComplianceEdu/#scenario_3","text":"To see how a school might approach Information Protection, consider the following example: A local middle school wants to ensure that staff aren\u2019t accessing sensitive school resources on devices that are not managed by the school (home machines). To ensure that the school\u2019s data is protected, the IT department leverages Microsoft Information Protection to protect sensitive student information such as student records from being accessed on unmanaged devices. If a staff member tries logging onto their school account from a personal device and try accessing their records, access to the records will be denied because of the protection set up around the sensitive data. The IT department can set up similar protections for other applications and sensitive data from unmanaged devices.","title":"Scenario"},{"location":"notes/ComplianceEdu/#additional-resources_3","text":"Learn more about Information Protection by reading the Compliance CxE Playbook Visit Microsoft Information Protection - Microsoft Docs to learn more about data protection","title":"Additional Resources"},{"location":"notes/ComplianceEdu/#advanced-ediscovery-and-advanced-audit","text":"","title":"Advanced eDiscovery and Advanced Audit"},{"location":"notes/ComplianceEdu/#overview_5","text":"Advanced eDiscovery provides an end-to-end workflow to preserve, collect, analyze, review, and export content that's responsive to your organization's internal and external investigations. Advanced Audit helps organizations conduct forensic and compliance investigations by increasing audit log retention and providing access to events related to the investigation.","title":"Overview"},{"location":"notes/ComplianceEdu/#scenario_4","text":"To see how a school might approach Advanced eDiscovery and Advanced Audit, consider the following example: A local high school launched an investigation into a bullying incident. The communication compliance flagged communications for harassment between two 11th grade students. By leveraging Advanced eDiscovery, the IT department and admins were able to pull all of the communication interactions between the two students. Records showed that there were several harmful messages between the students. As the school launched an investigation, they used Advanced Audit to retain records of the interactions past the 90-day retention period in order aid the investigation until it\u2019s completion.","title":"Scenario"},{"location":"notes/ComplianceEdu/#additional-resources_4","text":"Learn more about Advanced eDiscovery and Advanced Audit by reading the Compliance CxE Playbook Visit Advanced eDiscovery solution in Microsoft 365 - Microsoft Docs to learn more about Advanced eDiscovery configuration Visit Advanced Audit in Microsoft 365 - Microsoft Docs to learn more about Advanced Audit configuration","title":"Additional Resources"},{"location":"notes/mig/ms/","text":"Info Please contribute suggestions or additional scenarios. Overview \u2693\ufe0e With our previous disposition solution, when reached the end of a period of retention select individuals would receive an email notification to take an action. The 'Records Manager' or 'Disposition Reviewer' then would use the Disposition tab in Records Management to review the labels acting upon items to then dispose or permanently delete, extend the retention period or apply another label. For a detailed overview of the disposition process, refer to the Microsoft document here . Figure 1: Label creation with disposition trigger. Figure 1 above depicts a label action triggering a disposition review. Figure 2 below illustrates adding a single user or mail enabled group as disposition reviewer. Figure 2: Adding user or mail enabled security group. This process left a gap for large complex organizations needing to streamline the disposition process where all appropriate people would need to give approval before any action could be taken. One can imagine this could be a simple internal process or an extremely complex workflow. This flow led to the records manager or approver seeing all items needing disposition. Multi-Stage Features \u2693\ufe0e We heard this feedback from our customers that people should only see the items that they are assigned to and that are ready for disposition but not all items needing disposition. With this in mind, we developed multi-stage disposition. We are excited to share the new capabilities in Records Management: Multiple stage and reviewers Support for multi-geo Email customization and templates Reviewer experience (in line view, taking actions) Adding reviewers to a stage History and details tab Tip For a detailed explanation or instructions for implementing the new features of multi-stage click this link . We will discuss one such use case scenario here that leverages these new features. Scenario \u2693\ufe0e Note The example below is more a general example that can be applied to all industries as regulations or company policy may not be the same in all parts of the world. A global company that conducts business in Europe and is headquartered in California. The goal is to define a process of disposition to accommodate specific people or departments in Germany who are tasked with a review of expired records complying with BaFin , GDPR and CPRA regulations. These records consist of contracts in the region of the world the company conducts business. The record manager of the company needs to create a process for taking actions for expired records and ensure the process is followed as defined by the company\u2019s retention schedule. Some departments have a regional lead that oversees all the contract specialists in each country who might all have input into if record needs to be disposed. These subject matter experts for record types will need to approve items for disposition that are assigned to them and have the ability to view the context of the record. The company needs both the contract specialist or regional lead and records manager to approve all records requiring disposition review but only see the relevant items they are related to their job function. Contract specialists need email notifications daily with the correct instructions and approval guidance in multiple languages to accommodate global workforce. The records manager needs email notification instructions and business guidance that differ from the contract\u2019s specialist or regional lead. The records manager needs a unified disposition process across all the locations of the world and reporting for proof that disposed items are not discoverable. Lastly, if business structure or change management dictate, they require the ability to update the disposition process while adhering to the company's defined retention schedule. We will use the below workflow to map the business use case to the solution. Workflow \u2693\ufe0e Image 1: Label workflow with multi-stage disposition Relating to the requirements above, there are three users in our tenant mapping to each role. Randall Testuser \u2013 Contract\u2019s Specialist in Europe (Germany) Joanna Hackett \u2013 WW Lead for Contracts MIG Admin \u2013 Records Manager As you can see from the Figure 3 below both Joanna Hackett and MIG Admin are located in the United States (California). Figure 3: User with PDL in Germany Randall works in Germany as shown in Figure 4 . Figure 4: User with PDL in USA Note For an overview of M365 multi-geo and Preferred Data Location (PDL) visit here Label Creation \u2693\ufe0e We start by creating a new retention label with the record option enabled via the File Plan tab within the Records Management section of Microsoft 365 Compliance Center. The label is called Multi-Stage Multi-Geo Label , and has a 1 day retention setting, disposition (deletion) after the retention period has expired, and requiring a disposition review. The label below shows three stages and three reviewers: Stage 1 called: Germany SOW Stage 2 called: Europe SOW Approval Stage 3 called: Records Manager SOW Approval Figure 5: Settings of Multi-Stage Multi-Geo retention label. Note The label shows a setting of 1 day but should be set to the requirement of your organization or regulation. The label name could be Contracts as an example here or any other nomenclature that resonates within your business. Label Policy \u2693\ufe0e Our next step is to create a retention label policy called Multi-Stage Multi-Geo Policy publishing label Multi-Stage Multi-Geo Label . The published label covers one exchange mailbox, one SharePoint site and two user OneDrive locations. Figure 6: Auto-applied label settings. We configured the policy to apply to Randall Testuser\u2019s email, a SharePoint site used by Randall Testuser in Germany for SOWs, and to include both Randall Testuser\u2019s + MIG Admin\u2019s OneDrive locations. Email Notifications \u2693\ufe0e Next we move to configuring the email notifications once items are ready for disposal. In addition to the default message we are adding instructions for Randall Testuser on expiring SOW contracts in Germany along with instructions for California expiring SOW contracts. Notice the first line is in German ( Please verify all SOWs conform to BaFIN regulations. ) and the second line is in English. Figure 7: Customize message for email notification. Once an item is up for disposition, the persons or security group added to the first stage are sent one mail per day per label similar to the email shown below. Figure 8: Email notification from O365 Security & Compliance Center. Stage 1 Disposition \u2693\ufe0e Next, we navigate to the Microsoft 365 Compliance Center (MCC) to review items for disposition for Randall Testuser notified above in email. We see the items ready for disposition that are assigned to Randall Testuser as the approver or assigned disposition reviewer for the first stage named Germany SOW . The reviewer can now see items for all multi-geo locations for the respective label. Figure 9: Stage 1 disposition view. Compared to the view of record manager role, one can see that Randall Testuser has 17 items under the Multi-Stage Multi-Geo Label (shown in Figure 9) and MIG Admin shows 18 items including one item in the second stage called Europe SOW Approval (shown in Figure 10). Figure 10: Stage 1 and Stage 2 disposition view. Randall Testuser will follow guidance to Approve the disposition, Relabel , Extend or Add additional Reviewers to each item. Once approving an item for disposition, it will flow the second stage. Figure 11: Item view actions available. As Randall Testuser clicks on an item, he can quickly see the context to make an informed decision. Figure 12: Context view of item. Stage 2 Disposition \u2693\ufe0e Once clicking Approve the item then moves to stage 2 called Europe SOW Approval and Joanna Hackett is notified via email to then review items for disposition in the second stage. Figure 13: Stage 2 view of item. Joanna Hackett approves items and adds her comments for the disposition action as seen in Figure 14 history pane. Figure 14: History of actions and comments. Stage 3 Disposition \u2693\ufe0e Lastly the item follows the flow to the final stage for MIG Admin our records administrator to approve the disposition. Before doing so, an email was sent out by legal stating all contracts from Germany need to be immutable with a 55 year retention hold per new regulation guidance that came out in the last week. MIG Admin then adds Nancy Liang from legal to the review process. Adding additional reviewers \u2693\ufe0e Figure 15: Adding legal reviewer and comments. Relabeling \u2693\ufe0e Nancy Liang follows the same steps after receiving an email to review the item for disposition. She will then Relabel the item as a regulatory record Multi-Stage Multi-Geo Regulatory Label that has a retention record of 55 years. Figure 16: Regulatory label summary with retention duration Figure 16 shows the settings of the regulatory label and Figure 17 shows the relabeling with comments. Figure 17: Relabel action and comments On behalf of the MIG/RM PM team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP Brendon Lee - Extended Compliance CXE","title":"Notes from the field"},{"location":"notes/mig/ms/#overview","text":"With our previous disposition solution, when reached the end of a period of retention select individuals would receive an email notification to take an action. The 'Records Manager' or 'Disposition Reviewer' then would use the Disposition tab in Records Management to review the labels acting upon items to then dispose or permanently delete, extend the retention period or apply another label. For a detailed overview of the disposition process, refer to the Microsoft document here . Figure 1: Label creation with disposition trigger. Figure 1 above depicts a label action triggering a disposition review. Figure 2 below illustrates adding a single user or mail enabled group as disposition reviewer. Figure 2: Adding user or mail enabled security group. This process left a gap for large complex organizations needing to streamline the disposition process where all appropriate people would need to give approval before any action could be taken. One can imagine this could be a simple internal process or an extremely complex workflow. This flow led to the records manager or approver seeing all items needing disposition.","title":"Overview"},{"location":"notes/mig/ms/#multi-stage-features","text":"We heard this feedback from our customers that people should only see the items that they are assigned to and that are ready for disposition but not all items needing disposition. With this in mind, we developed multi-stage disposition. We are excited to share the new capabilities in Records Management: Multiple stage and reviewers Support for multi-geo Email customization and templates Reviewer experience (in line view, taking actions) Adding reviewers to a stage History and details tab Tip For a detailed explanation or instructions for implementing the new features of multi-stage click this link . We will discuss one such use case scenario here that leverages these new features.","title":"Multi-Stage Features"},{"location":"notes/mig/ms/#scenario","text":"Note The example below is more a general example that can be applied to all industries as regulations or company policy may not be the same in all parts of the world. A global company that conducts business in Europe and is headquartered in California. The goal is to define a process of disposition to accommodate specific people or departments in Germany who are tasked with a review of expired records complying with BaFin , GDPR and CPRA regulations. These records consist of contracts in the region of the world the company conducts business. The record manager of the company needs to create a process for taking actions for expired records and ensure the process is followed as defined by the company\u2019s retention schedule. Some departments have a regional lead that oversees all the contract specialists in each country who might all have input into if record needs to be disposed. These subject matter experts for record types will need to approve items for disposition that are assigned to them and have the ability to view the context of the record. The company needs both the contract specialist or regional lead and records manager to approve all records requiring disposition review but only see the relevant items they are related to their job function. Contract specialists need email notifications daily with the correct instructions and approval guidance in multiple languages to accommodate global workforce. The records manager needs email notification instructions and business guidance that differ from the contract\u2019s specialist or regional lead. The records manager needs a unified disposition process across all the locations of the world and reporting for proof that disposed items are not discoverable. Lastly, if business structure or change management dictate, they require the ability to update the disposition process while adhering to the company's defined retention schedule. We will use the below workflow to map the business use case to the solution.","title":"Scenario"},{"location":"notes/mig/ms/#workflow","text":"Image 1: Label workflow with multi-stage disposition Relating to the requirements above, there are three users in our tenant mapping to each role. Randall Testuser \u2013 Contract\u2019s Specialist in Europe (Germany) Joanna Hackett \u2013 WW Lead for Contracts MIG Admin \u2013 Records Manager As you can see from the Figure 3 below both Joanna Hackett and MIG Admin are located in the United States (California). Figure 3: User with PDL in Germany Randall works in Germany as shown in Figure 4 . Figure 4: User with PDL in USA Note For an overview of M365 multi-geo and Preferred Data Location (PDL) visit here","title":"Workflow"},{"location":"notes/mig/ms/#label-creation","text":"We start by creating a new retention label with the record option enabled via the File Plan tab within the Records Management section of Microsoft 365 Compliance Center. The label is called Multi-Stage Multi-Geo Label , and has a 1 day retention setting, disposition (deletion) after the retention period has expired, and requiring a disposition review. The label below shows three stages and three reviewers: Stage 1 called: Germany SOW Stage 2 called: Europe SOW Approval Stage 3 called: Records Manager SOW Approval Figure 5: Settings of Multi-Stage Multi-Geo retention label. Note The label shows a setting of 1 day but should be set to the requirement of your organization or regulation. The label name could be Contracts as an example here or any other nomenclature that resonates within your business.","title":"Label Creation"},{"location":"notes/mig/ms/#label-policy","text":"Our next step is to create a retention label policy called Multi-Stage Multi-Geo Policy publishing label Multi-Stage Multi-Geo Label . The published label covers one exchange mailbox, one SharePoint site and two user OneDrive locations. Figure 6: Auto-applied label settings. We configured the policy to apply to Randall Testuser\u2019s email, a SharePoint site used by Randall Testuser in Germany for SOWs, and to include both Randall Testuser\u2019s + MIG Admin\u2019s OneDrive locations.","title":"Label Policy"},{"location":"notes/mig/ms/#email-notifications","text":"Next we move to configuring the email notifications once items are ready for disposal. In addition to the default message we are adding instructions for Randall Testuser on expiring SOW contracts in Germany along with instructions for California expiring SOW contracts. Notice the first line is in German ( Please verify all SOWs conform to BaFIN regulations. ) and the second line is in English. Figure 7: Customize message for email notification. Once an item is up for disposition, the persons or security group added to the first stage are sent one mail per day per label similar to the email shown below. Figure 8: Email notification from O365 Security & Compliance Center.","title":"Email Notifications"},{"location":"notes/mig/ms/#stage-1-disposition","text":"Next, we navigate to the Microsoft 365 Compliance Center (MCC) to review items for disposition for Randall Testuser notified above in email. We see the items ready for disposition that are assigned to Randall Testuser as the approver or assigned disposition reviewer for the first stage named Germany SOW . The reviewer can now see items for all multi-geo locations for the respective label. Figure 9: Stage 1 disposition view. Compared to the view of record manager role, one can see that Randall Testuser has 17 items under the Multi-Stage Multi-Geo Label (shown in Figure 9) and MIG Admin shows 18 items including one item in the second stage called Europe SOW Approval (shown in Figure 10). Figure 10: Stage 1 and Stage 2 disposition view. Randall Testuser will follow guidance to Approve the disposition, Relabel , Extend or Add additional Reviewers to each item. Once approving an item for disposition, it will flow the second stage. Figure 11: Item view actions available. As Randall Testuser clicks on an item, he can quickly see the context to make an informed decision. Figure 12: Context view of item.","title":"Stage 1 Disposition"},{"location":"notes/mig/ms/#stage-2-disposition","text":"Once clicking Approve the item then moves to stage 2 called Europe SOW Approval and Joanna Hackett is notified via email to then review items for disposition in the second stage. Figure 13: Stage 2 view of item. Joanna Hackett approves items and adds her comments for the disposition action as seen in Figure 14 history pane. Figure 14: History of actions and comments.","title":"Stage 2 Disposition"},{"location":"notes/mig/ms/#stage-3-disposition","text":"Lastly the item follows the flow to the final stage for MIG Admin our records administrator to approve the disposition. Before doing so, an email was sent out by legal stating all contracts from Germany need to be immutable with a 55 year retention hold per new regulation guidance that came out in the last week. MIG Admin then adds Nancy Liang from legal to the review process.","title":"Stage 3 Disposition"},{"location":"notes/mig/ms/#adding-additional-reviewers","text":"Figure 15: Adding legal reviewer and comments.","title":"Adding additional reviewers"},{"location":"notes/mig/ms/#relabeling","text":"Nancy Liang follows the same steps after receiving an email to review the item for disposition. She will then Relabel the item as a regulatory record Multi-Stage Multi-Geo Regulatory Label that has a retention record of 55 years. Figure 16: Regulatory label summary with retention duration Figure 16 shows the settings of the regulatory label and Figure 17 shows the relabeling with comments. Figure 17: Relabel action and comments On behalf of the MIG/RM PM team, we would like to recognize the contributions of the following persons to this post: Joanne Klein - Microsoft MVP Brendon Lee - Extended Compliance CXE","title":"Relabeling"},{"location":"notes/mig/ri-rewrite/","text":"Deep Dive into the Exchange Recoverable Items Folder \u2693\ufe0e Exchange is frequently a common target for retention policies, eDiscovery holds, litigation holds, etc. But how does a hold or retention affect the content within a mailbox? This is what we hope to clarify with this article. Prerequisite Knowledge \u2693\ufe0e Before we start, we do recommend that you review the following Microsoft 365 docs articles prior to continuing: Litigation Hold in Exchange Online \u2693\ufe0e How to create a litigation hold Microsoft 365 Retention Policies and Labels \u2693\ufe0e Learn about retention policies and retention labels Learn about retention for Exchange Create retention labels and apply them in apps Automatically apply a retention label to retain or delete content Microsoft 365 eDiscovery \u2693\ufe0e How to create an eDiscovery hold Additionally, it should be noted that Exchange has a feature commonly referred to as retention policies, which are more accurately named Messaging Records Management (MRM) policies . It is important to understand that MRM policies are not the same thing as Microsoft 365 retention policies or labels. MRM policices are used to move items (such as to an archive), whereas Microsoft 365 retention policies are used to preserve and/or delete items (such as for regulatory compliance). Finally, there are many different types of holds that can be placed on an object in Exchange \u2013 eDiscovery hold, litigation hold and retention policy/label. Each have their own benefits and use cases. The purpose of this article is to discuss how Exchange handles deleted items when affected by retention or a hold, so will not discuss the difference between each of these types of holds. You can learn more about them at the links listed above. Info We plan to release future articles describing the differences between MRM policies and M365 retention policies as well as the different types of holds that can affect an Exchange mailbox and when to use each. We will update the links here once released. Now that we\u2019ve covered those prerequisites \u2013 let's deep dive into the Recoverable Items (RI) folder! Introduction \u2693\ufe0e The Exchange mailbox can be a mysterious place. Many people see only the face of their mailbox - that is what's available to them in an email client such as Outlook. However there's a whole world of information and structure behind the scenes that only Exchange administrators typically get to witness. Join me as we peel away the layers of the mailbox to understand how it is affected by Microsoft 365 Information Governance (MIG) and eDiscovery solutions. The Recoverable Items Folder \u2693\ufe0e Within the mailbox, two logical containers exist. The first, in which most of the user-interactive and visible data is stored, is called the \u2018IPM Subtree\u2019 (or Top of Information Store). This is exactly as it sounds \u2013 it is (to the user) the top level folder of the information store within the mailbox and houses familiar user-visible folders such as \u2018Inbox\u2019, \u2018Contacts\u2019, \u2018Calendar\u2019, \u2018Deleted Items\u2019, etc. The second container is called the \u2018non-IPM subtree\u2019, and contains operational and configuration data related to the mailbox. Within this non-IPM subtree, and thus virtually invisible to the user (as a folder), is a location called the Recoverable Items (RI) folder which houses it\u2019s own set of subfolders used for various purposes including storing audit logs, calendar logging information and, of course, storing deleted items for recovery and/or retention. Figure 1: Diagram of the mailbox split into two logical containers or trees. Deletions \u2693\ufe0e When items are deleted from their original location, they are generally (unless deleted with SHIFT + DELETE) first sent to the \u2018Deleted Items\u2019 folder within the IPM Subtree. This is a sort of visible safety net that provides users another chance to restore something if it was accidentally deleted. However, if permanently deleted, or if deleted from the 'Deleted Items' folder (otherwise known as a soft delete ), it is then sent to the Deletions subfolder within the Recoverable Items folder, which is another less visible safety net. Items in this folder can be restored or purged by the user in Outlook or Outlook on the Web (OWA) for as long as the mailbox is configured to keep deleted items for . This configuration is referred to as the RetainDeletedItemsFor value which, in Exchange Online, is 14 days by default, expandable to up to 30 days. Figure 2 in the diagram below gives a very high level view of the user visible deletion process: Figure 2: Diagram of deleting mailbox content without any holds or retention applied. To put it simply, the Deletions subfolder within the RI is a built-in feature to help ensure managing data in Exchange is somewhat accident-proof for the user. However, as easy as it is to restore items from the RI, users can also purge (or hard delete ) items. So what happens in the case of malicious intent? How can an organization be sure to retain items related to litigation, regulation or company policy? That\u2019s where holds and retention are necessary \u2013 but since the Deletions subfolder in the RI is visible to the user, we needed another place to store items affected by retention and holds. When Retention or Holds Apply \u2693\ufe0e Believe it or not, the ability to retain Exchange items in the event of litigation \u2013 or for regulatory/other reasons, is not a concept created for Exchange Online in Microsoft 365. Exchange 2010 first introduced a feature called Litigation hold (lithold) , which, although now considered legacy, is still used today within Exchange Online. Prior to Exchange 2010, if an item was soft deleted by a user, it was stored in what was called the \"dumpster\", which would then purge items as they reached the database's configured retention time. The major limitation with the dumpster concept, however, was that if a mailbox was moved \u2013 all the items in the dumpster were lost. This, of course, is bad news for items that need to be retained for litigation or regulatory reasons \u2013 especially as moving mailboxes becomes a much more common process between on-premises servers and up to the cloud. With the introduction of litigation hold in Exchange 2010, we needed a way to ensure items could be retained even if the mailbox is moved to another database, and, of course, be searchable for eDiscovery purposes. This is how the Recoverable Items folder was born \u2013 the dumpster was converted to a location within the mailbox, which has its own quota and stays with the mailbox wherever it is moved. Within the RI, other than the Deletions folder, there are several other subfolders all with different purposes \u2013 many created to meet the needs of regulatory retention and litigation. Unlike the Deletions folder, however, the other folders are completely invisible to the end user (via a client). Let\u2019s walk through each of them. Note For the purpose of this article, we are only going to discuss the subfolders that are used by M365 retention/hold features for Exchange mailboxes. Purges \u2693\ufe0e The Purges folder should be considered the beginning of a deleted item's retention journey within a mailbox. All items hard deleted from the Deletions folder end up in the Purges folder . Depending on the type of hold - if there is a hold at all - the items may then move to other folders. Single Item Recovery \u2693\ufe0e The first scenario we wanted to cover here was if there was no retention or holds applied to the mailbox. But wait - didn't we discuss that above? Yes - however there's some extra non user visible things happening in the background. Exchange Online has a feature called single item recovery , which is enabled on every mailbox by default. The purpose of this feature is to allow administrators a short amount of time to restore purged items without needing to rely on a backup of the mailbox. As depicted in Figure 3 below, it will retain any items that have been hard deleted within the Purges folder for as long as the RetainDeletedItemsFor value is configured, based on the last modified time of the item . Note The last modified time of the item is updated any time a modification is made including moving from the Deletions folder to the Purges folder. Example A user does not have any retention policy or hold applied to their mailbox and the RetainDeletedItemsFor value is the default of 14 days. The user deletes an email message from the inbox then soft deletes it from the Deleted Items folder. 7 days later, the user goes into the Deletions folder within Outlook or OWA and hard deletes the message. At this point, single item recovery will move the message to the Purges folder, where it will remain for 14 days before finally being purged . Figure 3: Diagram of deleting mailbox content with single item recovery enabled. Absolute hold vs Query-based hold \u2693\ufe0e Now, before we move on to the other scenarios, it's important to distinguish that there are two concepts of holds within the mailbox: Query-based and Absolute . Absolute hold \u2693\ufe0e Absolute holds are basically defined as when Exchange litigation hold or delay hold is enabled without a LitigationHoldDuration defined. This was our first type of hold with Exchange on-premises, whereas the entire mailbox was required to be kept forever. Because there was no further evaluation needed of what to keep and what not to keep, items simply remained within the Purges folder until litigation hold was disabled. Important Because they always apply to the entire mailbox, absolute holds always take precedence over any other type of hold . Figure 4: Diagram of deleting mailbox content when litigation hold is enabled. Query-based hold \u2693\ufe0e Eventually, however, simply applying a hold to the entire mailbox was not flexible enough. We needed to add the capability to allow conditions. This includes: Litigation Hold with the LitigationHoldDuration parameter configured Microsoft 365 Retention Policies with any duration of retention Microsoft 365 Retention Labels with any duration of retention eDiscovery holds with any duration of retention Because of the many possible conditions, we needed a way to evaluate content to identify if it met the conditions specified within the hold. Since we already use the Purges folder for absolute holds, we needed to create a new subfolder - DiscoveryHolds . DiscoveryHolds \u2693\ufe0e As mentioned above, the DiscoveryHolds folder is used to evaluate and then keep items that match a query-based hold. However, as also mentioned above, the Purges folder is always used first . This is where the RetainDeletedItemsFor configuration is again important. As the items reach their configured time within the Purges folder, if a query based hold is applied to the mailbox (with no absolute hold specified), the items will then be moved to the DiscoveryHolds folder. Example A user has an org-wide Microsoft 365 retention policy applied to their mailbox, Litigation hold is disabled and the RetainDeletedItemsFor value is the default of 14 days. The user deletes an email from their inbox, then soft deletes the message from the Deleted Items folder. After 7 days, the user hard deletes the message from the Deletions folder. The message is then stored within the Purges folder for 14 days before being moved to the DiscoveryHolds folder to remain until no longer subject to the applied retention policy . Figure 5: Diagram of deleting mailbox content that has a Query-based hold applied. Versions \u2693\ufe0e Then finally \u2013 the Versions folder. Consider that we've intentionally enabled some kind of retention policy or hold on a mailbox - meaning we need to make sure for either regulatory, legal or other reasons, that we don't delete anything affected by the hold. Now, consider - what if an object is modified ? We, of course, need to make sure that we keep all versions or instances of each item as it is modified. That's what the Versions folder is for - to keep the original copy of the item as well as all versions before the modification is made. This capability relies on an Exchange feature called Copy-on-Write (COW) page protection which triggers a copy any time certain properties of an Exchange object are modified. Example A user has an eDiscovery hold applied to their mailbox, Litigation hold is disabled and the RetainDeletedItemsFor value is the default of 14 days. The user sends an email to their personal email address with an attachment. After sending, they go into their Sent items, and choose to remove the attachment. Then they delete, soft delete and hard delete the sent message. When the user removes the attachment, Exchange will copy the original version of the message (with the attachment) to the Versions folder before removing the attachment . When the user hard deletes the message, it will be retained in the Purges folder for 14 days, then moved to the DiscoveryHolds folder . Both the original sent message and the deleted modified message will be discoverable via eDiscovery searches and both will be removed once the eDiscovery hold is removed. Figure 6: Diagram modifying content that has a query-based hold enabled. Quota \u2693\ufe0e One of the benefits of the Recoverable Items folder is that it has a quota separate from that of the user's mailbox . This is actually incredibly important . The Recoverable Items folder should be completely seamless to the user (in other words, they user should have no idea it exists) - if it shared the same quota as the mailbox, all kinds of potential issues could arise, such as preventing the user from sending/receiving email because they unintentionally deleted too many things that were subject to a hold. In Exchange Online, the following quota's exist: Location Not on Hold On Hold Mailbox 100 GB (E3/E5) 100 GB (E3/E5) Recoverable Items Folder 30 GB 100 GB Online Archive \u2693\ufe0e While the Recoverable Items folder having a separate quota from the mailbox greatly reduces the chance of users being impacted by retention policies or holds, there is still a potential risk. If, for some reason, the RI folder exceeds it's quota, users will no longer be able to delete items. To prevent this, it is highly recommended to use Online Archiving . A default MRM tag exists out of the box which, if Online Archiving is enabled, automatically moves items that are 14 days or older from the primary RI folder to the RI folder within the Online Archive. This helps to ensure that the RI folder doesn't exceed it's quota as the Online Archive has it's own RI folder : Location Not on Hold On Hold Online Archive 100 GB (E3/E5) 100 GB (E3/E5) Recoverable Items Folder (Archive) 30 GB 100 GB Note The auto-expanding capabilities of the Online Archive also apply to the Recoverable Items folder within the archive . Conclusion \u2693\ufe0e We hope that you enjoyed this journey into the Exchange mailbox from a retention and hold perspective. Please feel free to submit feedback or suggest edits using the links at the top of this article. Additional Resources \u2693\ufe0e How to identify the type of hold placed on an Exchange Online mailbox How to clean up or delete items from the RI folder Brendon Lee - Compliance CxE With contributions from: Randall Galloway Stefanie Bier David Santamaria","title":"Deep Dive into the Exchange Recoverable Items Folder"},{"location":"notes/mig/ri-rewrite/#deep-dive-into-the-exchange-recoverable-items-folder","text":"Exchange is frequently a common target for retention policies, eDiscovery holds, litigation holds, etc. But how does a hold or retention affect the content within a mailbox? This is what we hope to clarify with this article.","title":"Deep Dive into the Exchange Recoverable Items Folder"},{"location":"notes/mig/ri-rewrite/#prerequisite-knowledge","text":"Before we start, we do recommend that you review the following Microsoft 365 docs articles prior to continuing:","title":"Prerequisite Knowledge"},{"location":"notes/mig/ri-rewrite/#litigation-hold-in-exchange-online","text":"How to create a litigation hold","title":"Litigation Hold in Exchange Online"},{"location":"notes/mig/ri-rewrite/#microsoft-365-retention-policies-and-labels","text":"Learn about retention policies and retention labels Learn about retention for Exchange Create retention labels and apply them in apps Automatically apply a retention label to retain or delete content","title":"Microsoft 365 Retention Policies and Labels"},{"location":"notes/mig/ri-rewrite/#microsoft-365-ediscovery","text":"How to create an eDiscovery hold Additionally, it should be noted that Exchange has a feature commonly referred to as retention policies, which are more accurately named Messaging Records Management (MRM) policies . It is important to understand that MRM policies are not the same thing as Microsoft 365 retention policies or labels. MRM policices are used to move items (such as to an archive), whereas Microsoft 365 retention policies are used to preserve and/or delete items (such as for regulatory compliance). Finally, there are many different types of holds that can be placed on an object in Exchange \u2013 eDiscovery hold, litigation hold and retention policy/label. Each have their own benefits and use cases. The purpose of this article is to discuss how Exchange handles deleted items when affected by retention or a hold, so will not discuss the difference between each of these types of holds. You can learn more about them at the links listed above. Info We plan to release future articles describing the differences between MRM policies and M365 retention policies as well as the different types of holds that can affect an Exchange mailbox and when to use each. We will update the links here once released. Now that we\u2019ve covered those prerequisites \u2013 let's deep dive into the Recoverable Items (RI) folder!","title":"Microsoft 365 eDiscovery"},{"location":"notes/mig/ri-rewrite/#introduction","text":"The Exchange mailbox can be a mysterious place. Many people see only the face of their mailbox - that is what's available to them in an email client such as Outlook. However there's a whole world of information and structure behind the scenes that only Exchange administrators typically get to witness. Join me as we peel away the layers of the mailbox to understand how it is affected by Microsoft 365 Information Governance (MIG) and eDiscovery solutions.","title":"Introduction"},{"location":"notes/mig/ri-rewrite/#the-recoverable-items-folder","text":"Within the mailbox, two logical containers exist. The first, in which most of the user-interactive and visible data is stored, is called the \u2018IPM Subtree\u2019 (or Top of Information Store). This is exactly as it sounds \u2013 it is (to the user) the top level folder of the information store within the mailbox and houses familiar user-visible folders such as \u2018Inbox\u2019, \u2018Contacts\u2019, \u2018Calendar\u2019, \u2018Deleted Items\u2019, etc. The second container is called the \u2018non-IPM subtree\u2019, and contains operational and configuration data related to the mailbox. Within this non-IPM subtree, and thus virtually invisible to the user (as a folder), is a location called the Recoverable Items (RI) folder which houses it\u2019s own set of subfolders used for various purposes including storing audit logs, calendar logging information and, of course, storing deleted items for recovery and/or retention. Figure 1: Diagram of the mailbox split into two logical containers or trees.","title":"The Recoverable Items Folder"},{"location":"notes/mig/ri-rewrite/#deletions","text":"When items are deleted from their original location, they are generally (unless deleted with SHIFT + DELETE) first sent to the \u2018Deleted Items\u2019 folder within the IPM Subtree. This is a sort of visible safety net that provides users another chance to restore something if it was accidentally deleted. However, if permanently deleted, or if deleted from the 'Deleted Items' folder (otherwise known as a soft delete ), it is then sent to the Deletions subfolder within the Recoverable Items folder, which is another less visible safety net. Items in this folder can be restored or purged by the user in Outlook or Outlook on the Web (OWA) for as long as the mailbox is configured to keep deleted items for . This configuration is referred to as the RetainDeletedItemsFor value which, in Exchange Online, is 14 days by default, expandable to up to 30 days. Figure 2 in the diagram below gives a very high level view of the user visible deletion process: Figure 2: Diagram of deleting mailbox content without any holds or retention applied. To put it simply, the Deletions subfolder within the RI is a built-in feature to help ensure managing data in Exchange is somewhat accident-proof for the user. However, as easy as it is to restore items from the RI, users can also purge (or hard delete ) items. So what happens in the case of malicious intent? How can an organization be sure to retain items related to litigation, regulation or company policy? That\u2019s where holds and retention are necessary \u2013 but since the Deletions subfolder in the RI is visible to the user, we needed another place to store items affected by retention and holds.","title":"Deletions"},{"location":"notes/mig/ri-rewrite/#when-retention-or-holds-apply","text":"Believe it or not, the ability to retain Exchange items in the event of litigation \u2013 or for regulatory/other reasons, is not a concept created for Exchange Online in Microsoft 365. Exchange 2010 first introduced a feature called Litigation hold (lithold) , which, although now considered legacy, is still used today within Exchange Online. Prior to Exchange 2010, if an item was soft deleted by a user, it was stored in what was called the \"dumpster\", which would then purge items as they reached the database's configured retention time. The major limitation with the dumpster concept, however, was that if a mailbox was moved \u2013 all the items in the dumpster were lost. This, of course, is bad news for items that need to be retained for litigation or regulatory reasons \u2013 especially as moving mailboxes becomes a much more common process between on-premises servers and up to the cloud. With the introduction of litigation hold in Exchange 2010, we needed a way to ensure items could be retained even if the mailbox is moved to another database, and, of course, be searchable for eDiscovery purposes. This is how the Recoverable Items folder was born \u2013 the dumpster was converted to a location within the mailbox, which has its own quota and stays with the mailbox wherever it is moved. Within the RI, other than the Deletions folder, there are several other subfolders all with different purposes \u2013 many created to meet the needs of regulatory retention and litigation. Unlike the Deletions folder, however, the other folders are completely invisible to the end user (via a client). Let\u2019s walk through each of them. Note For the purpose of this article, we are only going to discuss the subfolders that are used by M365 retention/hold features for Exchange mailboxes.","title":"When Retention or Holds Apply"},{"location":"notes/mig/ri-rewrite/#purges","text":"The Purges folder should be considered the beginning of a deleted item's retention journey within a mailbox. All items hard deleted from the Deletions folder end up in the Purges folder . Depending on the type of hold - if there is a hold at all - the items may then move to other folders.","title":"Purges"},{"location":"notes/mig/ri-rewrite/#single-item-recovery","text":"The first scenario we wanted to cover here was if there was no retention or holds applied to the mailbox. But wait - didn't we discuss that above? Yes - however there's some extra non user visible things happening in the background. Exchange Online has a feature called single item recovery , which is enabled on every mailbox by default. The purpose of this feature is to allow administrators a short amount of time to restore purged items without needing to rely on a backup of the mailbox. As depicted in Figure 3 below, it will retain any items that have been hard deleted within the Purges folder for as long as the RetainDeletedItemsFor value is configured, based on the last modified time of the item . Note The last modified time of the item is updated any time a modification is made including moving from the Deletions folder to the Purges folder. Example A user does not have any retention policy or hold applied to their mailbox and the RetainDeletedItemsFor value is the default of 14 days. The user deletes an email message from the inbox then soft deletes it from the Deleted Items folder. 7 days later, the user goes into the Deletions folder within Outlook or OWA and hard deletes the message. At this point, single item recovery will move the message to the Purges folder, where it will remain for 14 days before finally being purged . Figure 3: Diagram of deleting mailbox content with single item recovery enabled.","title":"Single Item Recovery"},{"location":"notes/mig/ri-rewrite/#absolute-hold-vs-query-based-hold","text":"Now, before we move on to the other scenarios, it's important to distinguish that there are two concepts of holds within the mailbox: Query-based and Absolute .","title":"Absolute hold vs Query-based hold"},{"location":"notes/mig/ri-rewrite/#absolute-hold","text":"Absolute holds are basically defined as when Exchange litigation hold or delay hold is enabled without a LitigationHoldDuration defined. This was our first type of hold with Exchange on-premises, whereas the entire mailbox was required to be kept forever. Because there was no further evaluation needed of what to keep and what not to keep, items simply remained within the Purges folder until litigation hold was disabled. Important Because they always apply to the entire mailbox, absolute holds always take precedence over any other type of hold . Figure 4: Diagram of deleting mailbox content when litigation hold is enabled.","title":"Absolute hold"},{"location":"notes/mig/ri-rewrite/#query-based-hold","text":"Eventually, however, simply applying a hold to the entire mailbox was not flexible enough. We needed to add the capability to allow conditions. This includes: Litigation Hold with the LitigationHoldDuration parameter configured Microsoft 365 Retention Policies with any duration of retention Microsoft 365 Retention Labels with any duration of retention eDiscovery holds with any duration of retention Because of the many possible conditions, we needed a way to evaluate content to identify if it met the conditions specified within the hold. Since we already use the Purges folder for absolute holds, we needed to create a new subfolder - DiscoveryHolds .","title":"Query-based hold"},{"location":"notes/mig/ri-rewrite/#discoveryholds","text":"As mentioned above, the DiscoveryHolds folder is used to evaluate and then keep items that match a query-based hold. However, as also mentioned above, the Purges folder is always used first . This is where the RetainDeletedItemsFor configuration is again important. As the items reach their configured time within the Purges folder, if a query based hold is applied to the mailbox (with no absolute hold specified), the items will then be moved to the DiscoveryHolds folder. Example A user has an org-wide Microsoft 365 retention policy applied to their mailbox, Litigation hold is disabled and the RetainDeletedItemsFor value is the default of 14 days. The user deletes an email from their inbox, then soft deletes the message from the Deleted Items folder. After 7 days, the user hard deletes the message from the Deletions folder. The message is then stored within the Purges folder for 14 days before being moved to the DiscoveryHolds folder to remain until no longer subject to the applied retention policy . Figure 5: Diagram of deleting mailbox content that has a Query-based hold applied.","title":"DiscoveryHolds"},{"location":"notes/mig/ri-rewrite/#versions","text":"Then finally \u2013 the Versions folder. Consider that we've intentionally enabled some kind of retention policy or hold on a mailbox - meaning we need to make sure for either regulatory, legal or other reasons, that we don't delete anything affected by the hold. Now, consider - what if an object is modified ? We, of course, need to make sure that we keep all versions or instances of each item as it is modified. That's what the Versions folder is for - to keep the original copy of the item as well as all versions before the modification is made. This capability relies on an Exchange feature called Copy-on-Write (COW) page protection which triggers a copy any time certain properties of an Exchange object are modified. Example A user has an eDiscovery hold applied to their mailbox, Litigation hold is disabled and the RetainDeletedItemsFor value is the default of 14 days. The user sends an email to their personal email address with an attachment. After sending, they go into their Sent items, and choose to remove the attachment. Then they delete, soft delete and hard delete the sent message. When the user removes the attachment, Exchange will copy the original version of the message (with the attachment) to the Versions folder before removing the attachment . When the user hard deletes the message, it will be retained in the Purges folder for 14 days, then moved to the DiscoveryHolds folder . Both the original sent message and the deleted modified message will be discoverable via eDiscovery searches and both will be removed once the eDiscovery hold is removed. Figure 6: Diagram modifying content that has a query-based hold enabled.","title":"Versions"},{"location":"notes/mig/ri-rewrite/#quota","text":"One of the benefits of the Recoverable Items folder is that it has a quota separate from that of the user's mailbox . This is actually incredibly important . The Recoverable Items folder should be completely seamless to the user (in other words, they user should have no idea it exists) - if it shared the same quota as the mailbox, all kinds of potential issues could arise, such as preventing the user from sending/receiving email because they unintentionally deleted too many things that were subject to a hold. In Exchange Online, the following quota's exist: Location Not on Hold On Hold Mailbox 100 GB (E3/E5) 100 GB (E3/E5) Recoverable Items Folder 30 GB 100 GB","title":"Quota"},{"location":"notes/mig/ri-rewrite/#online-archive","text":"While the Recoverable Items folder having a separate quota from the mailbox greatly reduces the chance of users being impacted by retention policies or holds, there is still a potential risk. If, for some reason, the RI folder exceeds it's quota, users will no longer be able to delete items. To prevent this, it is highly recommended to use Online Archiving . A default MRM tag exists out of the box which, if Online Archiving is enabled, automatically moves items that are 14 days or older from the primary RI folder to the RI folder within the Online Archive. This helps to ensure that the RI folder doesn't exceed it's quota as the Online Archive has it's own RI folder : Location Not on Hold On Hold Online Archive 100 GB (E3/E5) 100 GB (E3/E5) Recoverable Items Folder (Archive) 30 GB 100 GB Note The auto-expanding capabilities of the Online Archive also apply to the Recoverable Items folder within the archive .","title":"Online Archive"},{"location":"notes/mig/ri-rewrite/#conclusion","text":"We hope that you enjoyed this journey into the Exchange mailbox from a retention and hold perspective. Please feel free to submit feedback or suggest edits using the links at the top of this article.","title":"Conclusion"},{"location":"notes/mig/ri-rewrite/#additional-resources","text":"How to identify the type of hold placed on an Exchange Online mailbox How to clean up or delete items from the RI folder Brendon Lee - Compliance CxE With contributions from: Randall Galloway Stefanie Bier David Santamaria","title":"Additional Resources"},{"location":"notes/mig/ri/","text":"Deep Dive into the Exchange Recoverable Items Folder \u2693\ufe0e Warning This article has been temporarily removed so that it can be refreshed. For information on the Reoverable Items folder, refer to the official documentation .","title":"Deep Dive into the Exchange Recoverable Items Folder"},{"location":"notes/mig/ri/#deep-dive-into-the-exchange-recoverable-items-folder","text":"Warning This article has been temporarily removed so that it can be refreshed. For information on the Reoverable Items folder, refer to the official documentation .","title":"Deep Dive into the Exchange Recoverable Items Folder"},{"location":"notes/mip-dlp/DLP-policy-externalshare/","text":"Preventing and educating users from sharing sensitive documents externally \u2693\ufe0e Overview \u2693\ufe0e This short note is to help organizations build a policy to help educate their information workers to apply the right label when sharing files externally. This is done by building a DLP policy to block sharing of files with Internal label and notify the user that they need to change the label before they can share this. This could be combined and scoped to only sites that allow for external sharing. The DLP Policy would be scoped to SharePoint and OneDrive workloads. Note this screen capture is scoped to all but you could narrow this if needed. Figure 1: DLP policy locations picker The condition would be to look for a sensitivity label example Internal and shared externally: Figure 2: DLP policy conditions The action you would take is block this: Figure 3: DLP policy conditions Then, the best practice is to notify the end user with a custom message to let them know to change the label. Figure 4: DLP policy conditions We hope you found this helpful \ud83d\ude0a Thank you!","title":"Preventing external sharing with DLP policy"},{"location":"notes/mip-dlp/DLP-policy-externalshare/#preventing-and-educating-users-from-sharing-sensitive-documents-externally","text":"","title":"Preventing and educating users from sharing sensitive documents externally"},{"location":"notes/mip-dlp/DLP-policy-externalshare/#overview","text":"This short note is to help organizations build a policy to help educate their information workers to apply the right label when sharing files externally. This is done by building a DLP policy to block sharing of files with Internal label and notify the user that they need to change the label before they can share this. This could be combined and scoped to only sites that allow for external sharing. The DLP Policy would be scoped to SharePoint and OneDrive workloads. Note this screen capture is scoped to all but you could narrow this if needed. Figure 1: DLP policy locations picker The condition would be to look for a sensitivity label example Internal and shared externally: Figure 2: DLP policy conditions The action you would take is block this: Figure 3: DLP policy conditions Then, the best practice is to notify the end user with a custom message to let them know to change the label. Figure 4: DLP policy conditions We hope you found this helpful \ud83d\ude0a Thank you!","title":"Overview"},{"location":"notes/mip-dlp/SPOblockUpload/","text":"Alerting/blocking for mismatched sensitive docs to SPO site \u2693\ufe0e Business objective: Protect against the risk of documents labeled for higher sensitivity purposes being added to SharePoint sites labeled with a lower sensitivity \u2693\ufe0e This can be achieved by using an API to read sensitivity labels on documents and on sites, and then using it from Power Automate that will look at the document sensitivity and will either warn or move that document to another folder until the issue is resolved. Note: The main limitation with this approach is that you can\u2019t configure Power Automate to monitor all sites, so you would have to explicitly add an entry point for each site you want to monitor. Figure 1: Power Automate flow You can also choose to move the uploaded file to a different (secured) folder Figure 2: moving the file to a different folder Click here to see a short video that demos the process Thank you!","title":"Blocking upload of files with higher sensitivity label to SPO"},{"location":"notes/mip-dlp/SPOblockUpload/#alertingblocking-for-mismatched-sensitive-docs-to-spo-site","text":"","title":"Alerting/blocking for mismatched sensitive docs to SPO site"},{"location":"notes/mip-dlp/SPOblockUpload/#business-objective-protect-against-the-risk-of-documents-labeled-for-higher-sensitivity-purposes-being-added-to-sharepoint-sites-labeled-with-a-lower-sensitivity","text":"This can be achieved by using an API to read sensitivity labels on documents and on sites, and then using it from Power Automate that will look at the document sensitivity and will either warn or move that document to another folder until the issue is resolved. Note: The main limitation with this approach is that you can\u2019t configure Power Automate to monitor all sites, so you would have to explicitly add an entry point for each site you want to monitor. Figure 1: Power Automate flow You can also choose to move the uploaded file to a different (secured) folder Figure 2: moving the file to a different folder Click here to see a short video that demos the process Thank you!","title":"Business objective: Protect against the risk of documents labeled for higher sensitivity purposes being added to SharePoint sites labeled with a lower sensitivity"},{"location":"notes/mip-dlp/audit-log-management-activity-api/","text":"Auditing and reporting play important roles in the security and compliance strategy for many organizations. With the continued expansion of the technology landscape that has an ever-increasing number of systems, endpoints, operations, and regulations, it becomes even more important to have a comprehensive logging and reporting solution in place. The following blog series deep dives into what audit logs are available and how to access them programmatically for use in reporting, alerting and other SIEM use cases. Part 1 \u2693\ufe0e In part 1, we discuss the importance of auditing and reporting for an organization's security and compliance posture. We also discuss Microsoft auditing solutions, auditing architecture (and its components), as well as Microsoft Information Protection audit log schema. Microsoft 365 Compliance audit log activities via O365 management API - Part 1 Part 2 \u2693\ufe0e In part 2, we introduce a sample script that can be used to help understand how to programmatically connect and download audit events from the O365 management activity API. We then show how to integrate the DLP data into a sample PowerBI dashboard for reporting. Microsoft 365 Compliance audit log activities via O365 management API - Part 2 We're not done \u2693\ufe0e More parts to come soon!","title":"Microsoft Purview Audit (Premium) Log Activities via the O365 Management API"},{"location":"notes/mip-dlp/audit-log-management-activity-api/#part-1","text":"In part 1, we discuss the importance of auditing and reporting for an organization's security and compliance posture. We also discuss Microsoft auditing solutions, auditing architecture (and its components), as well as Microsoft Information Protection audit log schema. Microsoft 365 Compliance audit log activities via O365 management API - Part 1","title":"Part 1"},{"location":"notes/mip-dlp/audit-log-management-activity-api/#part-2","text":"In part 2, we introduce a sample script that can be used to help understand how to programmatically connect and download audit events from the O365 management activity API. We then show how to integrate the DLP data into a sample PowerBI dashboard for reporting. Microsoft 365 Compliance audit log activities via O365 management API - Part 2","title":"Part 2"},{"location":"notes/mip-dlp/audit-log-management-activity-api/#were-not-done","text":"More parts to come soon!","title":"We're not done"},{"location":"notes/mip-dlp/mip-dlp-best-practices/","text":"Best practices for creating MIP and DLP policies - or \"Better together\" \u2693\ufe0e TL;DR \u2693\ufe0e You should not design the DLP policy and the labeling policy independently and at different times. There are many significant advantages to doing both in concert. Introduction \u2693\ufe0e When you start your MIP and DLP journey, you often think it would be best to start with either and then, when policy is in place, plan the other. Here is where you got it all wrong! By planning both policies together, you can achieve more. Reason 1 \u2693\ufe0e Designing a labeling taxonomy with DLP in mind increases the granularity of the protection you can get from labels. We heard of customers that are fearful of having data exposed by default, so they want to use a label with protection (encryption) as their default label, user experience be dammed. Since the alternative for the default label is to use one without protection, they see no good alternative. Including DLP in the design means you can set a label without encryption but still with \u201cprotection\u201d. E.g., you can have Confidential and HC labels using encryption, and public/personal without encryption, but the default label can be \u201cInternal\u201d enforced to stay that way by DLP, preventing accidental sharing and forwarding unless the user explicitly selects another label (e.g., External). This provides the user experience benefits of a label without encryption while providing effective protection against the most common mistakes. Reason 2 \u2693\ufe0e Incorporating your labels in the design of DLP rules allows you for much better handling of exceptions. Let\u2019s say you have a rule that blocks sharing of PII with the outside world. One team tries to share such content with their partners and is blocked. After some escalation they convince you to grant them an exception, which now must be encoded in the DLP rule. With each such exception the DLP rule becomes more complicated and less legible, increasing risk of mistakes. And then one day one of these users accidentally forwards an email full of PII to a random person and all your DLP work was for nothing. With labels added to DLP rules you can have a \u201cPII Special Sharing Exception\u201d label, which is exempted from the DLP rule up to a certain amount of PII. In the same situation instead of complicating the DLP rules with each exception you add one exception to the policy for that label, and then you add the group in question to the scope of the label. This is easier to manage and more scalable, and it also means that accidents like the one above won\u2019t happen since the user has to select the label explicitly and proactively when they need to share such content with such partners. If this is not enough, you can also add encryption to the label with only specific domains allowed as recipients. Reason 3 \u2693\ufe0e Aligning auto labeling with DLP policies gives you visibility into the sensitive data affected by those DLP policies before users even think of sharing it, and better visibility to the user of what they are dealing with and the controls in place for that data. Essentially, DLP will give IT and the users that information when it\u2019s being shared, labeling will do the same the minute the data is created. And of course, if the auto labeling rule applies encryption it will also provide controls while the data is inside the org, limiting oversharing and ensuring that even after the data is shared (by exception or through some loophole) it is still protected from unintended access. Reason 4 \u2693\ufe0e Defense in depth: errors happen, either by users or admins. Duplicating your DLP rules as auto labeling rules means that problems with DLP enforcement (specific to one rule or general), the data was protected from the time of creation, so the risk is strongly mitigated. And of course, the reverse is also true: if labeling is not functional when the data is being created or edited, DLP will still protect the content at time of sharing, so either way you are covered. Conclusion \u2693\ufe0e To summarize, plan both policies together, make sure they complement each other. That will help you protect your organization\u2019s data and reduce risks.","title":"Best Practices for Creating IP and DLP Policies"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#best-practices-for-creating-mip-and-dlp-policies-or-better-together","text":"","title":"Best practices for creating MIP and DLP policies - or \"Better together\""},{"location":"notes/mip-dlp/mip-dlp-best-practices/#tldr","text":"You should not design the DLP policy and the labeling policy independently and at different times. There are many significant advantages to doing both in concert.","title":"TL;DR"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#introduction","text":"When you start your MIP and DLP journey, you often think it would be best to start with either and then, when policy is in place, plan the other. Here is where you got it all wrong! By planning both policies together, you can achieve more.","title":"Introduction"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#reason-1","text":"Designing a labeling taxonomy with DLP in mind increases the granularity of the protection you can get from labels. We heard of customers that are fearful of having data exposed by default, so they want to use a label with protection (encryption) as their default label, user experience be dammed. Since the alternative for the default label is to use one without protection, they see no good alternative. Including DLP in the design means you can set a label without encryption but still with \u201cprotection\u201d. E.g., you can have Confidential and HC labels using encryption, and public/personal without encryption, but the default label can be \u201cInternal\u201d enforced to stay that way by DLP, preventing accidental sharing and forwarding unless the user explicitly selects another label (e.g., External). This provides the user experience benefits of a label without encryption while providing effective protection against the most common mistakes.","title":"Reason 1"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#reason-2","text":"Incorporating your labels in the design of DLP rules allows you for much better handling of exceptions. Let\u2019s say you have a rule that blocks sharing of PII with the outside world. One team tries to share such content with their partners and is blocked. After some escalation they convince you to grant them an exception, which now must be encoded in the DLP rule. With each such exception the DLP rule becomes more complicated and less legible, increasing risk of mistakes. And then one day one of these users accidentally forwards an email full of PII to a random person and all your DLP work was for nothing. With labels added to DLP rules you can have a \u201cPII Special Sharing Exception\u201d label, which is exempted from the DLP rule up to a certain amount of PII. In the same situation instead of complicating the DLP rules with each exception you add one exception to the policy for that label, and then you add the group in question to the scope of the label. This is easier to manage and more scalable, and it also means that accidents like the one above won\u2019t happen since the user has to select the label explicitly and proactively when they need to share such content with such partners. If this is not enough, you can also add encryption to the label with only specific domains allowed as recipients.","title":"Reason 2"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#reason-3","text":"Aligning auto labeling with DLP policies gives you visibility into the sensitive data affected by those DLP policies before users even think of sharing it, and better visibility to the user of what they are dealing with and the controls in place for that data. Essentially, DLP will give IT and the users that information when it\u2019s being shared, labeling will do the same the minute the data is created. And of course, if the auto labeling rule applies encryption it will also provide controls while the data is inside the org, limiting oversharing and ensuring that even after the data is shared (by exception or through some loophole) it is still protected from unintended access.","title":"Reason 3"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#reason-4","text":"Defense in depth: errors happen, either by users or admins. Duplicating your DLP rules as auto labeling rules means that problems with DLP enforcement (specific to one rule or general), the data was protected from the time of creation, so the risk is strongly mitigated. And of course, the reverse is also true: if labeling is not functional when the data is being created or edited, DLP will still protect the content at time of sharing, so either way you are covered.","title":"Reason 4"},{"location":"notes/mip-dlp/mip-dlp-best-practices/#conclusion","text":"To summarize, plan both policies together, make sure they complement each other. That will help you protect your organization\u2019s data and reduce risks.","title":"Conclusion"},{"location":"playbooks/etr2dlp/","text":"Introduction \u2693\ufe0e Please use this guide as a starting point for migrating Exchange Transport Rules (EAC-DLP) to Microsoft 365 DLP (Microsoft Compliance Center) . All links and references should be up to date, however, in the event that you have a question about the correctness of any information in this document, please reach out to our yammer group aka.ms/askmipteam For a refresher on the knowledge and differences between Exchange Transport Rules (EAC-DLP) and Microsoft Information Protection \u2013DLP (MIP-DLP) when applied to the Exchange workload , please review the overview section of this documentation prior to moving forward. All screenshots in this guide contain the proper configuration settings according to best practices at the time of publication. Please ensure that your configurations mirror those used in this guide. Please refer to the Microsoft documentation online at https://docs.microsoft.com/en-us/microsoft-365/compliance/?view=o365-worldwide for the latest updates. Though the name of this document shows as play book, it can be equally considered as a deployment guide. This document will be updated as and when new features are introduced to the Migration Wizard. Also please note that, not all below stages needs to be implemented. It all depends on the requirement of the organization and the availability of licenses. There are 2 stages/tracks exists in any of the MIP/DLP deployment Stage 1 : Migration from ETR (EAC-DLP) to Microsoft 365 DLP (EXO) Stage 2 : Integration with other workloads (SPO/ODB/MCAS/Devices) (Out of scope of this document) . Refer this blog for more details Objective \u2693\ufe0e This document provides an overview of how enterprise customers can migrate their existing Exchange Transport Rules (DLP) to Microsoft compliance portal \u2013 DLP(EXO). It walks through the different stages of migration and shows the effectiveness of the DLP portal as a single place to define all aspects of your DLP strategy. In summary, this play book will help to Understand the migration process. Understand the unified console and interface. Develop a strategy for the migration. Ensure a smooth migration process. Find resources to support the migration process. Scope \u2693\ufe0e This document helps readers understand the process to be followed during the migration of traditional exchange transport rules from Exchange Admin Centre (EAC) portal \u2013 DLP section to Microsoft Compliance Center- DLP portal , followed by the addition of other workloads based on the organizational need. Microsoft Compliance portal has integration with multiple workloads that help to protect customer data with a single policy. This document helps in understanding the process to be followed in migrating existing traditional ETR rules in Exchange Center Portal (DLP) to Microsoft 365 DLP using the in-service - DLP policy Migration Wizard. Assumptions \u2693\ufe0e Customer is currently using ETR (EAC-DLP) policies for data protection on Exchange. All the Data Classification needs (Sensitive Information Types) has been Identified. Intended Audience \u2693\ufe0e Customers, Partners, Internal Microsoft employees Overview \u2693\ufe0e Exchange Admin Center - Data Loss Prevention \u2693\ufe0e Prior to Microsoft 365 DLP, most organizations protected data using the rules created in Exchange. You can use mail flow rules (also known as transport rules) to identify and act on messages that flow through the Exchange Online organization. Mail flow rules are like the Inbox rules available in Outlook and Outlook on the web. Mail flow rules contain a richer set of conditions, exceptions, and actions, which provide you with the flexibility to implement many types of messaging policies. Please note that, Exchange Transport Rules are not deprecating, and they remain same. Only, the ETR\u2019s linked to Exchange DLP policy (refer below URL or Figure-1) are being migrated (recommended) to Microsoft 365 DLP portal. data loss prevention - Microsoft Exchange (office365.com) Like Microsoft 365 DLP portal, mail flow rules have components such as: Conditions, Exceptions, Actions and Alerts/notifications. Mail flow rules are primarily used for: Defining rules to encrypt messages. Defining rules to route mails based on keywords or phrases. Block mails when the attachment contains Sensitive Information Types or exceeds a recommended size. Organization-wide message disclaimers, signatures, footers, or headers in Exchange Online Setting the spam confidence level (SCL) in messages For summary and detail reports about messages that matched mail flow rules, see here . The exchange transport rules are available in https://outlook.office365.com/ecp/?form=eac&mkt=en-US . The rules that are in the highlighted portion of the below picture are the rules, needs to be migrated to the Microsoft 365 DLP portal using the Wizard. Other Rules remains in the portal and is not part of this migration. Figure 1: Exchange Admin Center On click of the yellow ribbon, you will be taken to the compliance Portal for further actions. The compliance Portal overview has been given in the next section. Microsoft Compliance Center (MCC) \u2693\ufe0e Microsoft Compliance Centre has many Compliance Products, and this document helps in understanding one of the product/platforms, i.e., Microsoft Information Protection (MIP) at a high level. It has 3 components. 1 \u2013 Data Classification 2-Data Loss Prevention 3-Information Protection. Current documents talk more about, Data Loss Prevention (DLP) Microsoft Information Protection (MIP) helps to identify, discover, classify, protect, and prevent sensitive information wherever it lives either at rest or in transit. Figure 2: Microsoft Information Protection Cycle Know your data assists in understanding the current data landscape and provides organizations with the ability to identify sensitive content residing in Microsoft 365, across Exchange, SPO, ODB and physical devices depending on workloads used and licensing owned. Protect your data assists in applying flexible protection that includes visual marking, encryption and access restrictions across apps, services and devices that travel inside and outside the organization. Prevent data loss (DLP) assists in preventing the accidental data loss and oversharing of sensitive information with-in or outside the organization. In the Data Loss Prevention capability of MIP, Global and Compliance admins can create policies across workloads and applies rules to protect data oversharing. Pre-defined built in regulatory templates across various industries are available. Administrators can create their own custom policies to suit organizational needs. Once the data is classified based on the organizational needs, start creating the policies/rules to prevent the data loss using the URL: https://compliance.microsoft.com/datalossprevention . Login with an appropriate role as described in this document and create policies as per the need on one location or on multiple locations. Figure 3: Microsoft 365 Compliance Portal DLP Wizard Figure 4: Microsoft 365 Compliance Portal - DLP across workloads The alerts produced during the protection of data can be viewed using DLP-Alerts/Activity explorer. Activity explorer (E5 license) provides a 360-degree view (also known as \u201cKnow your data\u201d) of user risky activities across the tenant and helps administrators take preventive measures. Figure 5 shows Activity Explorer with detailed metadata of user activity where and when it has happened. Figure 5: Activity Explorer with user activities Similarly, MIP has a Content Explorer which is part of the Data Classification dashboard. Content Explorer shows a current snapshot of items with sensitivity labels, retention labels and contained Sensitive Information Types in your organization. A DLP policy can help protect sensitive information, which is detected through one or more Sensitive Information Types. Microsoft 365 includes definitions for many common Sensitive Information Types from across many different regions that are ready to use. For example, a credit card number, bank account numbers, national ID numbers, and Windows Live ID service numbers. Figure 6: Content Explorer with summary view Upon further drill down, the exact file location and file containing sensitive information can be viewed for further action or protection, along with data pertaining to last modification date and user. Note For both features (Activity explorer and Content Explorer), separate role-based access is required to view the files. With the availability of the unified console across, Microsoft recommends migrating all existing ETR (EAC-DLP) rules into Microsoft 365 DLP(EXO). This will provide a far more streamlined experience for administrators via a single console. Why now, moving to MCC-DLP? \u2693\ufe0e DLP policy management will soon be retired from the Exchange admin center, so we recommend migrating these policies to the Microsoft 365 compliance center to extend protection beyond Exchange email to content in locations such as Teams, SharePoint, devices, and more. With a single data loss prevention (DLP) policy in the Microsoft 365 Compliance Center, you can identify, monitor, and automatically protect sensitive information across Office 365. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams and Endpoint. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Migration wizard brings over your DLP policies from Exchange admin center to O365 DLP. Save on time and effort to move your policies from EAC DLP to O365 DLP. All policies with associated rules are brought over to O365 DLP solution with just a few clicks in the wizard. Minimal post migration steps Since the policies and associated are brought over in the state selected by admin, fine-tuning to policies is minimal. Supports multi-phase migration. The policies can be brought over to O365 DLP in a phased manner. Choose to start with a single policy and test side by side to evaluate O365 DLP solution. Once satisfied, you can bring over the entire lot of policies that exist on the EAC DLP side. Side by side analysis \u2013 Test before you deploy. Bring over the policies to O365 DLP in test mode and compare the GIR to evaluate and re-validate before you move to production. Detailed post migration reports Any rule that may have warnings or errors at the time of migration is captured in the post migration report. Go over the report to identify gaps (if any). Benefits from Migration from EAC-DLP to Microsoft 365 DLP \u2693\ufe0e The following benefits gets to the user with rich experience on: Unified admin console which is easy to maintain Single policy across all workloads (Exchange, SPO, ODB, Teams, Devices, MCAS) Protection of data at rest and in transit. Easy navigation to other compliance features and capabilities More advanced classification and labelling Rich built in alerting and incident management experience Improves ROI by providing new MIP features from a common portal. Greater protection coverage: Available for Office apps on Windows, web, Mac, Android, and iOS Required Roles to Set Up \u2693\ufe0e To create/edit DLP policies/rules in the Microsoft 365 Compliance Center, the user should have a role of Global Admin or Compliance Admin/ Compliance Data Admin Migration Using Wizard \u2693\ufe0e Below is the approach to be followed before migrating Exchange Admin Center DLP policies (along with associated transport rules) to Microsoft 365 compliance center DLP. This section explains the process through an automated wizard approach. Microsoft has developed a migration wizard for replacing the current manual approach to an automated process at a faster pace. This helps in improving the speed and accuracy of the migration. This wizard acts like an accelerator during the migration from EAC-DLP to DLP-EXO. Once ready for migration of EAC (Exchange Admin Centre) DLP rules to Microsoft 365 DLP, please follow the below steps to perform the migration. Open the\u202f Microsoft 365 Compliance center \u202fDLP console.\u202f If there are Exchange EAC DLP policies that needs to be migrated from EAC portal , a banner will appear at the top of the page letting you know of the same. Figure 7: Microsoft Compliance Portal \u2013 Data Loss Prevention- Policy Wizard (Migration) Choose\u202f Migrate policies \u202fin the banner to open the migration wizard. All the Exchange DLP policies are listed. Previously migrated policies cannot be selected.\u202f Click on \u2018Migrate policies\u2019 and select the policies you want to migrate. You can migrate them individually or in groups. Select\u202f Next .\u202f Figure 8: Microsoft Compliance Portal \u2013 Policies to migrate Review the flyout pane for any warnings or messages. Resolve any issues before proceeding.\u202f If there are any warnings, below screen will appear. Figure 9: Microsoft Compliance Portal \u2013 warnings screen Note Policies, rules, priority, and status will be exported as-is, from EAC DLP for admin\u2019s deeper analysis. Select the mode you want the new Exchange DLP policy created in,\u202f Active,\u202fTest, or Disabled . The default is\u202f Test . Select\u202f Next . Figure 10: Microsoft Compliance Portal \u2013 Test mode or Turn on Choose the locations (highlighted) to extend the policy to other locations. A duplicate policy will be created for the additional workloads. Figure 11: Microsoft Compliance Portal \u2013 choose policies across work load Review the Policies to Migrate Figure 12: Microsoft Compliance Portal \u2013 Review Click on Migrate . All the selected policies will be migrated. Download the post migration report to review the rules and policies that have been successfully migrated. Figure 13: Microsoft Compliance Portal \u2013 Post Migration Pay attention to any failures involving Exchange mail flow rules. You can fix them in EAC using the recommendations provided in the post migration report and re-migrate the associated policies. The migrated policies into Microsoft 365 compliance center will be displayed as below: Figure 14: Microsoft Compliance Portal \u2013 Data Loss Prevention- Status (Test Mode) Testing and Validation \u2693\ufe0e A thorough parallel testing can be done between the policies in EAC and MICROSOFT 365 compliance center. You may perform the validations either through the email incident reports or through policy match reports or both. The details of both the approaches are provided in the following sections. Validate by comparing email incident reports \u2693\ufe0e For a side-by-side analysis we can generate Incident Report (GIR) coming from both EAC-DLP and DLP-EXO. Below figures shows both Incident Reports \u2013 One from Microsoft 365 DLP and Other from Exchange Admin Centre-DLP Figure 15: Generated Incident Report from Microsoft 365 DLP \u2013 Detected Rule EAC- DLP Incident Report is captured in the screenshot below: Figure 16: Generated Incident Report from Exchange Admin Center \u2013 Detected Rule Given this is a migration scenario where the rule name and policy name would remain the same when the policies are migrated in the test mode for a side by side analysis, it is easy to capture difference between the two as Microsoft 365 DLP GIR would be include Service as a field. Tracking the two GIRs will help the customer in validating that, the previously defined ETRs will work as expected with Microsoft 365 DLP post migration. Validate by comparing the policy matches \u2693\ufe0e To ensure that the migrated policies behave as expected, you can export the reports from both admin centers and do a comparison of the policy matches. Connect to Exchange Online PowerShell Export the EAC DLP report . You can use the below cmdlet and insert the appropriate values: Get-MailDetailDlpPolicyReport -StartDate < dd / mm / yyyy -EndDate < dd / mm / yyyy > -PageSize 5000 | select Date , MessageId , DlpPolicy , TransportRule -Unique | Export-CSV < \"C:\\path\\filename.csv\" > Export the Microsoft 365 DLP report . You can use the below cmdlet and insert the appropriate values: Get-DlpDetailReport -StartDate < dd / mm / yyyy > -EndDate < dd / mm / yyyy > -PageSize 5000 | select Date , Location , DlpCompliancePolicy , DlpComplianceRule -Unique | Export-CSV < \"C:\\path\\filename.csv\" > Production Phase \u2693\ufe0e Post validating the results and upon satisfaction, you can disable the legacy EAC DLP policy in exchange admin center and turn on the Microsoft 365 DLP policy in M365 compliance center . Figure 17: All migrated policies are enabled post testing From then, the IT team/Admin will create, modify, or tune all the DLP rules on Exchange in the unified security and compliance portal. The migration approach, with wizard is much faster than manual approach and is recommended based on our analysis. Insights/Best Practices \u2693\ufe0e Based on experience to date, a solid upgrade largely depends on 6 factors: Understand thoroughly the migration process. Seeing the value of unified Interface Accessing the scope of migration Managing and planning the migration process Taking advantage of MIP console Accommodating the changes and gaps in the Unified Interface FAQs \u2693\ufe0e Are ETR (mail flow rules) being deprecated? No changes planned for mail flow rules. Only Exchange DLP will be deprecated (Dates, yet to announce) Will the migration wizard impact my existing DLP policies in Exchange? No. The migration wizard only creates new policies in compliance center. You can choose to disable the Exchange policies using the wizard or independently Why am I not seeing the migration wizard banner? Migration wizard banner will be displayed only if you have active Exchange DLP policies What should I do if there are any failures in migration? Check details in migration report to understand the root cause. Make required edits in Exchange policy and retry migration using the wizard For testing purpose, can I enable both EAC-DLP rule and Microsoft 365 DLP rule? Yes. As soon as, the results are satisfied, make the EAC-DLP rules to disable state. Why am I getting 2 incident reports? This is expected in case both Exchange and Microsoft 365 DLP policies are in enabled state What should I do if my rules are using unsupported conditions? Create a separate mail flow rule for conditions like SCLOver which are not supported in Microsoft 365 DLP, remove the unsupported condition from the transport rule and perform the migration. Discrepancy in Exchange and Microsoft 365 DLP policy evaluation If policies are enforced in both Exchange and Microsoft 365 DLP, please refer to this document to understand the expected behavior Abbreviations \u2693\ufe0e Name Description MIP Microsoft Information Protection DLP Data Loss prevention ETR Exchange Transport Rule MCC Microsoft Compliance Center EAC Exchange Admin Center SIT Sensitive Information Type EXO Exchange Online ODB OneDrive for Business GIR Generate Incident Report References \u2693\ufe0e https://techcommunity.microsoft.com/t5/security-compliance-and-identity/migrating-from-exchange-transport-rules-to-unified-dlp-the/ba-p/1749723#M4410 https://techcommunity.microsoft.com/t5/security-compliance-and-identity/migrate-legacy-exchange-dlp-policies-to-the-microsoft/ba-p/2198883 https://docs.microsoft.com/en-us/microsoft-365/compliance/create-test-tune-dlp-policy?view=o365-worldwide https://docs.microsoft.com/en-us/exchange/security-and-compliance/mail-flow-rules/mail-flow-rules https://techcommunity.microsoft.com/t5/microsoft-security-and/understanding-unified-labeling-migration/ba-p/783185","title":"Legacy DLP Policies (ETR) to DLP Playbook"},{"location":"playbooks/etr2dlp/#introduction","text":"Please use this guide as a starting point for migrating Exchange Transport Rules (EAC-DLP) to Microsoft 365 DLP (Microsoft Compliance Center) . All links and references should be up to date, however, in the event that you have a question about the correctness of any information in this document, please reach out to our yammer group aka.ms/askmipteam For a refresher on the knowledge and differences between Exchange Transport Rules (EAC-DLP) and Microsoft Information Protection \u2013DLP (MIP-DLP) when applied to the Exchange workload , please review the overview section of this documentation prior to moving forward. All screenshots in this guide contain the proper configuration settings according to best practices at the time of publication. Please ensure that your configurations mirror those used in this guide. Please refer to the Microsoft documentation online at https://docs.microsoft.com/en-us/microsoft-365/compliance/?view=o365-worldwide for the latest updates. Though the name of this document shows as play book, it can be equally considered as a deployment guide. This document will be updated as and when new features are introduced to the Migration Wizard. Also please note that, not all below stages needs to be implemented. It all depends on the requirement of the organization and the availability of licenses. There are 2 stages/tracks exists in any of the MIP/DLP deployment Stage 1 : Migration from ETR (EAC-DLP) to Microsoft 365 DLP (EXO) Stage 2 : Integration with other workloads (SPO/ODB/MCAS/Devices) (Out of scope of this document) . Refer this blog for more details","title":"Introduction"},{"location":"playbooks/etr2dlp/#objective","text":"This document provides an overview of how enterprise customers can migrate their existing Exchange Transport Rules (DLP) to Microsoft compliance portal \u2013 DLP(EXO). It walks through the different stages of migration and shows the effectiveness of the DLP portal as a single place to define all aspects of your DLP strategy. In summary, this play book will help to Understand the migration process. Understand the unified console and interface. Develop a strategy for the migration. Ensure a smooth migration process. Find resources to support the migration process.","title":"Objective"},{"location":"playbooks/etr2dlp/#scope","text":"This document helps readers understand the process to be followed during the migration of traditional exchange transport rules from Exchange Admin Centre (EAC) portal \u2013 DLP section to Microsoft Compliance Center- DLP portal , followed by the addition of other workloads based on the organizational need. Microsoft Compliance portal has integration with multiple workloads that help to protect customer data with a single policy. This document helps in understanding the process to be followed in migrating existing traditional ETR rules in Exchange Center Portal (DLP) to Microsoft 365 DLP using the in-service - DLP policy Migration Wizard.","title":"Scope"},{"location":"playbooks/etr2dlp/#assumptions","text":"Customer is currently using ETR (EAC-DLP) policies for data protection on Exchange. All the Data Classification needs (Sensitive Information Types) has been Identified.","title":"Assumptions"},{"location":"playbooks/etr2dlp/#intended-audience","text":"Customers, Partners, Internal Microsoft employees","title":"Intended Audience"},{"location":"playbooks/etr2dlp/#overview","text":"","title":"Overview"},{"location":"playbooks/etr2dlp/#exchange-admin-center-data-loss-prevention","text":"Prior to Microsoft 365 DLP, most organizations protected data using the rules created in Exchange. You can use mail flow rules (also known as transport rules) to identify and act on messages that flow through the Exchange Online organization. Mail flow rules are like the Inbox rules available in Outlook and Outlook on the web. Mail flow rules contain a richer set of conditions, exceptions, and actions, which provide you with the flexibility to implement many types of messaging policies. Please note that, Exchange Transport Rules are not deprecating, and they remain same. Only, the ETR\u2019s linked to Exchange DLP policy (refer below URL or Figure-1) are being migrated (recommended) to Microsoft 365 DLP portal. data loss prevention - Microsoft Exchange (office365.com) Like Microsoft 365 DLP portal, mail flow rules have components such as: Conditions, Exceptions, Actions and Alerts/notifications. Mail flow rules are primarily used for: Defining rules to encrypt messages. Defining rules to route mails based on keywords or phrases. Block mails when the attachment contains Sensitive Information Types or exceeds a recommended size. Organization-wide message disclaimers, signatures, footers, or headers in Exchange Online Setting the spam confidence level (SCL) in messages For summary and detail reports about messages that matched mail flow rules, see here . The exchange transport rules are available in https://outlook.office365.com/ecp/?form=eac&mkt=en-US . The rules that are in the highlighted portion of the below picture are the rules, needs to be migrated to the Microsoft 365 DLP portal using the Wizard. Other Rules remains in the portal and is not part of this migration. Figure 1: Exchange Admin Center On click of the yellow ribbon, you will be taken to the compliance Portal for further actions. The compliance Portal overview has been given in the next section.","title":"Exchange Admin Center - Data Loss Prevention"},{"location":"playbooks/etr2dlp/#microsoft-compliance-center-mcc","text":"Microsoft Compliance Centre has many Compliance Products, and this document helps in understanding one of the product/platforms, i.e., Microsoft Information Protection (MIP) at a high level. It has 3 components. 1 \u2013 Data Classification 2-Data Loss Prevention 3-Information Protection. Current documents talk more about, Data Loss Prevention (DLP) Microsoft Information Protection (MIP) helps to identify, discover, classify, protect, and prevent sensitive information wherever it lives either at rest or in transit. Figure 2: Microsoft Information Protection Cycle Know your data assists in understanding the current data landscape and provides organizations with the ability to identify sensitive content residing in Microsoft 365, across Exchange, SPO, ODB and physical devices depending on workloads used and licensing owned. Protect your data assists in applying flexible protection that includes visual marking, encryption and access restrictions across apps, services and devices that travel inside and outside the organization. Prevent data loss (DLP) assists in preventing the accidental data loss and oversharing of sensitive information with-in or outside the organization. In the Data Loss Prevention capability of MIP, Global and Compliance admins can create policies across workloads and applies rules to protect data oversharing. Pre-defined built in regulatory templates across various industries are available. Administrators can create their own custom policies to suit organizational needs. Once the data is classified based on the organizational needs, start creating the policies/rules to prevent the data loss using the URL: https://compliance.microsoft.com/datalossprevention . Login with an appropriate role as described in this document and create policies as per the need on one location or on multiple locations. Figure 3: Microsoft 365 Compliance Portal DLP Wizard Figure 4: Microsoft 365 Compliance Portal - DLP across workloads The alerts produced during the protection of data can be viewed using DLP-Alerts/Activity explorer. Activity explorer (E5 license) provides a 360-degree view (also known as \u201cKnow your data\u201d) of user risky activities across the tenant and helps administrators take preventive measures. Figure 5 shows Activity Explorer with detailed metadata of user activity where and when it has happened. Figure 5: Activity Explorer with user activities Similarly, MIP has a Content Explorer which is part of the Data Classification dashboard. Content Explorer shows a current snapshot of items with sensitivity labels, retention labels and contained Sensitive Information Types in your organization. A DLP policy can help protect sensitive information, which is detected through one or more Sensitive Information Types. Microsoft 365 includes definitions for many common Sensitive Information Types from across many different regions that are ready to use. For example, a credit card number, bank account numbers, national ID numbers, and Windows Live ID service numbers. Figure 6: Content Explorer with summary view Upon further drill down, the exact file location and file containing sensitive information can be viewed for further action or protection, along with data pertaining to last modification date and user. Note For both features (Activity explorer and Content Explorer), separate role-based access is required to view the files. With the availability of the unified console across, Microsoft recommends migrating all existing ETR (EAC-DLP) rules into Microsoft 365 DLP(EXO). This will provide a far more streamlined experience for administrators via a single console.","title":"Microsoft Compliance Center (MCC)"},{"location":"playbooks/etr2dlp/#why-now-moving-to-mcc-dlp","text":"DLP policy management will soon be retired from the Exchange admin center, so we recommend migrating these policies to the Microsoft 365 compliance center to extend protection beyond Exchange email to content in locations such as Teams, SharePoint, devices, and more. With a single data loss prevention (DLP) policy in the Microsoft 365 Compliance Center, you can identify, monitor, and automatically protect sensitive information across Office 365. With a DLP policy, you can: Identify sensitive information across many locations, such as Exchange Online, SharePoint Online, OneDrive for Business, Microsoft Teams and Endpoint. For example, you can identify any document containing a credit card number that is stored in any OneDrive for Business site, or you can monitor just the OneDrive sites of specific people. Prevent the accidental sharing of sensitive information. For example, you can identify any document or email containing a health record that is shared with people outside your organization, and then automatically block access to that document or block the email from being sent. Monitor and protect sensitive information in the desktop versions of Excel, PowerPoint, and Word. Just like in Exchange Online, SharePoint Online, and OneDrive for Business, these Office desktop programs include the same capabilities to identify sensitive information and apply DLP policies. DLP provides continuous monitoring when people share content in these Office programs. Migration wizard brings over your DLP policies from Exchange admin center to O365 DLP. Save on time and effort to move your policies from EAC DLP to O365 DLP. All policies with associated rules are brought over to O365 DLP solution with just a few clicks in the wizard. Minimal post migration steps Since the policies and associated are brought over in the state selected by admin, fine-tuning to policies is minimal. Supports multi-phase migration. The policies can be brought over to O365 DLP in a phased manner. Choose to start with a single policy and test side by side to evaluate O365 DLP solution. Once satisfied, you can bring over the entire lot of policies that exist on the EAC DLP side. Side by side analysis \u2013 Test before you deploy. Bring over the policies to O365 DLP in test mode and compare the GIR to evaluate and re-validate before you move to production. Detailed post migration reports Any rule that may have warnings or errors at the time of migration is captured in the post migration report. Go over the report to identify gaps (if any).","title":"Why now, moving to MCC-DLP?"},{"location":"playbooks/etr2dlp/#benefits-from-migration-from-eac-dlp-to-microsoft-365-dlp","text":"The following benefits gets to the user with rich experience on: Unified admin console which is easy to maintain Single policy across all workloads (Exchange, SPO, ODB, Teams, Devices, MCAS) Protection of data at rest and in transit. Easy navigation to other compliance features and capabilities More advanced classification and labelling Rich built in alerting and incident management experience Improves ROI by providing new MIP features from a common portal. Greater protection coverage: Available for Office apps on Windows, web, Mac, Android, and iOS","title":"Benefits from Migration from EAC-DLP to Microsoft 365 DLP"},{"location":"playbooks/etr2dlp/#required-roles-to-set-up","text":"To create/edit DLP policies/rules in the Microsoft 365 Compliance Center, the user should have a role of Global Admin or Compliance Admin/ Compliance Data Admin","title":"Required Roles to Set Up"},{"location":"playbooks/etr2dlp/#migration-using-wizard","text":"Below is the approach to be followed before migrating Exchange Admin Center DLP policies (along with associated transport rules) to Microsoft 365 compliance center DLP. This section explains the process through an automated wizard approach. Microsoft has developed a migration wizard for replacing the current manual approach to an automated process at a faster pace. This helps in improving the speed and accuracy of the migration. This wizard acts like an accelerator during the migration from EAC-DLP to DLP-EXO. Once ready for migration of EAC (Exchange Admin Centre) DLP rules to Microsoft 365 DLP, please follow the below steps to perform the migration. Open the\u202f Microsoft 365 Compliance center \u202fDLP console.\u202f If there are Exchange EAC DLP policies that needs to be migrated from EAC portal , a banner will appear at the top of the page letting you know of the same. Figure 7: Microsoft Compliance Portal \u2013 Data Loss Prevention- Policy Wizard (Migration) Choose\u202f Migrate policies \u202fin the banner to open the migration wizard. All the Exchange DLP policies are listed. Previously migrated policies cannot be selected.\u202f Click on \u2018Migrate policies\u2019 and select the policies you want to migrate. You can migrate them individually or in groups. Select\u202f Next .\u202f Figure 8: Microsoft Compliance Portal \u2013 Policies to migrate Review the flyout pane for any warnings or messages. Resolve any issues before proceeding.\u202f If there are any warnings, below screen will appear. Figure 9: Microsoft Compliance Portal \u2013 warnings screen Note Policies, rules, priority, and status will be exported as-is, from EAC DLP for admin\u2019s deeper analysis. Select the mode you want the new Exchange DLP policy created in,\u202f Active,\u202fTest, or Disabled . The default is\u202f Test . Select\u202f Next . Figure 10: Microsoft Compliance Portal \u2013 Test mode or Turn on Choose the locations (highlighted) to extend the policy to other locations. A duplicate policy will be created for the additional workloads. Figure 11: Microsoft Compliance Portal \u2013 choose policies across work load Review the Policies to Migrate Figure 12: Microsoft Compliance Portal \u2013 Review Click on Migrate . All the selected policies will be migrated. Download the post migration report to review the rules and policies that have been successfully migrated. Figure 13: Microsoft Compliance Portal \u2013 Post Migration Pay attention to any failures involving Exchange mail flow rules. You can fix them in EAC using the recommendations provided in the post migration report and re-migrate the associated policies. The migrated policies into Microsoft 365 compliance center will be displayed as below: Figure 14: Microsoft Compliance Portal \u2013 Data Loss Prevention- Status (Test Mode)","title":"Migration Using Wizard"},{"location":"playbooks/etr2dlp/#testing-and-validation","text":"A thorough parallel testing can be done between the policies in EAC and MICROSOFT 365 compliance center. You may perform the validations either through the email incident reports or through policy match reports or both. The details of both the approaches are provided in the following sections.","title":"Testing and Validation"},{"location":"playbooks/etr2dlp/#validate-by-comparing-email-incident-reports","text":"For a side-by-side analysis we can generate Incident Report (GIR) coming from both EAC-DLP and DLP-EXO. Below figures shows both Incident Reports \u2013 One from Microsoft 365 DLP and Other from Exchange Admin Centre-DLP Figure 15: Generated Incident Report from Microsoft 365 DLP \u2013 Detected Rule EAC- DLP Incident Report is captured in the screenshot below: Figure 16: Generated Incident Report from Exchange Admin Center \u2013 Detected Rule Given this is a migration scenario where the rule name and policy name would remain the same when the policies are migrated in the test mode for a side by side analysis, it is easy to capture difference between the two as Microsoft 365 DLP GIR would be include Service as a field. Tracking the two GIRs will help the customer in validating that, the previously defined ETRs will work as expected with Microsoft 365 DLP post migration.","title":"Validate by comparing email incident reports"},{"location":"playbooks/etr2dlp/#validate-by-comparing-the-policy-matches","text":"To ensure that the migrated policies behave as expected, you can export the reports from both admin centers and do a comparison of the policy matches. Connect to Exchange Online PowerShell Export the EAC DLP report . You can use the below cmdlet and insert the appropriate values: Get-MailDetailDlpPolicyReport -StartDate < dd / mm / yyyy -EndDate < dd / mm / yyyy > -PageSize 5000 | select Date , MessageId , DlpPolicy , TransportRule -Unique | Export-CSV < \"C:\\path\\filename.csv\" > Export the Microsoft 365 DLP report . You can use the below cmdlet and insert the appropriate values: Get-DlpDetailReport -StartDate < dd / mm / yyyy > -EndDate < dd / mm / yyyy > -PageSize 5000 | select Date , Location , DlpCompliancePolicy , DlpComplianceRule -Unique | Export-CSV < \"C:\\path\\filename.csv\" >","title":"Validate by comparing the policy matches"},{"location":"playbooks/etr2dlp/#production-phase","text":"Post validating the results and upon satisfaction, you can disable the legacy EAC DLP policy in exchange admin center and turn on the Microsoft 365 DLP policy in M365 compliance center . Figure 17: All migrated policies are enabled post testing From then, the IT team/Admin will create, modify, or tune all the DLP rules on Exchange in the unified security and compliance portal. The migration approach, with wizard is much faster than manual approach and is recommended based on our analysis.","title":"Production Phase"},{"location":"playbooks/etr2dlp/#insightsbest-practices","text":"Based on experience to date, a solid upgrade largely depends on 6 factors: Understand thoroughly the migration process. Seeing the value of unified Interface Accessing the scope of migration Managing and planning the migration process Taking advantage of MIP console Accommodating the changes and gaps in the Unified Interface","title":"Insights/Best Practices"},{"location":"playbooks/etr2dlp/#faqs","text":"Are ETR (mail flow rules) being deprecated? No changes planned for mail flow rules. Only Exchange DLP will be deprecated (Dates, yet to announce) Will the migration wizard impact my existing DLP policies in Exchange? No. The migration wizard only creates new policies in compliance center. You can choose to disable the Exchange policies using the wizard or independently Why am I not seeing the migration wizard banner? Migration wizard banner will be displayed only if you have active Exchange DLP policies What should I do if there are any failures in migration? Check details in migration report to understand the root cause. Make required edits in Exchange policy and retry migration using the wizard For testing purpose, can I enable both EAC-DLP rule and Microsoft 365 DLP rule? Yes. As soon as, the results are satisfied, make the EAC-DLP rules to disable state. Why am I getting 2 incident reports? This is expected in case both Exchange and Microsoft 365 DLP policies are in enabled state What should I do if my rules are using unsupported conditions? Create a separate mail flow rule for conditions like SCLOver which are not supported in Microsoft 365 DLP, remove the unsupported condition from the transport rule and perform the migration. Discrepancy in Exchange and Microsoft 365 DLP policy evaluation If policies are enforced in both Exchange and Microsoft 365 DLP, please refer to this document to understand the expected behavior","title":"FAQs"},{"location":"playbooks/etr2dlp/#abbreviations","text":"Name Description MIP Microsoft Information Protection DLP Data Loss prevention ETR Exchange Transport Rule MCC Microsoft Compliance Center EAC Exchange Admin Center SIT Sensitive Information Type EXO Exchange Online ODB OneDrive for Business GIR Generate Incident Report","title":"Abbreviations"},{"location":"playbooks/etr2dlp/#references","text":"https://techcommunity.microsoft.com/t5/security-compliance-and-identity/migrating-from-exchange-transport-rules-to-unified-dlp-the/ba-p/1749723#M4410 https://techcommunity.microsoft.com/t5/security-compliance-and-identity/migrate-legacy-exchange-dlp-policies-to-the-microsoft/ba-p/2198883 https://docs.microsoft.com/en-us/microsoft-365/compliance/create-test-tune-dlp-policy?view=o365-worldwide https://docs.microsoft.com/en-us/exchange/security-and-compliance/mail-flow-rules/mail-flow-rules https://techcommunity.microsoft.com/t5/microsoft-security-and/understanding-unified-labeling-migration/ba-p/783185","title":"References"},{"location":"playbooks/fsicc/","text":"How to use this guide Please use this guide as a starting point for monitoring and protecting your communication in Microsoft Communication Compliance. All links and references should be up to date, however, if you have a question about the correctness of any information in this document, please reach out to our yammer group . All screenshots in this guide contain the proper configuration settings according to the best practices at the time of publication. Please ensure that your configurations mirror those used in this guide. Please refer to the Microsoft documentation online at docs for the latest updates Though the name of this document is shown as a play book, it can be equally considered a deployment guide. This document will be updated as and when new features are introduced to Microsoft Communication Compliance. This document covers in detail various use cases that can be achieved using Communication Compliance. Introduction \u2693\ufe0e Microsoft's Communication Compliance Playbook for the Financial Services Industry is intended to help Compliance Officers, and Auditors better understand their ability to manage current regulatory requirements regarding communication supervision and the controls needed to manage the risks associated thereof. This understanding can, in turn, help identify potential strategies and solutions designed to protect you, your firm, your personnel, and your clients. The Playbook can be used as a set of guiding principles and best practice use cases for Microsoft Communication Compliance. Additionally, this guide focuses on the regulatory drivers, i.e., the SEC 17A-4, and what internal and external auditors in the Financial Services Industry can use as auditable evidence in substantiating communication supervision controls. This Playbook will be updated when new features are introduced to Microsoft Communication Compliance or when additional FSI regulatory controls and processes are required. Please note This document focuses on and covers various use cases that can be achieved using Communication Compliance for the Financial Services Industries . This is only a guide and should not be interpreted as a guarantee of compliance. It is up to you to evaluate and validate the effectiveness of customer controls per your regulatory environment. Objective \u2693\ufe0e This document provides specific details of how customers can deploy and manage Microsoft Communication Compliance and provide guidance on satisfying internal and external compliance and auditor's requirements for communication supervision controls. In summary, this Playbook will help to: Understand the typical Communication Compliance use cases for the Financial Services Industry. Develop a strategy for ensuring Communication Compliance can meet internal and external auditor requirements and regulatory mandates. Define the compliance controls and validate communication supervision controls. Focus on enforcement and examinations, including an emphasis on cybersecurity, communication/collaboration insights, and risk mitigants. Scope \u2693\ufe0e This Playbook helps plan for a successful deployment and use of Communication Compliance and serves as a user guide to mitigating the risk of exchanging crucial data while communicating over chat, email or other collaboration solutions. Digital Communication Governance and Controls. Compliance professionals face an increased focus by regulators on governance and accountability for communication supervision processes and controls. Organizations should continually monitor their reporting, identification, and escalation processes, as well as internal audit and risk management controls. Geopolitical Uncertainty \u2693\ufe0e Companies, especially those with global footprints and regulatory demands, face increased geopolitical risks. Regulators worldwide have implemented communication supervision regulations, including 17A-4, GDPR, and MiFID II, and are taking other steps that may focus on future communication supervision regulatory requirements. Organizations should map their regulatory rules to their controls, evaluate ongoing regulatory changes, and formalize risk analysis and issue management processes to address these added risks. Organizations who are using Microsoft 365 can also look at utilizing Compliance Manager to stay on top of all the different compliance regulations impacting your industry and/or location and use these as a guide to help you stay compliant with this ever changing environment. More on Compliance Manager Microsoft Compliance Manager - Microsoft 365 Compliance | Microsoft Docs Intended Audience \u2693\ufe0e Compliance officers, IT administrator staff, partners, and auditors. Overview \u2693\ufe0e Communication Compliance is a risk management solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so designated reviewers can examine them. Reviewers can investigate scanned email, Microsoft Teams, Yammer, or third-party communications in your organization and take appropriate actions to make sure they're compliant with your organization's message standards. Financial Service Industry Regulations on Electronic Communications Supervision \u2693\ufe0e The Securities Exchange Act requires broker-dealers to create certain records, retain them for various lengths of time, and keep them in specified formats. FINRA Rules 3110 and 3120 govern supervisory systems and supervisory procedures as they relate to, among other things, electronic communications. These rules require the documentation and ongoing review, testing, and validation of these systems and procedures. In analyzing the enforcement associated with electronic communications, three top trends emerge for which firms should implement best practices: Written supervisory procedures Relevant lexicons (Keywords) Testing supervisory controls Using Relevant Lexicons (Custom Dictionaries) \u2693\ufe0e Compliance-driven organizations can use a lexicon-based (Keyword) approach to electronic communication supervision by ensuring or evaluating those lexicons that are being used are relevant to the business. As a result, and through this approach, specific risks associated with communication and other collaboration solutions are identified, investigated, and mitigated through Communication Compliance policies. By utilizing Microsoft's Communication Compliance solution, control processes can be put in place to periodically review lexicons and update them based on new regulations or specific risks to the organization. Whether an organization develops their own Lexicons, uses Machine-learning (Trainable Classifiers) or uses those developed by third-party vendors, it is extremely important to address the regulatory activity and internal risks specific to the firm and regulatory mandates. A best-practice approach includes ensuring the lexicons being used have context around them rather than using standalone words, such as guarantee, cash, or complain. This will ensure they are targeted and focused on the risk activity trying to be detected. Having context around lexicons will also help minimize false positives and unnecessary reviews, which place a considerable burden on time and resources. Lastly, organizations should develop a plan to revisit lexicons, at a minimum, annually to ensure they are current and specific to the business's risk activity. Testing Communication Supervision Controls \u2693\ufe0e Regular testing of the digital communication supervision process should be conducted to ensure appropriate controls are operationally effective. Testing supervisory controls must include, but are not limited to the following: Investigating or handling policy matches and regulatory violations Proactively detecting whether their overall process and controls are effective. Create formal testing plans and perform regularly scheduled testing of the policies to ensure processes are being followed and gaps are quickly identified and addressed. Sample randomly flagged messages to ensure: Lexicons accuracy. Detect messages that did not flag but should have flagged for review. The application of specific business risk lexicons and a well-thought-out testing strategy ensures the ability to enforce policies associated with electronic communication supervision. Communication Compliance Policies \u2693\ufe0e Communication Compliance policies must be clear, enforceable, and updated as necessary to address regulatory requirements. Compliance officers and auditors should have \"quick and easy\" access to the policies and alerts, and there should be very specific guidance regarding what are (and are not) permissible \"electronic communication mechanisms.\" \u2003 Policies should provide specific language explaining to employees using communication and collaboration tools, such as Microsoft Teams, the potential consequences of non-compliance, and appropriate training (on a regular and \"as-needed\" basis). Types of Electronic Communications Requiring Supervision Policies \u2693\ufe0e External Communications. From a compliance perspective, organizations must establish communication supervision policies regarding the forms of electronic communications that they permit employees to use when conducting business with the public and take reasonable steps to monitor compliance with such policies and regulatory requirements. More specifically, FINRA expects communication supervision policies to prohibit communications with the public for business purposes from employees' own electronic communications devices (including, for example, home computers) unless the organization is capable of properly supervising, receiving, and retaining such communications. Internal Communications . Financial Services firms may use \"risk-based principles\" to decide the extent to which internal communications will be reviewed. In connection with reaching a risk-based assessment, the guidance suggests areas that firms should consider, including assessing information barriers' effectiveness. In addition, firms may view \"various relevant existing processes,\" such as steps taken to reduce, manage, or eliminate potential conflicts of interest; and reviews of internal electronic communications that occur in connection with internal and/or regulatory examinations, transaction reviews, internal disciplinary reviews, and reviews relating to customer complaints or arbitration. Method of Review for Communications \u2693\ufe0e As a general matter, regardless of what review method is used, organizations should alert their reviewers about the issues to be raised and material to be examined, including acceptable content. (Note: Certain SRO rules, such as NASD Rule 2210, prescribe content standards for specified types of communications.) Firms should also develop communication compliance policies for other key and relevant areas of concern, such as the use of confidential, proprietary, and insider trading information, anti-money laundering issues; gifts and gratuities; private securities transactions; customer complaints; conflicts of interest, front-running; and rumor spreading. In addition, where financial services firms permit the use and receipt of encrypted electronic communications, they must monitor and supervise those communications in a controlled and compliant manner. Firms must also be able to review electronic correspondence in all languages to conduct business with the public. Moreover, under certain circumstances (e.g., when a specific problem has been identified), organizations should have their legal and/or compliance departments operate as a reviewer of communication compliance policies and pending alerts. This playbook focuses on two methods of review - \"lexicon-based\" reviews (those based on sensitive words or phrases) and \"random\" reviews (which employ a reasonable percentage sampling technique, whereby some percentage of the electronic communications generated by the firm is reviewed), and identifies areas of consideration with each method. Organizations in highly regulated industries are encouraged to consider \"complementary review techniques,\" which would entail the use of some combination of lexicon-based and random reviews. Moreover, \"to best assure the effectiveness over time of any system, firms should incorporate ongoing evaluation procedures to identify and address any 'loopholes' or other issues that may arise, as the means of transmitting sensitive information 'under the regulatory radar' becomes more sophisticated and difficult to capture.\" Frequency of the Review of Communications' Compliance Controls \u2693\ufe0e This playbook considers the frequency of communications review may vary depending on the nature of the firm's business and should be related to factors as the regulatory requirements, types of business conducted, the type of customers involved, the scope of the activities, the geographical location of the activities, the disciplinary record of covered persons, and the volume of the communications subject to review. With those considerations in mind, firms should prescribe reasonable timeframes within which supervisors are expected to complete their reviews and the tools, i.e., Microsoft Communication Compliance, used. Documentation of the Review of Communications and Collecting Evidence \u2693\ufe0e Compliance-driven organizations must audit their reviews and reasonably demonstrate reviews were conducted, ensure data and artifacts have the greatest level of auditor-reliance while being compliant with the regulatory requirements. This would entail, at a minimum, developed policies, lexicon-based datasets, alerting and disposition strategies, clear identification of the reviewer, the communication that was reviewed, the date of review, and the steps taken as a result of any significant regulatory issues identified during the examination. FINRA adds that \"merely opening the communication will not be deemed a sufficient review and will not satisfy auditable evidence requirements.\" In the event the evidence of the required documentation cannot be achieved, trainable classifiers can be used for organizational communication policy requirements, but depending on your compliance requirements, they may not provide enough evidence of due diligence If this is the case, you should use dictionary-based policies. COMMUNICATION COMPLIANCE USE CASES \u2693\ufe0e Policy Configuration and Management \u2693\ufe0e Organizations can use communication compliance policies to monitor, enforce, and take action on user communications. Users must comply with acceptable use, ethical standards, and other policies in all their business-related communications. Organizations can develop their communication compliance policies to detect and investigate abusive language, insider trading risks, conflicts of interest, unauthorized sharing of sensitive information, and corrective actions to help respond and recover from incidents. Other examples include reviewing broker-dealer communications within the firm to safeguard against potential collusion or bribery activities. 17A-4 requires financial services firms to implement a supervisory or oversight process for communication that is appropriate. The FINRA Rule 3110 is an example of a requirement for organizations to have supervisory procedures to scan user communications and the types of businesses it engages. Microsoft Communication Compliance policies can help organizations meet these requirements by providing a process to both scan and report on corporate communications. Acceptable Digital Communication Channels \u2693\ufe0e FINRA emphasizes that the digital communications of regulated firms meet the record-keeping requirements of Exchange Act rules 17a-3 and 17a-4, as well as FINRA Rule Series 4510 . Financial Services Firms are responsible for conducting due diligence to comply with FINRA rules, securities laws and follow up on potential violations of those rules related to employee communication and collaboration applications. Effective practices recommended include the following: Establish a comprehensive governance program for digital communication channels. Manage the organization's decisions about which digital communication channels are permitted and define each digital channel's compliance processes. Firms are also required to monitor the rapidly changing landscape of digital communication channels and keep compliance processes up to date. Clearly define and control permissible digital channels. Define both approved and prohibited digital channels. Block or restrict the use of prohibited digital channels or prohibited features within digital channels that limit the firm's ability to comply with records management and supervisory requirements. Provide training for digital communications. Implement mandatory training programs before granting access to approved digital channels. Training helps clarify an organization's expectations for business and personal digital communications, and it guides users through using permitted features of each channel in a compliant manner. Risk Management \u2693\ufe0e Using communication compliance policies helps identify and manage potential legal exposure and reduces the risk of damaging corporate reputation. For example, organizations can scan messages for unauthorized communications and conflicts of interest about confidential projects such as upcoming acquisitions, mergers, earnings disclosures, reorganizations, or leadership team changes. Fulfilling Supervisory Requirements \u2693\ufe0e Using the built-in remediation workflows, companies can quickly identify and act on messages with policy matches. The following features increase efficiency for investigation and remediation activities: Pausing Communication Compliance Policies (Preview): Pausing a policy will enable an administrator to suspend evaluations of communications manually. Copying Communication Compliance Policies (Preview): Copying a policy will allow an administrator to make an exact copy of a policy to duplicate an existing working policy to scope to different individuals, groups or applications. Investigating and Remediation: The ability to un-resolve a message and highlighting messages that have been tagged. Monitor and Manage Teams Attachments: (Coming Soon) Analyze the content of documents shared in chat for potential policy match. Monitor and manage Teams Conversations: Analyze teams conversation and even remove inappropriate messages. Team Conversation Context: Get 5 messages before and 5 message after the flagged conversation to be able to quickly see context. Flexible remediation workflow: New remediation workflow helps you quickly act on policy matches, including new options to escalate messages to other reviewers and to send email notifications to users with policy matches. Conversation threading: Messages are now visually grouped by original message and all associated reply messages, giving you better context during investigation and remediation actions. Keyword highlighting: Terms matching policy conditions are highlighted in the message text view to help reviewers quickly locate and remediate policy alerts. Exact and near-duplicate detection: In addition to scanning for exact terms matching communication compliance policies, near-duplicate detection groups textually similar terms and messages together to help speed up your review process. Optical character recognition (OCR): Scan, detect and investigate printed and handwritten text within images embedded or attached to an email or Microsoft Teams chat messages. New Filters: Investigate and remediate policy alerts faster with message filters for several fields, including sender, recipient, date, domains, and many more. Improved message views: Investigation and remediation actions are now quicker with new message source, text, and annotation views. Message attachments are now viewable to provide full context when taking remediation actions. User history view: Historical view of all user message remediation activities, such as past notifications and escalations for policy matches, now provides reviewers with more context during the remediation workflow process. First-time or repeat instances of policy matches for users are now archived and easily viewable. Pattern detected notification: Many harassing and bullying actions occur over time and involve reoccurring instances of the same user behavior. The new pattern detected notification to display in alert details helps raise attention to these alerts and behavior types. Show Translate view: Quickly investigate message details by automatically converting alert message text to the language configured in the displayed language setting in the Microsoft 365 subscription for each reviewer. This supports more then 90 languages provided by Microsoft Translator Languages . LEXICONS AND CUSTOM DICTIONARIES \u2693\ufe0e Organizations can configure custom keyword dictionaries (or lexicons) to provide simple management of keywords specific to your organization or industry. Keyword dictionaries support up to 1 MB of terms (post-compression) in the dictionary and support any language. The tenant limit is also 1 MB after compression. 1 MB of post compression limit means that all dictionaries combined across a tenant can have close to 1 million characters. If needed, you can apply multiple custom keyword dictionaries to a single policy or have a single keyword dictionary per policy. These dictionaries are assigned to a communication compliance policy and can be sourced from a file (such as a .csv or .txt list) or a list you can Import in the Compliance Center . Use custom dictionaries when you need to support terms or languages specific to your organization and policies. Create Your Lexicon or Custom Dictionary \u2693\ufe0e How to create a custom Sensitive Information type using a keyword dictionary In the Microsoft Compliance Center at compliance.microsoft.com click on the Data Classification , and then click on Sensitive Info Types and Create sensitive info type to create the SIT. Figure 1: Microsoft Sensitive Info Types From here, you want to name your SIT and provide a description. These are both mandatory fields. When done click Next . Figure 2: Name your sensitive info type Every sensitive information type entity is defined by these fields: Name: how the sensitive information type is referred to Description: describes what the sensitive information type is looking for Pattern: a pattern defines what a sensitive information type detects. It consists of the following components Primary element \u2013 the main element that the sensitive information type is looking for. It can be a regular expression with or without a checksum validation, a keyword list, a keyword dictionary, or a function. Supporting element \u2013 elements that act as supporting evidence that help in increasing the confidence of the match. For example, keyword \u201cSSN\u201d in proximity of an SSN number. It can be a regular expression with or without a checksum validation, keyword list, keyword dictionary function or a group of elements. Using these can help you get very precise when building a custom sensitive information type. Confidence Level - confidence levels (high, medium, low) reflect how much supporting evidence was detected along with the primary element. The more supporting evidence an item contains, the higher the confidence that a matched item contains the sensitive info you're looking for. Proximity \u2013 When the primary element is matched, any supporting elements will match only when found within this proximity to the primary element. The closer the primary and supporting elements are to each other, the more likely the detected content is going to be what you're looking for. You also have an option to find the supporting elements anywhere in the document. Next, define the pattern for your SIT, as shown below. Figure 3: New SIT pattern Note, the following mandatory fields must be completed: Confidence Level (Low, Medium, High) Primary Element (Regular Expression, Keyword List, Keyword Dictionary, Functions) The following fields are Optional but can help cut down on false positives by providing additional supporting evidence when looking at a your primary elements. Set your character proximity or keep the default value Add any additional supporting elements Add any additional checks Useful Links \u2693\ufe0e Learn about sensitive information types Get Started with Custom Sensitive Information Types Create a Keyword Dictionary Functions Regular Expressions - M365 sensitive information types uses the Boost.RegEx 5.1.3 engine. In this case we have a large list of terms so we care going to use a Custom Keyword Dictionary (Lexicon) by uploading the CSV or TXT file. Note you have other options when creating your elements based on your needs. We will select Keyword dictionary : Figure 4: Select Keyword Dictionary This will open a new window which we are required to upload our csv or txt file and name our dictionary. Figure 5: Upload Keyword Dictionary file Figure 6: Select csv or txt file The following keyword(s) or phrases will be added to the UI as illustrated: Figure 7: Add Keyword dictionary Provide a name for the Lexicon/keyword dictionary and click done . This is the minimum requirements for a custom SIT but as mentioned above you might want to provide other supporting elements and conditions to cut down on the false positives. Figure 8: New pattern with custom dictionary Once you are complete with your pattern click Create . If you would like you can add additional patterns to this sensitive info type (SIT) for example you might have a Low, Medium and High pattern in the same SIT. Your low might be just find a keyword while a High is finding a keyword with supporting elements. Once you are done with the patterns click on Next . Figure 9: Define patterns for this sensitive info type Choose the recommend confidence level for the policy. If you only have one then you should match this. To learn more about confidence levels check out this video- Confidence Level Video In our case we choose high so we will choose high here. Figure 10: Choose the recommended confidence level Review your settings and continue. Figure 11: Review settings Create your Communication Compliance Policy \u2693\ufe0e Now that we have created our custom keyword dictionary we will switch over to the Communication Compliance solution to create a new Communication Compliance Policy. Once in the Communication Compliance solution click on Create policy and select Custom Policy . Figure 12: Customer Communication Compliance Policy You need to provide a Name for your Communication Compliance policy (required field) and add a description if you would like to your custom policy. When done click Next . Figure 13: Name and describe your policy Define what users and/or groups you want to supervise communications for and who the reviews should be for this policy. Click Next . Figure 14: Choose supervised users and reviewers Choose locations you wish to monitor communications. Click Next . If you have any data connectors to 3rd party sources such as Slack or Bloomberg Message, etc you will also see those here. Figure 15: Choose locations to monitor communications On the \"Choose conditions and review percentage\" page. Choose the direction you want to monitor communication. You have tree options here: Inbound Detects communications sent to supervised users from external and internal senders, including other supervised users in this policy. Outbound Detects communications sent from supervised users to external and internal recipients, including other supervised users in this policy. Internal Detects communications between the supervised users or groups in this policy. Choose your conditions. In our case we are going to be selecting the custom keyword dictionary that we created earlier using content contains any of the sensitive info types . There are several options to pick from and you can find more details here - Communication compliance feature reference - Microsoft 365 Compliance | Microsoft Docs Figure 16: Choose content contains any of these sensitive info types Figure 17: Select the custom keyword dictionary After selecting the custom SIT we created before we click Add . If you wish to add any additional conditions or exceptions to your policy you can do that now. In our case we are just looking for the words in our custom keyword dictionary. So we are not going to add any more conditions. You also have additional options such as if you want to capture optical character recognition (OCR) where we will search for these words on images or hard written notes. You also want to make sure you specify what percentage of matches you want to capture. This can be anywhere from 1-100%. You can use this to capture all messages or a sample of the messages based on your organization requirements. Figure 18: Optical Character Recognition When you are done click Next to go to the review settings screen. Figure 19: Review and finish the policy Review the settings and if everything looks correct then click create policy to create the new policy. Otherwise you can go back and make any required changes. Figure 20: Policy Created Once this is complete you will have a Communication Compliance policy using a custom Lexicon set of keywords. Please take the following note: If simple dictionary matches are not enough for a particular scenario an organization needs to detect, multiple keyword lists can be combined via more complex logic (e.g. one word from list A near a word from list B but without the presence of a word from list C) by creating a custom Sensitive Information Type in the Compliance Center or via PowerShell using a custom XML file . Implementation Strategy \u2693\ufe0e See Microsoft 365 productivity illustrations for guidance on implementing all M365 capabilities with a focus on cross technologies. Based on experience, a solid implementation strategy follows these three phases: Crawl -The first stage is about starting to evaluate your organization's security and compliance with your goal of defining a strategic direction for your company. For example, you can create test policies with basic dictionaries that include the words directly associated with the scenarios one wants to detect (e.g. for bribes words like award, payment, reward, bonus, \u201con us\u201d, complimentary, etc.) and monitor communications using these, especially to detect false positives. For each false positive, take note of the words in those messages that you could use to identify the topics where the target words alone would cause a false positive. In the walk phase, you can implement more complex rules that use the learnings from the first phase to more precisely target the right messages. Walk -The second stage builds the foundation for a successful, scale, and sustainable deployment. In this phase, you plan the details of your implementation and build the solution. You may also run a pilot or proof of concept with a select group of users or locations. Run -The last stage is about optimizing the solution for Microsoft 365. In this phase, you will set up an automated, scalable approach for each solution. In the run phase you could include enable OCR in the policies, adding foreign terms (if appropriate for a multinational company) and enable automatic translation, create Power Automate flows, etc. References \u2693\ufe0e Learn about communication compliance - Microsoft 365 Compliance | Microsoft Docs Communication compliance with Microsoft Teams - Microsoft Teams | Microsoft Docs Sensitive information type entity definitions - Microsoft 365 Compliance | Microsoft Docs Get started with trainable classifiers - Microsoft 365 Compliance | Microsoft Docs Trainable classifier auto-labeling with sensitivity labels webinar - Microsoft Tech Community","title":"Financial Services Industry Playbook"},{"location":"playbooks/fsicc/#introduction","text":"Microsoft's Communication Compliance Playbook for the Financial Services Industry is intended to help Compliance Officers, and Auditors better understand their ability to manage current regulatory requirements regarding communication supervision and the controls needed to manage the risks associated thereof. This understanding can, in turn, help identify potential strategies and solutions designed to protect you, your firm, your personnel, and your clients. The Playbook can be used as a set of guiding principles and best practice use cases for Microsoft Communication Compliance. Additionally, this guide focuses on the regulatory drivers, i.e., the SEC 17A-4, and what internal and external auditors in the Financial Services Industry can use as auditable evidence in substantiating communication supervision controls. This Playbook will be updated when new features are introduced to Microsoft Communication Compliance or when additional FSI regulatory controls and processes are required. Please note This document focuses on and covers various use cases that can be achieved using Communication Compliance for the Financial Services Industries . This is only a guide and should not be interpreted as a guarantee of compliance. It is up to you to evaluate and validate the effectiveness of customer controls per your regulatory environment.","title":"Introduction"},{"location":"playbooks/fsicc/#objective","text":"This document provides specific details of how customers can deploy and manage Microsoft Communication Compliance and provide guidance on satisfying internal and external compliance and auditor's requirements for communication supervision controls. In summary, this Playbook will help to: Understand the typical Communication Compliance use cases for the Financial Services Industry. Develop a strategy for ensuring Communication Compliance can meet internal and external auditor requirements and regulatory mandates. Define the compliance controls and validate communication supervision controls. Focus on enforcement and examinations, including an emphasis on cybersecurity, communication/collaboration insights, and risk mitigants.","title":"Objective"},{"location":"playbooks/fsicc/#scope","text":"This Playbook helps plan for a successful deployment and use of Communication Compliance and serves as a user guide to mitigating the risk of exchanging crucial data while communicating over chat, email or other collaboration solutions. Digital Communication Governance and Controls. Compliance professionals face an increased focus by regulators on governance and accountability for communication supervision processes and controls. Organizations should continually monitor their reporting, identification, and escalation processes, as well as internal audit and risk management controls.","title":"Scope"},{"location":"playbooks/fsicc/#geopolitical-uncertainty","text":"Companies, especially those with global footprints and regulatory demands, face increased geopolitical risks. Regulators worldwide have implemented communication supervision regulations, including 17A-4, GDPR, and MiFID II, and are taking other steps that may focus on future communication supervision regulatory requirements. Organizations should map their regulatory rules to their controls, evaluate ongoing regulatory changes, and formalize risk analysis and issue management processes to address these added risks. Organizations who are using Microsoft 365 can also look at utilizing Compliance Manager to stay on top of all the different compliance regulations impacting your industry and/or location and use these as a guide to help you stay compliant with this ever changing environment. More on Compliance Manager Microsoft Compliance Manager - Microsoft 365 Compliance | Microsoft Docs","title":"Geopolitical Uncertainty"},{"location":"playbooks/fsicc/#intended-audience","text":"Compliance officers, IT administrator staff, partners, and auditors.","title":"Intended Audience"},{"location":"playbooks/fsicc/#overview","text":"Communication Compliance is a risk management solution in Microsoft 365 that helps minimize communication risks by helping you detect, capture, and act on inappropriate messages in your organization. Pre-defined and custom policies allow you to scan internal and external communications for policy matches so designated reviewers can examine them. Reviewers can investigate scanned email, Microsoft Teams, Yammer, or third-party communications in your organization and take appropriate actions to make sure they're compliant with your organization's message standards.","title":"Overview"},{"location":"playbooks/fsicc/#financial-service-industry-regulations-on-electronic-communications-supervision","text":"The Securities Exchange Act requires broker-dealers to create certain records, retain them for various lengths of time, and keep them in specified formats. FINRA Rules 3110 and 3120 govern supervisory systems and supervisory procedures as they relate to, among other things, electronic communications. These rules require the documentation and ongoing review, testing, and validation of these systems and procedures. In analyzing the enforcement associated with electronic communications, three top trends emerge for which firms should implement best practices: Written supervisory procedures Relevant lexicons (Keywords) Testing supervisory controls","title":"Financial Service Industry Regulations on Electronic Communications Supervision"},{"location":"playbooks/fsicc/#using-relevant-lexicons-custom-dictionaries","text":"Compliance-driven organizations can use a lexicon-based (Keyword) approach to electronic communication supervision by ensuring or evaluating those lexicons that are being used are relevant to the business. As a result, and through this approach, specific risks associated with communication and other collaboration solutions are identified, investigated, and mitigated through Communication Compliance policies. By utilizing Microsoft's Communication Compliance solution, control processes can be put in place to periodically review lexicons and update them based on new regulations or specific risks to the organization. Whether an organization develops their own Lexicons, uses Machine-learning (Trainable Classifiers) or uses those developed by third-party vendors, it is extremely important to address the regulatory activity and internal risks specific to the firm and regulatory mandates. A best-practice approach includes ensuring the lexicons being used have context around them rather than using standalone words, such as guarantee, cash, or complain. This will ensure they are targeted and focused on the risk activity trying to be detected. Having context around lexicons will also help minimize false positives and unnecessary reviews, which place a considerable burden on time and resources. Lastly, organizations should develop a plan to revisit lexicons, at a minimum, annually to ensure they are current and specific to the business's risk activity.","title":"Using Relevant Lexicons (Custom Dictionaries)"},{"location":"playbooks/fsicc/#testing-communication-supervision-controls","text":"Regular testing of the digital communication supervision process should be conducted to ensure appropriate controls are operationally effective. Testing supervisory controls must include, but are not limited to the following: Investigating or handling policy matches and regulatory violations Proactively detecting whether their overall process and controls are effective. Create formal testing plans and perform regularly scheduled testing of the policies to ensure processes are being followed and gaps are quickly identified and addressed. Sample randomly flagged messages to ensure: Lexicons accuracy. Detect messages that did not flag but should have flagged for review. The application of specific business risk lexicons and a well-thought-out testing strategy ensures the ability to enforce policies associated with electronic communication supervision.","title":"Testing Communication Supervision Controls"},{"location":"playbooks/fsicc/#communication-compliance-policies","text":"Communication Compliance policies must be clear, enforceable, and updated as necessary to address regulatory requirements. Compliance officers and auditors should have \"quick and easy\" access to the policies and alerts, and there should be very specific guidance regarding what are (and are not) permissible \"electronic communication mechanisms.\" \u2003 Policies should provide specific language explaining to employees using communication and collaboration tools, such as Microsoft Teams, the potential consequences of non-compliance, and appropriate training (on a regular and \"as-needed\" basis).","title":"Communication Compliance Policies"},{"location":"playbooks/fsicc/#types-of-electronic-communications-requiring-supervision-policies","text":"External Communications. From a compliance perspective, organizations must establish communication supervision policies regarding the forms of electronic communications that they permit employees to use when conducting business with the public and take reasonable steps to monitor compliance with such policies and regulatory requirements. More specifically, FINRA expects communication supervision policies to prohibit communications with the public for business purposes from employees' own electronic communications devices (including, for example, home computers) unless the organization is capable of properly supervising, receiving, and retaining such communications. Internal Communications . Financial Services firms may use \"risk-based principles\" to decide the extent to which internal communications will be reviewed. In connection with reaching a risk-based assessment, the guidance suggests areas that firms should consider, including assessing information barriers' effectiveness. In addition, firms may view \"various relevant existing processes,\" such as steps taken to reduce, manage, or eliminate potential conflicts of interest; and reviews of internal electronic communications that occur in connection with internal and/or regulatory examinations, transaction reviews, internal disciplinary reviews, and reviews relating to customer complaints or arbitration.","title":"Types of Electronic Communications Requiring Supervision Policies"},{"location":"playbooks/fsicc/#method-of-review-for-communications","text":"As a general matter, regardless of what review method is used, organizations should alert their reviewers about the issues to be raised and material to be examined, including acceptable content. (Note: Certain SRO rules, such as NASD Rule 2210, prescribe content standards for specified types of communications.) Firms should also develop communication compliance policies for other key and relevant areas of concern, such as the use of confidential, proprietary, and insider trading information, anti-money laundering issues; gifts and gratuities; private securities transactions; customer complaints; conflicts of interest, front-running; and rumor spreading. In addition, where financial services firms permit the use and receipt of encrypted electronic communications, they must monitor and supervise those communications in a controlled and compliant manner. Firms must also be able to review electronic correspondence in all languages to conduct business with the public. Moreover, under certain circumstances (e.g., when a specific problem has been identified), organizations should have their legal and/or compliance departments operate as a reviewer of communication compliance policies and pending alerts. This playbook focuses on two methods of review - \"lexicon-based\" reviews (those based on sensitive words or phrases) and \"random\" reviews (which employ a reasonable percentage sampling technique, whereby some percentage of the electronic communications generated by the firm is reviewed), and identifies areas of consideration with each method. Organizations in highly regulated industries are encouraged to consider \"complementary review techniques,\" which would entail the use of some combination of lexicon-based and random reviews. Moreover, \"to best assure the effectiveness over time of any system, firms should incorporate ongoing evaluation procedures to identify and address any 'loopholes' or other issues that may arise, as the means of transmitting sensitive information 'under the regulatory radar' becomes more sophisticated and difficult to capture.\"","title":"Method of Review for Communications"},{"location":"playbooks/fsicc/#frequency-of-the-review-of-communications-compliance-controls","text":"This playbook considers the frequency of communications review may vary depending on the nature of the firm's business and should be related to factors as the regulatory requirements, types of business conducted, the type of customers involved, the scope of the activities, the geographical location of the activities, the disciplinary record of covered persons, and the volume of the communications subject to review. With those considerations in mind, firms should prescribe reasonable timeframes within which supervisors are expected to complete their reviews and the tools, i.e., Microsoft Communication Compliance, used.","title":"Frequency of the Review of Communications' Compliance Controls"},{"location":"playbooks/fsicc/#documentation-of-the-review-of-communications-and-collecting-evidence","text":"Compliance-driven organizations must audit their reviews and reasonably demonstrate reviews were conducted, ensure data and artifacts have the greatest level of auditor-reliance while being compliant with the regulatory requirements. This would entail, at a minimum, developed policies, lexicon-based datasets, alerting and disposition strategies, clear identification of the reviewer, the communication that was reviewed, the date of review, and the steps taken as a result of any significant regulatory issues identified during the examination. FINRA adds that \"merely opening the communication will not be deemed a sufficient review and will not satisfy auditable evidence requirements.\" In the event the evidence of the required documentation cannot be achieved, trainable classifiers can be used for organizational communication policy requirements, but depending on your compliance requirements, they may not provide enough evidence of due diligence If this is the case, you should use dictionary-based policies.","title":"Documentation of the Review of Communications and Collecting Evidence"},{"location":"playbooks/fsicc/#communication-compliance-use-cases","text":"","title":"COMMUNICATION COMPLIANCE USE CASES"},{"location":"playbooks/fsicc/#policy-configuration-and-management","text":"Organizations can use communication compliance policies to monitor, enforce, and take action on user communications. Users must comply with acceptable use, ethical standards, and other policies in all their business-related communications. Organizations can develop their communication compliance policies to detect and investigate abusive language, insider trading risks, conflicts of interest, unauthorized sharing of sensitive information, and corrective actions to help respond and recover from incidents. Other examples include reviewing broker-dealer communications within the firm to safeguard against potential collusion or bribery activities. 17A-4 requires financial services firms to implement a supervisory or oversight process for communication that is appropriate. The FINRA Rule 3110 is an example of a requirement for organizations to have supervisory procedures to scan user communications and the types of businesses it engages. Microsoft Communication Compliance policies can help organizations meet these requirements by providing a process to both scan and report on corporate communications.","title":"Policy Configuration and Management"},{"location":"playbooks/fsicc/#acceptable-digital-communication-channels","text":"FINRA emphasizes that the digital communications of regulated firms meet the record-keeping requirements of Exchange Act rules 17a-3 and 17a-4, as well as FINRA Rule Series 4510 . Financial Services Firms are responsible for conducting due diligence to comply with FINRA rules, securities laws and follow up on potential violations of those rules related to employee communication and collaboration applications. Effective practices recommended include the following: Establish a comprehensive governance program for digital communication channels. Manage the organization's decisions about which digital communication channels are permitted and define each digital channel's compliance processes. Firms are also required to monitor the rapidly changing landscape of digital communication channels and keep compliance processes up to date. Clearly define and control permissible digital channels. Define both approved and prohibited digital channels. Block or restrict the use of prohibited digital channels or prohibited features within digital channels that limit the firm's ability to comply with records management and supervisory requirements. Provide training for digital communications. Implement mandatory training programs before granting access to approved digital channels. Training helps clarify an organization's expectations for business and personal digital communications, and it guides users through using permitted features of each channel in a compliant manner.","title":"Acceptable Digital Communication Channels"},{"location":"playbooks/fsicc/#risk-management","text":"Using communication compliance policies helps identify and manage potential legal exposure and reduces the risk of damaging corporate reputation. For example, organizations can scan messages for unauthorized communications and conflicts of interest about confidential projects such as upcoming acquisitions, mergers, earnings disclosures, reorganizations, or leadership team changes.","title":"Risk Management"},{"location":"playbooks/fsicc/#fulfilling-supervisory-requirements","text":"Using the built-in remediation workflows, companies can quickly identify and act on messages with policy matches. The following features increase efficiency for investigation and remediation activities: Pausing Communication Compliance Policies (Preview): Pausing a policy will enable an administrator to suspend evaluations of communications manually. Copying Communication Compliance Policies (Preview): Copying a policy will allow an administrator to make an exact copy of a policy to duplicate an existing working policy to scope to different individuals, groups or applications. Investigating and Remediation: The ability to un-resolve a message and highlighting messages that have been tagged. Monitor and Manage Teams Attachments: (Coming Soon) Analyze the content of documents shared in chat for potential policy match. Monitor and manage Teams Conversations: Analyze teams conversation and even remove inappropriate messages. Team Conversation Context: Get 5 messages before and 5 message after the flagged conversation to be able to quickly see context. Flexible remediation workflow: New remediation workflow helps you quickly act on policy matches, including new options to escalate messages to other reviewers and to send email notifications to users with policy matches. Conversation threading: Messages are now visually grouped by original message and all associated reply messages, giving you better context during investigation and remediation actions. Keyword highlighting: Terms matching policy conditions are highlighted in the message text view to help reviewers quickly locate and remediate policy alerts. Exact and near-duplicate detection: In addition to scanning for exact terms matching communication compliance policies, near-duplicate detection groups textually similar terms and messages together to help speed up your review process. Optical character recognition (OCR): Scan, detect and investigate printed and handwritten text within images embedded or attached to an email or Microsoft Teams chat messages. New Filters: Investigate and remediate policy alerts faster with message filters for several fields, including sender, recipient, date, domains, and many more. Improved message views: Investigation and remediation actions are now quicker with new message source, text, and annotation views. Message attachments are now viewable to provide full context when taking remediation actions. User history view: Historical view of all user message remediation activities, such as past notifications and escalations for policy matches, now provides reviewers with more context during the remediation workflow process. First-time or repeat instances of policy matches for users are now archived and easily viewable. Pattern detected notification: Many harassing and bullying actions occur over time and involve reoccurring instances of the same user behavior. The new pattern detected notification to display in alert details helps raise attention to these alerts and behavior types. Show Translate view: Quickly investigate message details by automatically converting alert message text to the language configured in the displayed language setting in the Microsoft 365 subscription for each reviewer. This supports more then 90 languages provided by Microsoft Translator Languages .","title":"Fulfilling Supervisory Requirements"},{"location":"playbooks/fsicc/#lexicons-and-custom-dictionaries","text":"Organizations can configure custom keyword dictionaries (or lexicons) to provide simple management of keywords specific to your organization or industry. Keyword dictionaries support up to 1 MB of terms (post-compression) in the dictionary and support any language. The tenant limit is also 1 MB after compression. 1 MB of post compression limit means that all dictionaries combined across a tenant can have close to 1 million characters. If needed, you can apply multiple custom keyword dictionaries to a single policy or have a single keyword dictionary per policy. These dictionaries are assigned to a communication compliance policy and can be sourced from a file (such as a .csv or .txt list) or a list you can Import in the Compliance Center . Use custom dictionaries when you need to support terms or languages specific to your organization and policies.","title":"LEXICONS AND CUSTOM DICTIONARIES"},{"location":"playbooks/fsicc/#create-your-lexicon-or-custom-dictionary","text":"How to create a custom Sensitive Information type using a keyword dictionary In the Microsoft Compliance Center at compliance.microsoft.com click on the Data Classification , and then click on Sensitive Info Types and Create sensitive info type to create the SIT. Figure 1: Microsoft Sensitive Info Types From here, you want to name your SIT and provide a description. These are both mandatory fields. When done click Next . Figure 2: Name your sensitive info type Every sensitive information type entity is defined by these fields: Name: how the sensitive information type is referred to Description: describes what the sensitive information type is looking for Pattern: a pattern defines what a sensitive information type detects. It consists of the following components Primary element \u2013 the main element that the sensitive information type is looking for. It can be a regular expression with or without a checksum validation, a keyword list, a keyword dictionary, or a function. Supporting element \u2013 elements that act as supporting evidence that help in increasing the confidence of the match. For example, keyword \u201cSSN\u201d in proximity of an SSN number. It can be a regular expression with or without a checksum validation, keyword list, keyword dictionary function or a group of elements. Using these can help you get very precise when building a custom sensitive information type. Confidence Level - confidence levels (high, medium, low) reflect how much supporting evidence was detected along with the primary element. The more supporting evidence an item contains, the higher the confidence that a matched item contains the sensitive info you're looking for. Proximity \u2013 When the primary element is matched, any supporting elements will match only when found within this proximity to the primary element. The closer the primary and supporting elements are to each other, the more likely the detected content is going to be what you're looking for. You also have an option to find the supporting elements anywhere in the document. Next, define the pattern for your SIT, as shown below. Figure 3: New SIT pattern Note, the following mandatory fields must be completed: Confidence Level (Low, Medium, High) Primary Element (Regular Expression, Keyword List, Keyword Dictionary, Functions) The following fields are Optional but can help cut down on false positives by providing additional supporting evidence when looking at a your primary elements. Set your character proximity or keep the default value Add any additional supporting elements Add any additional checks","title":"Create Your Lexicon or Custom Dictionary"},{"location":"playbooks/fsicc/#useful-links","text":"Learn about sensitive information types Get Started with Custom Sensitive Information Types Create a Keyword Dictionary Functions Regular Expressions - M365 sensitive information types uses the Boost.RegEx 5.1.3 engine. In this case we have a large list of terms so we care going to use a Custom Keyword Dictionary (Lexicon) by uploading the CSV or TXT file. Note you have other options when creating your elements based on your needs. We will select Keyword dictionary : Figure 4: Select Keyword Dictionary This will open a new window which we are required to upload our csv or txt file and name our dictionary. Figure 5: Upload Keyword Dictionary file Figure 6: Select csv or txt file The following keyword(s) or phrases will be added to the UI as illustrated: Figure 7: Add Keyword dictionary Provide a name for the Lexicon/keyword dictionary and click done . This is the minimum requirements for a custom SIT but as mentioned above you might want to provide other supporting elements and conditions to cut down on the false positives. Figure 8: New pattern with custom dictionary Once you are complete with your pattern click Create . If you would like you can add additional patterns to this sensitive info type (SIT) for example you might have a Low, Medium and High pattern in the same SIT. Your low might be just find a keyword while a High is finding a keyword with supporting elements. Once you are done with the patterns click on Next . Figure 9: Define patterns for this sensitive info type Choose the recommend confidence level for the policy. If you only have one then you should match this. To learn more about confidence levels check out this video- Confidence Level Video In our case we choose high so we will choose high here. Figure 10: Choose the recommended confidence level Review your settings and continue. Figure 11: Review settings","title":"Useful Links"},{"location":"playbooks/fsicc/#create-your-communication-compliance-policy","text":"Now that we have created our custom keyword dictionary we will switch over to the Communication Compliance solution to create a new Communication Compliance Policy. Once in the Communication Compliance solution click on Create policy and select Custom Policy . Figure 12: Customer Communication Compliance Policy You need to provide a Name for your Communication Compliance policy (required field) and add a description if you would like to your custom policy. When done click Next . Figure 13: Name and describe your policy Define what users and/or groups you want to supervise communications for and who the reviews should be for this policy. Click Next . Figure 14: Choose supervised users and reviewers Choose locations you wish to monitor communications. Click Next . If you have any data connectors to 3rd party sources such as Slack or Bloomberg Message, etc you will also see those here. Figure 15: Choose locations to monitor communications On the \"Choose conditions and review percentage\" page. Choose the direction you want to monitor communication. You have tree options here: Inbound Detects communications sent to supervised users from external and internal senders, including other supervised users in this policy. Outbound Detects communications sent from supervised users to external and internal recipients, including other supervised users in this policy. Internal Detects communications between the supervised users or groups in this policy. Choose your conditions. In our case we are going to be selecting the custom keyword dictionary that we created earlier using content contains any of the sensitive info types . There are several options to pick from and you can find more details here - Communication compliance feature reference - Microsoft 365 Compliance | Microsoft Docs Figure 16: Choose content contains any of these sensitive info types Figure 17: Select the custom keyword dictionary After selecting the custom SIT we created before we click Add . If you wish to add any additional conditions or exceptions to your policy you can do that now. In our case we are just looking for the words in our custom keyword dictionary. So we are not going to add any more conditions. You also have additional options such as if you want to capture optical character recognition (OCR) where we will search for these words on images or hard written notes. You also want to make sure you specify what percentage of matches you want to capture. This can be anywhere from 1-100%. You can use this to capture all messages or a sample of the messages based on your organization requirements. Figure 18: Optical Character Recognition When you are done click Next to go to the review settings screen. Figure 19: Review and finish the policy Review the settings and if everything looks correct then click create policy to create the new policy. Otherwise you can go back and make any required changes. Figure 20: Policy Created Once this is complete you will have a Communication Compliance policy using a custom Lexicon set of keywords. Please take the following note: If simple dictionary matches are not enough for a particular scenario an organization needs to detect, multiple keyword lists can be combined via more complex logic (e.g. one word from list A near a word from list B but without the presence of a word from list C) by creating a custom Sensitive Information Type in the Compliance Center or via PowerShell using a custom XML file .","title":"Create your Communication Compliance Policy"},{"location":"playbooks/fsicc/#implementation-strategy","text":"See Microsoft 365 productivity illustrations for guidance on implementing all M365 capabilities with a focus on cross technologies. Based on experience, a solid implementation strategy follows these three phases: Crawl -The first stage is about starting to evaluate your organization's security and compliance with your goal of defining a strategic direction for your company. For example, you can create test policies with basic dictionaries that include the words directly associated with the scenarios one wants to detect (e.g. for bribes words like award, payment, reward, bonus, \u201con us\u201d, complimentary, etc.) and monitor communications using these, especially to detect false positives. For each false positive, take note of the words in those messages that you could use to identify the topics where the target words alone would cause a false positive. In the walk phase, you can implement more complex rules that use the learnings from the first phase to more precisely target the right messages. Walk -The second stage builds the foundation for a successful, scale, and sustainable deployment. In this phase, you plan the details of your implementation and build the solution. You may also run a pilot or proof of concept with a select group of users or locations. Run -The last stage is about optimizing the solution for Microsoft 365. In this phase, you will set up an automated, scalable approach for each solution. In the run phase you could include enable OCR in the policies, adding foreign terms (if appropriate for a multinational company) and enable automatic translation, create Power Automate flows, etc.","title":"Implementation Strategy"},{"location":"playbooks/fsicc/#references","text":"Learn about communication compliance - Microsoft 365 Compliance | Microsoft Docs Communication compliance with Microsoft Teams - Microsoft Teams | Microsoft Docs Sensitive information type entity definitions - Microsoft 365 Compliance | Microsoft Docs Get started with trainable classifiers - Microsoft 365 Compliance | Microsoft Docs Trainable classifier auto-labeling with sensitivity labels webinar - Microsoft Tech Community","title":"References"},{"location":"playbooks/service-side-auto-labeling/","text":"Service-side Auto-Labeling Playbook \u2693\ufe0e Introduction \u2693\ufe0e Microsoft Information Protection (MIP) is a built-in, intelligent, unified, and extensible solution to protect sensitive data across your enterprise \u2013 in Microsoft 365 cloud services, on-premises, third-party SaaS applications, and more. MIP provides a unified set of capabilities to know your data, protect your data, and protect against data loss across Microsoft 365 apps (e.g., Word, PowerPoint, Excel, Outlook) and services (e.g., Microsoft Teams, SharePoint, and Exchange). Figure 1: MIP life cycle Some of the key MIP capabilities include Sensitive information types (SIT), Trainable classifiers, Data classification, Sensitivity labels, Data loss prevention, Endpoint data loss prevention etc. Info For more information: Microsoft Information Protection in Microsoft 365 - Microsoft 365 Compliance | Microsoft Docs MIP Overview \u2693\ufe0e The foundation of MIP is the ability to classify data by our Data Classification Service, please see the MIP constellation below to view how the MIP functionalities all work together. Figure 2: How MIP functionalities work together Identifying and classifying sensitive items that are under your organization's control is the first step in the Information Protection discipline. Foundational to Microsoft are its classification capabilities\u2014from out-of-the-box sensitive information types to machine learning trainable classifiers to automatically finding and classifying sensitive content at scale. Sensitive Information Types are pattern-based classifiers which detect sensitive information like social security, credit card or bank account numbers within a tenant, and help customers to identify, evaluate, and protect their data. Data Classification Service and specifically Sensitive Information Types allow customers to define and identify what information is considered sensitive in their environments. Once you identify what sensitive content is important to you, you can leverage this data classification across your Microsoft 365 Compliance features including, but not limited to: Data Loss Prevention, Communication Compliance, Insider Risk Management, Auto-Labeling, Retention, and Sensitivity Labels. We announced several key enhancements to the intelligence and built-in capabilities of MIP across Microsoft 365 applications and services. These capabilities help organizations reduce the number of false positives as they accurately classify ever-increasing amounts of data. These capabilities also increase the coverage of classified data as they go across Microsoft 365 services and workloads. Info For more information: Microsoft Information Protection: Announcing Enhanced Automatic Classification Capabilities! - Microsoft Tech Community . Per the scope of this playbook, we\u2019ll focus on auto-labeling overview with some basic understanding of the capabilities: Sensitivity labels are at their basic level a tag, that is customizable, persistent, accessible to applications, and visible to users. Labels once applied to documents and email become the basis for enforcing data protection policies throughout the tenants\u2019 digital estate. When a label is applied to a file or email it is persisted as document metadata. When a label is applied to a SharePoint site or OneDrive for business the label persists as container metadata. Auto-Labeling Overview \u2693\ufe0e There are multiple methods for automatically applying a label to emails and documents based on their content in Microsoft 365, two of the key ones are: Client-side auto-labeling: Client-side auto-labeling happens on the client workstation as the user creates or edits a document or email using Word, Excel, PowerPoint, Outlook, and Office web applications (OWA). Depending on the content detected, the label is applied automatically or recommended to the users based on the properties of the label. A default label can also be assigned to documents and emails. This form of client-side labeling does not evaluate document content based on conditions defined on a global policy, but it is based on properties defined for each label. Service-side auto-labeling: Service-side auto-labeling is sometimes referred to as auto-labeling for data at rest and data in transit . Unlike client-side auto-labeling, service side auto labeling does not depend on the client to analyze the document content while it is being created. Instead, service-side auto-labeling reviews content that is stored (at-rest) in SharePoint or OneDrive document libraries, or that is \"in-flight\" or being sent within Exchange. For instance, when a message is submitted to transport. All policy review and application are done within the service. Service-side auto-labeling policies are created and configured from the Information Protection section of the Compliance Center under the Auto-labeling policy tab. Auto-labeling policies don't support recommended labeling because the user doesn't interact with the labeling process. Instead, the administrator runs the policies in simulation mode to help ensure the correct labeling of content before applying the label. Comparison of auto-labeling solutions: The table below provides a comparison of Service-side, Client-side, and Defender for cloud apps auto-labeling solutions that can help you identify when a particular solution is appropriate for labeling needs. Capabilities Service side Client side Defender for cloud apps (MCAS) Application support SharePoint, OneDrive and Exchange Online Word, PowerPoint, Excel or Outlook Microsoft 365 apps, or AIP plugin for Office SharePoint, OneDrive and third-party services supported by Defender for cloud apps File types supported .docx, .xlsx, .pptx and related formats .docx, .xlsx, .pptx and related formats .docx, .xlsx, .pptx and related formats, PDF Policy scoping By site, group or user By label By service, site, folder Classification options Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching Trainable classifiers (in private preview) Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching; Trainable Classifiers Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching; Trainable Classifiers; Fingerprint; Regular Expression Labeling conditions Sensitive content; Content is shared; Recipient properties; Sender properties; Email subject; Document title; Attachment extension; Attachment can't be scanned; Attachment is encrypted; Email headers Sensitive content in document or email body; Sensitive content in attachment Sensitive content; Access level; App; Content is shared; Creation time; File ID; File type; File owner; MIME type; Parent folder; Quarantine status; Existing sensitivity label; Document title; File extension Interaction with users Label visible after user opens document Automatic labeling: user can override; Recommended label: user can accept or dismiss Label visible after user opens document. Content markings are applied on save Applied to New and existing documents (including simulation mode); New emails Content that's created or edited by users New and existing documents (file policy); Content being downloaded; Content being uploaded Behaviors Label is applied; Outbound email is protected; Outbound attachment is protected (Office and PDF documents); Protection is applied to document; Content markings are applied after user opens document and saves it Label is applied; Document is protected; Email is protected; Attachment is protected (Office attachment only); Content marking is applied Label is applied; Protection is applied; Content markings are applied after user opens document and saves it Label external incoming emails Yes On reply or forward N/A Labeling limits 25k documents labeled per day None 100 documents labeled per day (can be extended upon request) For more information on the comparison of client vs. service auto-labeling, we have documentation here: Automatically apply a sensitivity label to content in Microsoft 365 - Microsoft 365 Compliance | Microsoft Docs How does client and service side labeling work in different labeling scenarios? A principle we have is that client/end user provided labels always overrides service basedservice-based ones. In addition, label priority is used in determining when and how an automatic label will be applied. The following table lists some common labeling scenarios, the label setting (i.e., auto or recommended label) and the expected outcome or behavior. Scenario Label Setting Behavior Content has no label Client-side recommendation Recommend new label Client-side auto labeling Apply new label Service-side auto labeling Apply new label Content has label manually applied Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling No action. Manually applied label takes precedence Service-side auto labeling No action. Manually applied label takes precedence Content has default label applied (Label policy) Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling Apply new label if higher sensitivity Service-side auto labeling Apply new label if higher sensitivity Content has auto label applied Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling Apply new label if higher sensitivity Service-side auto labeling Apply new label if higher sensitivity Licensing Requirements \u2693\ufe0e To understand your licensing requirements and options for MIP, see the Information Protection section from the Microsoft 365 licensing documentation . Below is the sensitivity labeling licensing info for your quick reference, however, we encourage you to reference the M365 licensing documentation for up-to-date information. For manual sensitivity labeling , the following licenses provide user rights: Microsoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium Enterprise Mobility + Security E3/E5 Office 365 E5/A5/E3/A3/F3 AIP Plan 1 AIP Plan 2 For both client and service-side automatic sensitivity labeling , the following licenses provide user rights: Microsoft 365 E5/A5/G5 F5 Compliance F5 Security & Compliance Microsoft 365 E5/A5/G5 Information Protection and Governance Office 365 E5 For client-side automatic sensitivity labeling only , the following license provides user rights: Enterprise Mobility + Security E5/A5/G5 AIP Plan 2 To apply and view sensitivity labels in Power BI and to protect data when it's exported from Power BI to Excel, PowerPoint, or PDF , the following licenses provide user rights: Microsoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium Enterprise Mobility + Security E3/E5 AIP Plan 1 AIP Plan 2 Note G3 and G5 are the Office 365 services/plans for Government organizations. For feature-level licensing requirements please refer to Licensing PDF file . Role Requirements \u2693\ufe0e Sensitivity labels from the MIP solution let you classify and protect your organization's data, while making sure that user productivity and their ability to collaborate isn't hindered. Members of your compliance team who will create sensitivity labels need permissions to the Microsoft 365 compliance center. By default, Global Administrators for your tenant have access to this admin center and can give compliance officers and other people access, without giving them all the permissions of a tenant admin. For this delegated limited admin access, add users to the Compliance Data Administrator, Compliance Administrator, or Security Administrator role group. Alternatively, using the default roles, you can create a new role group and add either Sensitivity Label Administrator or Organization Configuration roles to this group. For a read-only role, use Sensitivity Label Reader . These permissions are required only to create and configure sensitivity labels and their label policies. They are not required to apply the labels in apps or services. If additional permissions are needed for specific configurations that relate to sensitivity labels, those permissions will be listed in their respective documentation instructions. To be able to review matched items we find while in simulation mode (process before deployment that allows you to verify what items we will help you label if you turn on the policy), make sure you have the following permissions: Content Explorer List viewer: Membership in this role group allows you to see each item and its location in list view. The data classification list viewer role has been pre-assigned to this role group. Content Explorer Content viewer: Membership in this role group allows you to view the contents of each item in the list. The data classification content viewer role has been pre-assigned to this role group. For instructions to add users to the default roles or create your own role groups, see Permissions in the Microsoft 365 compliance center . The basic flow for deploying and applying sensitivity labels: Figure 3:Labeling flow from admin configuration and end user interaction to protection enforcement MIP Service Auto-Labeling in depth \u2693\ufe0e Auto labeling is a built-in Microsoft service that triggers off sensitive content found in files in SharePoint Online, OneDrive for Business and emails in Exchange Online. Define what sensitive information you want us to protect using regulatory templates, 200+ out of box sensitive info or custom types, named entities, Exact Data Match and ML models in an auto labeling policy. We will simulate what files are detected that match your auto-labeling policy in our simulation mode, so you can review and be confident in our matches before agreeing to allow us to automatically label those documents. Protecting Sensitive Information in SharePoint/OneDrive \u2693\ufe0e Sensitive files are automatically detected and labeled at rest. Office files for Word (.docx), PowerPoint (.pptx), and Excel (.xlsx) are supported. These files can be auto-labeled at rest before or after the auto-labeling policies are created. Files cannot be auto-labeled if they are part of an open session (the file is open). Currently, attachments to list items aren't supported and won't be auto-labeled. Maximum of 25,000 automatically labeled files in your tenant per day. Maximum of 100 auto-labeling policies per tenant, each targeting up to 100 sites (SharePoint or OneDrive) when they are specified individually. You can also specify all sites, and this configuration is exempt from the 100 sites maximum. Existing values for modified, modified by, and the date are not changed because of auto-labeling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. If this account is no longer in Azure Active Directory, the label won't be applied because these values can't be set. Protecting Sensitive Information in Exchange \u2693\ufe0e Sensitive emails are automatically detected and labeled in transit/ as they are sent. For Exchange, it does not include emails at rest (mailboxes). Note Emails detected in simulation mode will not be labeled when the policy is turned on, as we only label emails in transit and those emails were sent before the policy was enforced. Unlike manual labeling or auto-labeling with Office apps, PDF attachments as well as Office attachments are also scanned for the conditions you specify in your auto-labeling policy. When there is a match, the email is labeled but not the attachment. For PDF files, if the label applies encryption, these files are encrypted by using Office 365 Message Encryption (OME) when your tenant is enabled for PDF attachments . For these Office files, Word, PowerPoint, and Excel are supported. If the label applies encryption, they are encrypted by using Office 365 Message Encryption (OME) . If you have Exchange mail flow rules or data loss prevention (DLP) policies that apply IRM encryption: When content is identified by these rules or policies and an auto-labeling policy, the label is applied. If that label applies encryption, the IRM settings from the Exchange mail flow rules or DLP policies are ignored. However, if that label doesn't apply encryption, the IRM settings from the mail flow rules or DLP policies are applied in addition to the label. Email that has IRM encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labeling. Incoming email is labeled when there is a match with your auto-labeling conditions: If the label is configured for encryption , that encryption isn't applied. If the label is configured to apply dynamic markings , be aware that this configuration can result in the names of people outside your organization. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. There currently isn't a way to set a Rights Manager owner for all incoming email messages that are automatically encrypted. Requirements for configuring Service-side Auto-labeling \u2693\ufe0e Simulation mode: Auditing for Microsoft 365 must be turned on. If you need to turn on auditing or you're not sure whether auditing is already on, see Turn audit log search on or off . To auto-label files in SharePoint and OneDrive: You have enabled sensitivity labels for Office files in SharePoint and OneDrive . At the time the auto-labeling policy runs, the file mustn't be open by another process or user. A file that's checked out for editing falls into this category. If you plan to use custom sensitive information types rather than the built-in sensitivity types: Custom sensitivity information types apply only to content that is added or modified in SharePoint or OneDrive after the custom sensitivity information types are created. To test new custom sensitive information types, create them before you create your auto-labeling policy, and then create new documents with sample data for testing. Creating a MIP auto-labeling policy \u2693\ufe0e Step 1: Create and publish sensitivity labels \u2693\ufe0e One or more sensitivity labels created and published (to at least one user) that you can select for your auto-labeling policies. For these labels: It does not matter if the auto-labeling in Office apps label setting is turned on or off, because that label setting supplements auto-labeling policies If the labels you want to use for auto-labeling are configured to use visual markings (headers, footers, watermarks), note that these are not applied to documents. We recommend that you have your label taxonomy and hierarchy defined in a label policy applied to all users to help them get started with manual labeling from the information worker side. [Optional] While it is important to have your label taxonomy mostly defined, this does not include the need to define protection actions like encyrption. Encryption can be added to the label properties after the fact. Since protections are checked every time a document is opened, changes in protections to labels will be enforced. If the labels apply encryption : - When the auto-labeling policy includes locations for SharePoint or OneDrive, the label must be configured for the Assign permissions now setting. - When the auto-labeling policy is just for Exchange, the label can be configured for either Assign permissions now or Let users assign permissions (for the Do Not Forward or Encrypt-Only options). In defining your labels, you can set up in-app auto-labeling recommendations, where you define what sensitive information you are concerned about, and information workers will see a banner that says that recommends them to label this document with that label if your defined sensitive information is found in the document they are working with. You can define a default label in your label policy that is automatically applied to files and emails in use that have not been manually labeled. You can easily get started with all things labeling by using our easy set-up of default label schema, label policy, and auto-labeling policy. In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Information protection Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 4: Banner for easy set-up of default policies located on the MIP overview page Activate recommended features to set up our default policy configurations designed to protect credit card numbers. You will only see this option if you have not set up labeling, in-app labeling recommendation, auto-labeling policy, Teams DLP, or DLP for devices. If you have already set up an auto-labeling policy, you will not be shown this banner but can configure our default auto-labeling policy on your own: Learn about the default labels and policies for Microsoft Information Protection - Microsoft 365 Compliance | Microsoft Docs Step 2: Create an auto-labeling policy \u2693\ufe0e Get started with auto-labeling with our default auto-labeling policy protecting credit card numbers on SharePoint, OneDrive, and Exchange If you already have your labels set up but have not create any auto-labeling policies \u2693\ufe0e In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Information protection Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 5: Banner for easy set-up of default policies located on the MIP overview page Activate recommended features to set up our default policy configurations designed to protect credit card numbers. You will be asked to pick two of your existing labels to use in the auto-labeling policy in simulation mode. We recommend using a \u201cConfidential\u201d like sublabel for both, with the higher count auto-labeling credit card policy having more protections than the low count. Note If you have already set up an auto-labeling policy you will not be shown this banner but can configure our default auto-labeling policy on your own: Learn about the default labels and policies for Microsoft Information Protection - Microsoft 365 Compliance | Microsoft Docs . Extend DLP policies covering Exchange to auto-labeling \u2693\ufe0e In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Data Loss Prevention Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 6: Extend Exchange Online DLP policy to auto-labeling Extend your Exchange DLP policy to an auto-labeling policy in simulation mode. Figure 7: Select your existing Exchange Online DLP policy to convert to auto-labeling simulation Create your own auto-labeling policy \u2693\ufe0e Figure 8: Different types of classifiers that can be used in auto-labeling policy: sensitive information types, named entities (in private preview), exact data match, and trainable classifiers (coming in 2022) You want to protect the sensitive data in your organization. What is sensitive in your organization? Start with our sensitive information types. We have 200+ out of the box sensitive information types that we help detect in your organization. Check content explorer to see which sensitive information types we are finding. So, what information is there? Do you detect a lot of sensitive information that needs to be protected with labeling? If you are unsure of what data to protect or how to get started, look at our provided Financial, Medical and Health, and Privacy templates. These provide a great baseline of sensitive information types to protect given different regulations and industries. You can customize these templates to add more sensitive information types you are concerned with. Named entities recognition (NER), which is something we are doing right now in private preview, allows you to be able to identify entities like physical address, names, and more with other sensitive information types to be more confident that it is something you are looking for. This works great to reduce false positives. As you get more advanced or have more business use cases, you can also explore things like exact data matching which looks at your specific customer data that you are passing in detects and labels for this customer's information. This is a more complex process that requires more time to configure and execute but can bring your false positive rates to near zero allowing you to be more assertive with auto-labeling policies. Another option is trainable classifiers where we use machine learning, to understand what content in your organization looks like from business files like resumes to source code and protect that information. These different classifier types are not mutually exclusive to each other. You can and in fact we encourage you to try out combinations of different types of classifiers. For example, you can use a sensitive information type (SIT) for PII together with named entity recognition for person's names in a policy trying to detect large amounts of identity information in a table, or you can use trainable classifiers together with a custom SIT to detect invoices above a certain amount. You can also use EDM as an exclusion to a rule based on a regular SIT to avoid identifying employee PII as potential customer PII, etc. Pick your scope: Option 1: ALL \u2013 SharePoint sites, OneDrive accounts and Email users Option 2 : Subset of sites or accounts \u2013 can use PowerShell for longer lists Roadmap Note We are working to support OneDrive groups Select a label to use for auto-labeling, but note: This label will not go into effect until you turn on your policy from simulation mode. You can always simulate the policy. Check the matches, and then go back and edit the label used for the policy. The protections of the label you select will then apply to every document automatically labeled. Step 3: Simulate \u2693\ufe0e After 12 hours, you can analyze the results of our auto-labeling simulation. You will be shown files and emails that match your auto-labeling policy configurations that would be labeled if your policy was turned on. Review these matches to make sure they match with what you are expecting. Step 4: Refine Policy \u2693\ufe0e Fine tuning your policy \u2693\ufe0e If you are seeing high amounts of false positives, fine-tune your policy with the following recommendations: Increase the thresholds of sensitive information types found to determine severity It is okay to use different thresholds for individual classifiers Understand confidence levels and how they are defined Low confidence may be good! Try using a low confidence with high threshold or a higher confidence level Group like information types together Combine multiple SITs to detect combinations that matter (e.g. a Social Security Number on its own may not be relevant without a person associated, but an SSN together with an account number, a person's name or a medical condition may be). Switch from looking for \u201cAny of these\u201d to \u201cAll of these\u201d Use Boolean operators to combine groups Look for SSN AND Driver\u2019s License instead of SSN OR driver\u2019s License Figure 9: Example of how to use Boolean operators to combine groups of sensitive information Advanced refinement \u2693\ufe0e More advanced refinement strategies if the above don\u2019t work: Switch this policy to be for client-side auto labeling, since false positives are much less problematic with client-side since the user can take care of the \"mistake\" with one click Use EDM to eliminate false positives by matching only known sensitive information (ex. actual customer PII) Clone and modify the built-in SITs to include additional conditions, such as keywords, more stringent matching of values or stronger formatting requirements. Modify a custom SIT to exclude known prefixes, suffixes or patterns. For example, a custom SIT to detect phone numbers might trigger for every email if your email signatures or document headers include your offices phone numbers. Excluding the sequences common to your company's phones as prefixes to your custom SIT can prevent the rule from triggering for every email or document. Include additional dictionary-based SITs as conditions to narrow down the matches to those that talk about the relevant topics. ex. a rule for matching patient diagnostics may be enhanced by requiring the presence of words like diagnostic, diagnosis, condition, symptom, patient, etc. Step 5: Enforce \u2693\ufe0e When you are confident in the matches you see in simulation, turn on your policy from simulation mode so that we can start auto labeling the files and emails in your organization. You can see what\u2019s getting labeled through activity explorer. Auto labeling use cases from our customers \u2693\ufe0e Scenario 1: Protecting payment information of customers \u2693\ufe0e A lot of customers have an interest in protecting their financial data surrounding payment data to comply with financial regulations. This usually entails a combination of bank account numbers, PII (Personal Identifiable Information) of customers, credit card numbers and account information. Figure 10: Out of the box financial templates you can use for auto-labeling Recommendation \u2693\ufe0e Use our U.S. Gramm-Leach Bliley Act (GLBA) Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only Scenario 2: Complying with HIPPA regulations on health care data \u2693\ufe0e Another field that we\u2019ve seen a lot of interest in protecting is health care data information to comply with HIPPA regulations. Figure 11: Out of the box healthcare templates you can use for auto-labeling and the grouping of sensitive information types they protect Recommendation \u2693\ufe0e Use our U.S. Health Insurance Act (HIPPA) Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only Scenario 3: Protecting personal data \u2693\ufe0e Similarly, we have seen an interest in protecting the personal data of both customers and employees. We have auto-labeling templates to protect U.S. Personally Identifiable Information (PII) Data, General Data Protection Regulation (GDPR), and more. Figure 12: Out of the box privacy templates you can use for auto-labeling Recommendation \u2693\ufe0e Use our U.S. PII Data Enhanced or GDPR Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only Advanced Scenario \u2693\ufe0e Consider using exact data matching (EDM) to identify patient healthcare data. Reports \u2693\ufe0e Simulation results showing number of files and emails matched in how which locations are available when you click on the auto-labeling policy for more details. Figure 13: Example of simulation mode showing number of files matched for review After an auto-labeling policy is enabled, you can view the labeling activity in Activity Explorer: Figure 14: Activity Explorer showcases auto labeling activities Implementation Strategy \u2693\ufe0e If you do not have labels set up yet, set up all things labeling with our default policies and configurations . If you have labels, and an Exchange DLP policy, extend your Exchange DLP policy to auto-labeling . If you have client-side auto-labeling set up, but no service side auto-labeling policy: Use client-side auto labeling or recommendations and service-side auto labeling in combination, with the same conditions but with different thresholds, ex. use high confidence matches for service-side auto labeling and use low or medium confidence for a client-side recommendation, which gives the user an option to dismiss the label if it isn't appropriate for the content and apply a different label. If you have labels set up, but no service side auto-labeling policy: Get started with auto-labeling with our default auto-labeling policy Create custom auto-labeling policy using a template Create auto labeling policies that trigger for different confidence levels of the SITs with different counts (ex. one high confidence count or multiple medium confidence count) to avoid false positives without risking leakage of large amounts of sensitive data that may not meet the most stringent conditions of higher confidence. Tip Use content explorer to understand where data is present that may need to be included in an auto-labeling policy. FAQ \u2693\ufe0e How should I finetune for false positives? \u2693\ufe0e Increase the thresholds of sensitive information types found to determine severity It is okay to use different thresholds for individual classifiers Understand confidence levels and how they are defined Low confidence may be good! Try using a low confidence with high threshold or a higher confidence level Group like information types together Switch from looking for \u201cAny of these\u201d to \u201cAll of these\u201d Use Boolean operators to combine groups Look for SSN AND Driver\u2019s License instead of SSN OR driver\u2019s License Figure 15: Example of how to use Boolean operators to combine groups of sensitive information Advanced method: Use Exact Data Matching to only look for a specific set of data like your specific customer information (this is a more complex process that takes time to configure) What do I do if I have over 1 million matched files and cannot enforce my auto-labeling policy? \u2693\ufe0e Since we have a limit of 25,000 files being labeled a day on SharePoint/OneDrive , we want to make sure it does not take us that long to label all the matches from your policy. First check to make sure all the matches are accurate. If not, please finetune the policy for false positives. If the matches all look accurate but the matches still exceed 1 million, scope your policies to a smaller subset of locations first and enforce that policy. Then go in and create another identical policy scoped to the remaining locations. How does changing label protections affect auto-labeling? \u2693\ufe0e For SharePoint and OneDrive, when a file is open, we retrieve the updated protection actions of the labels. Therefore, any updates to the label protections will be reflected on the document the next time it is opened. For Exchange, emails are stamped with the label and associated protections at the time of the email being sent. If a label protection is modified, previously labeled emails with that label will retain the old permissions, but any new emails sent will have the new label protections. What happens if I need to change my label schema after enforcing an auto-labeling policy? \u2693\ufe0e We recommend that you have your established label schema in place before continuing to auto-labeling, but understand that sometimes minds change and revisions are needed. Decide what your new label schema is Create the new label schema. Edit existing labels if possible to fit the new label hierarchy, but do not delete any old labels yet. Determine if the label you used for auto-labeling is still appropriate? If so, you are all set. If not, determine the replacement label you would like to use. Make sure the replacement label has a higher label priority than the original label. Edit the auto-labeling policy to use the new label with higher label priority Simulate the policy Enforce the policy Delete original label if no longer part of your new label schema What is simulation mode? \u2693\ufe0e Simulation mode is a process between configuring the policy and enforcing it. It allows you to see what matches we find that match your policy configuration that will be labeled if you enforced your policy. No labeling is done in simulation mode. It serves as a reassurance assessment of our sensitive information type detection before we apply any labels for you automatically. What happens when I turn on a policy? \u2693\ufe0e Files and emails will start getting labeled according to your auto-labeling policy. You can view what is being labeled in activity explorer. We have a limit of 25,000 files being labeled a day on SharePoint/OneDrive , so labeling might span the course of several days depending on how many matched files we found in simulation mode. Abbreviations \u2693\ufe0e Acronym Definition EDM Exact Data Match EXO Exchange Online MIP Microsoft Information Protection NER Named Entity Recognition ODB OneDrive for Business OWA Office Web Applications PII Personally Identifiable Information SIT Sensitive Information Type SPO SharePoint Online TC Trainable Classifiers","title":"\ud83c\udd95 Service Side Auto-labeling"},{"location":"playbooks/service-side-auto-labeling/#service-side-auto-labeling-playbook","text":"","title":"Service-side Auto-Labeling Playbook"},{"location":"playbooks/service-side-auto-labeling/#introduction","text":"Microsoft Information Protection (MIP) is a built-in, intelligent, unified, and extensible solution to protect sensitive data across your enterprise \u2013 in Microsoft 365 cloud services, on-premises, third-party SaaS applications, and more. MIP provides a unified set of capabilities to know your data, protect your data, and protect against data loss across Microsoft 365 apps (e.g., Word, PowerPoint, Excel, Outlook) and services (e.g., Microsoft Teams, SharePoint, and Exchange). Figure 1: MIP life cycle Some of the key MIP capabilities include Sensitive information types (SIT), Trainable classifiers, Data classification, Sensitivity labels, Data loss prevention, Endpoint data loss prevention etc. Info For more information: Microsoft Information Protection in Microsoft 365 - Microsoft 365 Compliance | Microsoft Docs","title":"Introduction"},{"location":"playbooks/service-side-auto-labeling/#mip-overview","text":"The foundation of MIP is the ability to classify data by our Data Classification Service, please see the MIP constellation below to view how the MIP functionalities all work together. Figure 2: How MIP functionalities work together Identifying and classifying sensitive items that are under your organization's control is the first step in the Information Protection discipline. Foundational to Microsoft are its classification capabilities\u2014from out-of-the-box sensitive information types to machine learning trainable classifiers to automatically finding and classifying sensitive content at scale. Sensitive Information Types are pattern-based classifiers which detect sensitive information like social security, credit card or bank account numbers within a tenant, and help customers to identify, evaluate, and protect their data. Data Classification Service and specifically Sensitive Information Types allow customers to define and identify what information is considered sensitive in their environments. Once you identify what sensitive content is important to you, you can leverage this data classification across your Microsoft 365 Compliance features including, but not limited to: Data Loss Prevention, Communication Compliance, Insider Risk Management, Auto-Labeling, Retention, and Sensitivity Labels. We announced several key enhancements to the intelligence and built-in capabilities of MIP across Microsoft 365 applications and services. These capabilities help organizations reduce the number of false positives as they accurately classify ever-increasing amounts of data. These capabilities also increase the coverage of classified data as they go across Microsoft 365 services and workloads. Info For more information: Microsoft Information Protection: Announcing Enhanced Automatic Classification Capabilities! - Microsoft Tech Community . Per the scope of this playbook, we\u2019ll focus on auto-labeling overview with some basic understanding of the capabilities: Sensitivity labels are at their basic level a tag, that is customizable, persistent, accessible to applications, and visible to users. Labels once applied to documents and email become the basis for enforcing data protection policies throughout the tenants\u2019 digital estate. When a label is applied to a file or email it is persisted as document metadata. When a label is applied to a SharePoint site or OneDrive for business the label persists as container metadata.","title":"MIP Overview"},{"location":"playbooks/service-side-auto-labeling/#auto-labeling-overview","text":"There are multiple methods for automatically applying a label to emails and documents based on their content in Microsoft 365, two of the key ones are: Client-side auto-labeling: Client-side auto-labeling happens on the client workstation as the user creates or edits a document or email using Word, Excel, PowerPoint, Outlook, and Office web applications (OWA). Depending on the content detected, the label is applied automatically or recommended to the users based on the properties of the label. A default label can also be assigned to documents and emails. This form of client-side labeling does not evaluate document content based on conditions defined on a global policy, but it is based on properties defined for each label. Service-side auto-labeling: Service-side auto-labeling is sometimes referred to as auto-labeling for data at rest and data in transit . Unlike client-side auto-labeling, service side auto labeling does not depend on the client to analyze the document content while it is being created. Instead, service-side auto-labeling reviews content that is stored (at-rest) in SharePoint or OneDrive document libraries, or that is \"in-flight\" or being sent within Exchange. For instance, when a message is submitted to transport. All policy review and application are done within the service. Service-side auto-labeling policies are created and configured from the Information Protection section of the Compliance Center under the Auto-labeling policy tab. Auto-labeling policies don't support recommended labeling because the user doesn't interact with the labeling process. Instead, the administrator runs the policies in simulation mode to help ensure the correct labeling of content before applying the label. Comparison of auto-labeling solutions: The table below provides a comparison of Service-side, Client-side, and Defender for cloud apps auto-labeling solutions that can help you identify when a particular solution is appropriate for labeling needs. Capabilities Service side Client side Defender for cloud apps (MCAS) Application support SharePoint, OneDrive and Exchange Online Word, PowerPoint, Excel or Outlook Microsoft 365 apps, or AIP plugin for Office SharePoint, OneDrive and third-party services supported by Defender for cloud apps File types supported .docx, .xlsx, .pptx and related formats .docx, .xlsx, .pptx and related formats .docx, .xlsx, .pptx and related formats, PDF Policy scoping By site, group or user By label By service, site, folder Classification options Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching Trainable classifiers (in private preview) Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching; Trainable Classifiers Standard Sensitive Info Types; Custom Sensitive Info Types (incl. dictionaries); Exact Data Matching; Trainable Classifiers; Fingerprint; Regular Expression Labeling conditions Sensitive content; Content is shared; Recipient properties; Sender properties; Email subject; Document title; Attachment extension; Attachment can't be scanned; Attachment is encrypted; Email headers Sensitive content in document or email body; Sensitive content in attachment Sensitive content; Access level; App; Content is shared; Creation time; File ID; File type; File owner; MIME type; Parent folder; Quarantine status; Existing sensitivity label; Document title; File extension Interaction with users Label visible after user opens document Automatic labeling: user can override; Recommended label: user can accept or dismiss Label visible after user opens document. Content markings are applied on save Applied to New and existing documents (including simulation mode); New emails Content that's created or edited by users New and existing documents (file policy); Content being downloaded; Content being uploaded Behaviors Label is applied; Outbound email is protected; Outbound attachment is protected (Office and PDF documents); Protection is applied to document; Content markings are applied after user opens document and saves it Label is applied; Document is protected; Email is protected; Attachment is protected (Office attachment only); Content marking is applied Label is applied; Protection is applied; Content markings are applied after user opens document and saves it Label external incoming emails Yes On reply or forward N/A Labeling limits 25k documents labeled per day None 100 documents labeled per day (can be extended upon request) For more information on the comparison of client vs. service auto-labeling, we have documentation here: Automatically apply a sensitivity label to content in Microsoft 365 - Microsoft 365 Compliance | Microsoft Docs How does client and service side labeling work in different labeling scenarios? A principle we have is that client/end user provided labels always overrides service basedservice-based ones. In addition, label priority is used in determining when and how an automatic label will be applied. The following table lists some common labeling scenarios, the label setting (i.e., auto or recommended label) and the expected outcome or behavior. Scenario Label Setting Behavior Content has no label Client-side recommendation Recommend new label Client-side auto labeling Apply new label Service-side auto labeling Apply new label Content has label manually applied Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling No action. Manually applied label takes precedence Service-side auto labeling No action. Manually applied label takes precedence Content has default label applied (Label policy) Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling Apply new label if higher sensitivity Service-side auto labeling Apply new label if higher sensitivity Content has auto label applied Client-side recommendation Recommend new label if higher sensitivity Client-side auto labeling Apply new label if higher sensitivity Service-side auto labeling Apply new label if higher sensitivity","title":"Auto-Labeling Overview"},{"location":"playbooks/service-side-auto-labeling/#licensing-requirements","text":"To understand your licensing requirements and options for MIP, see the Information Protection section from the Microsoft 365 licensing documentation . Below is the sensitivity labeling licensing info for your quick reference, however, we encourage you to reference the M365 licensing documentation for up-to-date information. For manual sensitivity labeling , the following licenses provide user rights: Microsoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium Enterprise Mobility + Security E3/E5 Office 365 E5/A5/E3/A3/F3 AIP Plan 1 AIP Plan 2 For both client and service-side automatic sensitivity labeling , the following licenses provide user rights: Microsoft 365 E5/A5/G5 F5 Compliance F5 Security & Compliance Microsoft 365 E5/A5/G5 Information Protection and Governance Office 365 E5 For client-side automatic sensitivity labeling only , the following license provides user rights: Enterprise Mobility + Security E5/A5/G5 AIP Plan 2 To apply and view sensitivity labels in Power BI and to protect data when it's exported from Power BI to Excel, PowerPoint, or PDF , the following licenses provide user rights: Microsoft 365 E5/A5/G5/E3/A3/G3/F1/F3/Business Premium Enterprise Mobility + Security E3/E5 AIP Plan 1 AIP Plan 2 Note G3 and G5 are the Office 365 services/plans for Government organizations. For feature-level licensing requirements please refer to Licensing PDF file .","title":"Licensing Requirements"},{"location":"playbooks/service-side-auto-labeling/#role-requirements","text":"Sensitivity labels from the MIP solution let you classify and protect your organization's data, while making sure that user productivity and their ability to collaborate isn't hindered. Members of your compliance team who will create sensitivity labels need permissions to the Microsoft 365 compliance center. By default, Global Administrators for your tenant have access to this admin center and can give compliance officers and other people access, without giving them all the permissions of a tenant admin. For this delegated limited admin access, add users to the Compliance Data Administrator, Compliance Administrator, or Security Administrator role group. Alternatively, using the default roles, you can create a new role group and add either Sensitivity Label Administrator or Organization Configuration roles to this group. For a read-only role, use Sensitivity Label Reader . These permissions are required only to create and configure sensitivity labels and their label policies. They are not required to apply the labels in apps or services. If additional permissions are needed for specific configurations that relate to sensitivity labels, those permissions will be listed in their respective documentation instructions. To be able to review matched items we find while in simulation mode (process before deployment that allows you to verify what items we will help you label if you turn on the policy), make sure you have the following permissions: Content Explorer List viewer: Membership in this role group allows you to see each item and its location in list view. The data classification list viewer role has been pre-assigned to this role group. Content Explorer Content viewer: Membership in this role group allows you to view the contents of each item in the list. The data classification content viewer role has been pre-assigned to this role group. For instructions to add users to the default roles or create your own role groups, see Permissions in the Microsoft 365 compliance center . The basic flow for deploying and applying sensitivity labels: Figure 3:Labeling flow from admin configuration and end user interaction to protection enforcement","title":"Role Requirements"},{"location":"playbooks/service-side-auto-labeling/#mip-service-auto-labeling-in-depth","text":"Auto labeling is a built-in Microsoft service that triggers off sensitive content found in files in SharePoint Online, OneDrive for Business and emails in Exchange Online. Define what sensitive information you want us to protect using regulatory templates, 200+ out of box sensitive info or custom types, named entities, Exact Data Match and ML models in an auto labeling policy. We will simulate what files are detected that match your auto-labeling policy in our simulation mode, so you can review and be confident in our matches before agreeing to allow us to automatically label those documents.","title":"MIP Service Auto-Labeling in depth"},{"location":"playbooks/service-side-auto-labeling/#protecting-sensitive-information-in-sharepointonedrive","text":"Sensitive files are automatically detected and labeled at rest. Office files for Word (.docx), PowerPoint (.pptx), and Excel (.xlsx) are supported. These files can be auto-labeled at rest before or after the auto-labeling policies are created. Files cannot be auto-labeled if they are part of an open session (the file is open). Currently, attachments to list items aren't supported and won't be auto-labeled. Maximum of 25,000 automatically labeled files in your tenant per day. Maximum of 100 auto-labeling policies per tenant, each targeting up to 100 sites (SharePoint or OneDrive) when they are specified individually. You can also specify all sites, and this configuration is exempt from the 100 sites maximum. Existing values for modified, modified by, and the date are not changed because of auto-labeling policies\u2014for both simulation mode and when labels are applied. When the label applies encryption, the Rights Management issuer and Rights Management owner is the account that last modified the file. If this account is no longer in Azure Active Directory, the label won't be applied because these values can't be set.","title":"Protecting Sensitive Information in SharePoint/OneDrive"},{"location":"playbooks/service-side-auto-labeling/#protecting-sensitive-information-in-exchange","text":"Sensitive emails are automatically detected and labeled in transit/ as they are sent. For Exchange, it does not include emails at rest (mailboxes). Note Emails detected in simulation mode will not be labeled when the policy is turned on, as we only label emails in transit and those emails were sent before the policy was enforced. Unlike manual labeling or auto-labeling with Office apps, PDF attachments as well as Office attachments are also scanned for the conditions you specify in your auto-labeling policy. When there is a match, the email is labeled but not the attachment. For PDF files, if the label applies encryption, these files are encrypted by using Office 365 Message Encryption (OME) when your tenant is enabled for PDF attachments . For these Office files, Word, PowerPoint, and Excel are supported. If the label applies encryption, they are encrypted by using Office 365 Message Encryption (OME) . If you have Exchange mail flow rules or data loss prevention (DLP) policies that apply IRM encryption: When content is identified by these rules or policies and an auto-labeling policy, the label is applied. If that label applies encryption, the IRM settings from the Exchange mail flow rules or DLP policies are ignored. However, if that label doesn't apply encryption, the IRM settings from the mail flow rules or DLP policies are applied in addition to the label. Email that has IRM encryption with no label will be replaced by a label with any encryption settings when there is a match by using auto-labeling. Incoming email is labeled when there is a match with your auto-labeling conditions: If the label is configured for encryption , that encryption isn't applied. If the label is configured to apply dynamic markings , be aware that this configuration can result in the names of people outside your organization. When the label applies encryption, the Rights Management issuer and Rights Management owner is the person who sends the email. There currently isn't a way to set a Rights Manager owner for all incoming email messages that are automatically encrypted.","title":"Protecting Sensitive Information in Exchange"},{"location":"playbooks/service-side-auto-labeling/#requirements-for-configuring-service-side-auto-labeling","text":"Simulation mode: Auditing for Microsoft 365 must be turned on. If you need to turn on auditing or you're not sure whether auditing is already on, see Turn audit log search on or off . To auto-label files in SharePoint and OneDrive: You have enabled sensitivity labels for Office files in SharePoint and OneDrive . At the time the auto-labeling policy runs, the file mustn't be open by another process or user. A file that's checked out for editing falls into this category. If you plan to use custom sensitive information types rather than the built-in sensitivity types: Custom sensitivity information types apply only to content that is added or modified in SharePoint or OneDrive after the custom sensitivity information types are created. To test new custom sensitive information types, create them before you create your auto-labeling policy, and then create new documents with sample data for testing.","title":"Requirements for configuring Service-side Auto-labeling"},{"location":"playbooks/service-side-auto-labeling/#creating-a-mip-auto-labeling-policy","text":"","title":"Creating a MIP auto-labeling policy"},{"location":"playbooks/service-side-auto-labeling/#step-1-create-and-publish-sensitivity-labels","text":"One or more sensitivity labels created and published (to at least one user) that you can select for your auto-labeling policies. For these labels: It does not matter if the auto-labeling in Office apps label setting is turned on or off, because that label setting supplements auto-labeling policies If the labels you want to use for auto-labeling are configured to use visual markings (headers, footers, watermarks), note that these are not applied to documents. We recommend that you have your label taxonomy and hierarchy defined in a label policy applied to all users to help them get started with manual labeling from the information worker side. [Optional] While it is important to have your label taxonomy mostly defined, this does not include the need to define protection actions like encyrption. Encryption can be added to the label properties after the fact. Since protections are checked every time a document is opened, changes in protections to labels will be enforced. If the labels apply encryption : - When the auto-labeling policy includes locations for SharePoint or OneDrive, the label must be configured for the Assign permissions now setting. - When the auto-labeling policy is just for Exchange, the label can be configured for either Assign permissions now or Let users assign permissions (for the Do Not Forward or Encrypt-Only options). In defining your labels, you can set up in-app auto-labeling recommendations, where you define what sensitive information you are concerned about, and information workers will see a banner that says that recommends them to label this document with that label if your defined sensitive information is found in the document they are working with. You can define a default label in your label policy that is automatically applied to files and emails in use that have not been manually labeled. You can easily get started with all things labeling by using our easy set-up of default label schema, label policy, and auto-labeling policy. In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Information protection Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 4: Banner for easy set-up of default policies located on the MIP overview page Activate recommended features to set up our default policy configurations designed to protect credit card numbers. You will only see this option if you have not set up labeling, in-app labeling recommendation, auto-labeling policy, Teams DLP, or DLP for devices. If you have already set up an auto-labeling policy, you will not be shown this banner but can configure our default auto-labeling policy on your own: Learn about the default labels and policies for Microsoft Information Protection - Microsoft 365 Compliance | Microsoft Docs","title":"Step 1: Create and publish sensitivity labels"},{"location":"playbooks/service-side-auto-labeling/#step-2-create-an-auto-labeling-policy","text":"Get started with auto-labeling with our default auto-labeling policy protecting credit card numbers on SharePoint, OneDrive, and Exchange","title":"Step 2: Create an auto-labeling policy"},{"location":"playbooks/service-side-auto-labeling/#if-you-already-have-your-labels-set-up-but-have-not-create-any-auto-labeling-policies","text":"In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Information protection Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 5: Banner for easy set-up of default policies located on the MIP overview page Activate recommended features to set up our default policy configurations designed to protect credit card numbers. You will be asked to pick two of your existing labels to use in the auto-labeling policy in simulation mode. We recommend using a \u201cConfidential\u201d like sublabel for both, with the higher count auto-labeling credit card policy having more protections than the low count. Note If you have already set up an auto-labeling policy you will not be shown this banner but can configure our default auto-labeling policy on your own: Learn about the default labels and policies for Microsoft Information Protection - Microsoft 365 Compliance | Microsoft Docs .","title":"If you already have your labels set up but have not create any auto-labeling policies"},{"location":"playbooks/service-side-auto-labeling/#extend-dlp-policies-covering-exchange-to-auto-labeling","text":"In the Microsoft 365 compliance center , navigate to sensitivity labels: Solutions > Data Loss Prevention Tip If you don't immediately see this option, first select Show all . In the Overview tab you should see the following banner: Figure 6: Extend Exchange Online DLP policy to auto-labeling Extend your Exchange DLP policy to an auto-labeling policy in simulation mode. Figure 7: Select your existing Exchange Online DLP policy to convert to auto-labeling simulation","title":"Extend DLP policies covering Exchange to auto-labeling"},{"location":"playbooks/service-side-auto-labeling/#create-your-own-auto-labeling-policy","text":"Figure 8: Different types of classifiers that can be used in auto-labeling policy: sensitive information types, named entities (in private preview), exact data match, and trainable classifiers (coming in 2022) You want to protect the sensitive data in your organization. What is sensitive in your organization? Start with our sensitive information types. We have 200+ out of the box sensitive information types that we help detect in your organization. Check content explorer to see which sensitive information types we are finding. So, what information is there? Do you detect a lot of sensitive information that needs to be protected with labeling? If you are unsure of what data to protect or how to get started, look at our provided Financial, Medical and Health, and Privacy templates. These provide a great baseline of sensitive information types to protect given different regulations and industries. You can customize these templates to add more sensitive information types you are concerned with. Named entities recognition (NER), which is something we are doing right now in private preview, allows you to be able to identify entities like physical address, names, and more with other sensitive information types to be more confident that it is something you are looking for. This works great to reduce false positives. As you get more advanced or have more business use cases, you can also explore things like exact data matching which looks at your specific customer data that you are passing in detects and labels for this customer's information. This is a more complex process that requires more time to configure and execute but can bring your false positive rates to near zero allowing you to be more assertive with auto-labeling policies. Another option is trainable classifiers where we use machine learning, to understand what content in your organization looks like from business files like resumes to source code and protect that information. These different classifier types are not mutually exclusive to each other. You can and in fact we encourage you to try out combinations of different types of classifiers. For example, you can use a sensitive information type (SIT) for PII together with named entity recognition for person's names in a policy trying to detect large amounts of identity information in a table, or you can use trainable classifiers together with a custom SIT to detect invoices above a certain amount. You can also use EDM as an exclusion to a rule based on a regular SIT to avoid identifying employee PII as potential customer PII, etc. Pick your scope: Option 1: ALL \u2013 SharePoint sites, OneDrive accounts and Email users Option 2 : Subset of sites or accounts \u2013 can use PowerShell for longer lists Roadmap Note We are working to support OneDrive groups Select a label to use for auto-labeling, but note: This label will not go into effect until you turn on your policy from simulation mode. You can always simulate the policy. Check the matches, and then go back and edit the label used for the policy. The protections of the label you select will then apply to every document automatically labeled.","title":"Create your own auto-labeling policy"},{"location":"playbooks/service-side-auto-labeling/#step-3-simulate","text":"After 12 hours, you can analyze the results of our auto-labeling simulation. You will be shown files and emails that match your auto-labeling policy configurations that would be labeled if your policy was turned on. Review these matches to make sure they match with what you are expecting.","title":"Step 3: Simulate"},{"location":"playbooks/service-side-auto-labeling/#step-4-refine-policy","text":"","title":"Step 4: Refine Policy"},{"location":"playbooks/service-side-auto-labeling/#fine-tuning-your-policy","text":"If you are seeing high amounts of false positives, fine-tune your policy with the following recommendations: Increase the thresholds of sensitive information types found to determine severity It is okay to use different thresholds for individual classifiers Understand confidence levels and how they are defined Low confidence may be good! Try using a low confidence with high threshold or a higher confidence level Group like information types together Combine multiple SITs to detect combinations that matter (e.g. a Social Security Number on its own may not be relevant without a person associated, but an SSN together with an account number, a person's name or a medical condition may be). Switch from looking for \u201cAny of these\u201d to \u201cAll of these\u201d Use Boolean operators to combine groups Look for SSN AND Driver\u2019s License instead of SSN OR driver\u2019s License Figure 9: Example of how to use Boolean operators to combine groups of sensitive information","title":"Fine tuning your policy"},{"location":"playbooks/service-side-auto-labeling/#advanced-refinement","text":"More advanced refinement strategies if the above don\u2019t work: Switch this policy to be for client-side auto labeling, since false positives are much less problematic with client-side since the user can take care of the \"mistake\" with one click Use EDM to eliminate false positives by matching only known sensitive information (ex. actual customer PII) Clone and modify the built-in SITs to include additional conditions, such as keywords, more stringent matching of values or stronger formatting requirements. Modify a custom SIT to exclude known prefixes, suffixes or patterns. For example, a custom SIT to detect phone numbers might trigger for every email if your email signatures or document headers include your offices phone numbers. Excluding the sequences common to your company's phones as prefixes to your custom SIT can prevent the rule from triggering for every email or document. Include additional dictionary-based SITs as conditions to narrow down the matches to those that talk about the relevant topics. ex. a rule for matching patient diagnostics may be enhanced by requiring the presence of words like diagnostic, diagnosis, condition, symptom, patient, etc.","title":"Advanced refinement"},{"location":"playbooks/service-side-auto-labeling/#step-5-enforce","text":"When you are confident in the matches you see in simulation, turn on your policy from simulation mode so that we can start auto labeling the files and emails in your organization. You can see what\u2019s getting labeled through activity explorer.","title":"Step 5: Enforce"},{"location":"playbooks/service-side-auto-labeling/#auto-labeling-use-cases-from-our-customers","text":"","title":"Auto labeling use cases from our customers"},{"location":"playbooks/service-side-auto-labeling/#scenario-1-protecting-payment-information-of-customers","text":"A lot of customers have an interest in protecting their financial data surrounding payment data to comply with financial regulations. This usually entails a combination of bank account numbers, PII (Personal Identifiable Information) of customers, credit card numbers and account information. Figure 10: Out of the box financial templates you can use for auto-labeling","title":"Scenario 1: Protecting payment information of customers"},{"location":"playbooks/service-side-auto-labeling/#recommendation","text":"Use our U.S. Gramm-Leach Bliley Act (GLBA) Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only","title":"Recommendation"},{"location":"playbooks/service-side-auto-labeling/#scenario-2-complying-with-hippa-regulations-on-health-care-data","text":"Another field that we\u2019ve seen a lot of interest in protecting is health care data information to comply with HIPPA regulations. Figure 11: Out of the box healthcare templates you can use for auto-labeling and the grouping of sensitive information types they protect","title":"Scenario 2: Complying with HIPPA regulations on health care data"},{"location":"playbooks/service-side-auto-labeling/#recommendation_1","text":"Use our U.S. Health Insurance Act (HIPPA) Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only","title":"Recommendation"},{"location":"playbooks/service-side-auto-labeling/#scenario-3-protecting-personal-data","text":"Similarly, we have seen an interest in protecting the personal data of both customers and employees. We have auto-labeling templates to protect U.S. Personally Identifiable Information (PII) Data, General Data Protection Regulation (GDPR), and more. Figure 12: Out of the box privacy templates you can use for auto-labeling","title":"Scenario 3: Protecting personal data"},{"location":"playbooks/service-side-auto-labeling/#recommendation_2","text":"Use our U.S. PII Data Enhanced or GDPR Enhanced template On ALL locations (SharePoint, OneDrive, Exchange) Label guidance on which to apply: Label published to all users Confidential Label Priority (2nd highest parent label) Internal Only","title":"Recommendation"},{"location":"playbooks/service-side-auto-labeling/#advanced-scenario","text":"Consider using exact data matching (EDM) to identify patient healthcare data.","title":"Advanced Scenario"},{"location":"playbooks/service-side-auto-labeling/#reports","text":"Simulation results showing number of files and emails matched in how which locations are available when you click on the auto-labeling policy for more details. Figure 13: Example of simulation mode showing number of files matched for review After an auto-labeling policy is enabled, you can view the labeling activity in Activity Explorer: Figure 14: Activity Explorer showcases auto labeling activities","title":"Reports"},{"location":"playbooks/service-side-auto-labeling/#implementation-strategy","text":"If you do not have labels set up yet, set up all things labeling with our default policies and configurations . If you have labels, and an Exchange DLP policy, extend your Exchange DLP policy to auto-labeling . If you have client-side auto-labeling set up, but no service side auto-labeling policy: Use client-side auto labeling or recommendations and service-side auto labeling in combination, with the same conditions but with different thresholds, ex. use high confidence matches for service-side auto labeling and use low or medium confidence for a client-side recommendation, which gives the user an option to dismiss the label if it isn't appropriate for the content and apply a different label. If you have labels set up, but no service side auto-labeling policy: Get started with auto-labeling with our default auto-labeling policy Create custom auto-labeling policy using a template Create auto labeling policies that trigger for different confidence levels of the SITs with different counts (ex. one high confidence count or multiple medium confidence count) to avoid false positives without risking leakage of large amounts of sensitive data that may not meet the most stringent conditions of higher confidence. Tip Use content explorer to understand where data is present that may need to be included in an auto-labeling policy.","title":"Implementation Strategy"},{"location":"playbooks/service-side-auto-labeling/#faq","text":"","title":"FAQ"},{"location":"playbooks/service-side-auto-labeling/#how-should-i-finetune-for-false-positives","text":"Increase the thresholds of sensitive information types found to determine severity It is okay to use different thresholds for individual classifiers Understand confidence levels and how they are defined Low confidence may be good! Try using a low confidence with high threshold or a higher confidence level Group like information types together Switch from looking for \u201cAny of these\u201d to \u201cAll of these\u201d Use Boolean operators to combine groups Look for SSN AND Driver\u2019s License instead of SSN OR driver\u2019s License Figure 15: Example of how to use Boolean operators to combine groups of sensitive information Advanced method: Use Exact Data Matching to only look for a specific set of data like your specific customer information (this is a more complex process that takes time to configure)","title":"How should I finetune for false positives?"},{"location":"playbooks/service-side-auto-labeling/#what-do-i-do-if-i-have-over-1-million-matched-files-and-cannot-enforce-my-auto-labeling-policy","text":"Since we have a limit of 25,000 files being labeled a day on SharePoint/OneDrive , we want to make sure it does not take us that long to label all the matches from your policy. First check to make sure all the matches are accurate. If not, please finetune the policy for false positives. If the matches all look accurate but the matches still exceed 1 million, scope your policies to a smaller subset of locations first and enforce that policy. Then go in and create another identical policy scoped to the remaining locations.","title":"What do I do if I have over 1 million matched files and cannot enforce my auto-labeling policy?"},{"location":"playbooks/service-side-auto-labeling/#how-does-changing-label-protections-affect-auto-labeling","text":"For SharePoint and OneDrive, when a file is open, we retrieve the updated protection actions of the labels. Therefore, any updates to the label protections will be reflected on the document the next time it is opened. For Exchange, emails are stamped with the label and associated protections at the time of the email being sent. If a label protection is modified, previously labeled emails with that label will retain the old permissions, but any new emails sent will have the new label protections.","title":"How does changing label protections affect auto-labeling?"},{"location":"playbooks/service-side-auto-labeling/#what-happens-if-i-need-to-change-my-label-schema-after-enforcing-an-auto-labeling-policy","text":"We recommend that you have your established label schema in place before continuing to auto-labeling, but understand that sometimes minds change and revisions are needed. Decide what your new label schema is Create the new label schema. Edit existing labels if possible to fit the new label hierarchy, but do not delete any old labels yet. Determine if the label you used for auto-labeling is still appropriate? If so, you are all set. If not, determine the replacement label you would like to use. Make sure the replacement label has a higher label priority than the original label. Edit the auto-labeling policy to use the new label with higher label priority Simulate the policy Enforce the policy Delete original label if no longer part of your new label schema","title":"What happens if I need to change my label schema after enforcing an auto-labeling policy?"},{"location":"playbooks/service-side-auto-labeling/#what-is-simulation-mode","text":"Simulation mode is a process between configuring the policy and enforcing it. It allows you to see what matches we find that match your policy configuration that will be labeled if you enforced your policy. No labeling is done in simulation mode. It serves as a reassurance assessment of our sensitive information type detection before we apply any labels for you automatically.","title":"What is simulation mode?"},{"location":"playbooks/service-side-auto-labeling/#what-happens-when-i-turn-on-a-policy","text":"Files and emails will start getting labeled according to your auto-labeling policy. You can view what is being labeled in activity explorer. We have a limit of 25,000 files being labeled a day on SharePoint/OneDrive , so labeling might span the course of several days depending on how many matched files we found in simulation mode.","title":"What happens when I turn on a policy?"},{"location":"playbooks/service-side-auto-labeling/#abbreviations","text":"Acronym Definition EDM Exact Data Match EXO Exchange Online MIP Microsoft Information Protection NER Named Entity Recognition ODB OneDrive for Business OWA Office Web Applications PII Personally Identifiable Information SIT Sensitive Information Type SPO SharePoint Online TC Trainable Classifiers","title":"Abbreviations"},{"location":"playbooks/teamsdlp/","text":"How to use this guide Please use this guide as a starting point for protecting your sensitive information in Microsoft Teams communication channels via Unified DLP. All links and references should be up to date, however, if you have a question about the correctness of any information in this document, please reach out to our yammer group . All screenshots in this guide contain the proper configuration settings according to the best practices at the time of publication. Please ensure that your configurations mirror those used in this guide. Please refer to the Microsoft documentation online at docs for the latest updates Though the name of this document is shown as a play book, it can be equally considered a deployment guide. This document will be updated as and when new features are introduced to Microsoft Teams DLP. There are few abbreviations used in the document and please refer, Abbreviations of this document. This document covers in detail various use cases that can be achieved using Teams-DLP. Introduction \u2693\ufe0e This playbook provides an overview of how enterprise customers can deploy Microsoft Teams-DLP for protecting sensitive information that is coming/going within or outside of the organization. Unified DLP has integration with multiple workloads that help to protect customer data with a single policy. Teams-DLP is one of the workloads within the Unified-DLP console. This playbook walks through the various aspects of deploying use cases across content/containers and shows the effectiveness of the unified DLP portal as a single place to define all aspects of your DLP strategy. Using this play book will help to: Understand the unified console and interface. Develop a strategy for deploying Teams-DLP across the organization. Provide near real time Alerts with notifications. Review various scenarios to test Teams-DLP over chat and channel communication. This playbook helps readers plan and protect sensitive information scenarios that normally exist in every organization. It also helps as a user guide to mitigate the risk of exchanging crucial data while communicating over chat or giving access to sites for guest users. We are making the assumption one has identified the Sensitive Information Types (SITs) that are to be protected In Teams Chat or Channel messages. Info For more information on data classification click here and the deployment accelerator guide click here , please refer to the Appendix section in the whitepaper or Sensitivity Label Taxonomy section in the DAG . Overview \u2693\ufe0e Microsoft Information Protection (MIP) helps to identify, discover, classify, and protect sensitive information wherever it lives either at rest or in transit. Figure 1: Microsoft Information Protection Cycle Know your data assists in understanding the current data landscape and provides organizations with the ability to identify sensitive content residing in Microsoft 365 across Exchange, SharePoint, OneDrive for Business, and physical devices depending on workloads used and licensing owned. Protecting your data assists in applying flexible protection that includes visual marking, encryption and access restrictions across apps, services and devices that travel inside and outside the organization. Prevent data loss (DLP) assists in preventing accidental data loss and oversharing of sensitive information within or outside the organization. In the Data Loss Prevention capability of MIP, Global and Compliance admins can create policies across workloads and apply rules to protect data oversharing. Pre-defined built in regulatory templates across various industries are available. Administrators can also create their own custom policies to suit organizational needs. The URL for creating DLP policies is: DLP . Login with an appropriate role as described in Role Requirements of this document and creating policies inclusive of desired workloads. Figure 2: Microsoft 365 Compliance Portal DLP wizard Data Loss Prevention capabilities are across workloads such as.: Exchange, SPO, ODB, Devices (End point DLP), 3rd party Apps and now to Teams chat and channel messages. Figure 3: Microsoft 365 Compliance Portal \u2013 DLP across workloads This playbook explains the process of protecting data in the location \u201cTeams chat and channel messages.\u201d Individuals can view the DLP actions using reports and explore the files that contain sensitive information or have labels applied using the Content Explorer . The user activities on these labels can be viewed using the Activity Explorer . The below displayed features (Content Explorer & Activity Explorer) are not available on Teams-DLP activities at this moment but on the roadmap. During subsequent releases, the alerts produced during the protection of data can be viewed using DLP-Alerts/Activity Explorer. Activity Explorer, provides a 360-degree view (also known as Know your data ) of user risky activities across the tenant and helps administrators take preventive measures. The below figure shows Activity Explorer with detailed metadata of user activity where and when it has happened. Note Teams-DLP- User Activity in the Activity Explorer is coming soon Figure 4: Activity Explorer with user activities Similarly, MIP has a Content Explorer which is part of the Data Classification dashboard. Content Explorer shows a current snapshot of items with sensitivity labels, retention labels and (SITs) in your organization. A DLP policy can help protect sensitive information, which is detected through one or more sensitive information types. Definitions for many common sensitive information types from across many different regions that are ready to use. For example, a credit card number, bank account numbers, national ID numbers, and Windows Live ID service numbers. Figure 5: Content Explorer with summary view Upon further drill down, the exact file and location containing sensitive information can be viewed for further action or protection, along with data pertaining to the last modification date and user. Tip For both features (Activity Explorer and Content Explorer), separate role-based access is required to view the files Role Requirements . These are on the at this time for Teams-DLP activities. Licensing Requirements \u2693\ufe0e Office 365 Advanced Compliance, which is available as a standalone option and is included in Office 365 E5 and Microsoft 365 E5 Compliance. Office 365 and Microsoft 365 E3 include DLP protection for SharePoint, OneDrive, and Exchange Online. This also includes files that are shared through Teams because Teams uses SharePoint Online and OneDrive to share files. Support for DLP protection in Teams chat and channel messages requires E5 . To learn more about licensing requirements, see Licensing Guide . Role Requirements \u2693\ufe0e To create DLP policies or rules in the Microsoft 365 Compliance Center (MCC), the user should have a role of Global Admin or Compliance Admin or Compliance Data Admin . An additional role is required to view Content Explorer or Activity Explorer. To view the data visualization in the Data Classification module, there are two roles that grant access to content explorer RBAC : Content Explorer List viewer : Membership in this role group allows you to see each item and its location in list view. The data classification list viewer role has been pre-assigned to this role group. Content Explorer Content viewer : Membership in this role group allows you to view the contents of each item in the list. The data classification content viewer role has been pre-assigned to this role group. Data Loss Prevention for Teams-DLP \u2693\ufe0e A DLP policy helps organizations prevent data loss. It also helps users to make better decisions when sending SITs knowingly or unknowingly. The process of creating a unified DLP policy with Teams as the workload is explained in the later sections of this document. Tip Please refer to User Experience , before starting this process. Currently, Teams-DLP supports protecting data while sharing a message or a file that contains sensitive information via 1-1 chat or through channel messages. Below are some of the scenarios of an elevated level. The detailed screenshots with test results have been explained in User Experience of this document. Protecting Sensitive Information in Messages: \u2693\ufe0e If someone is trying to share a chat message that contains sensitive information to an external user or guest, based on the creation of DLP-Rule for the Teams workload, the message will be blocked within seconds. Both the sender and receiver see the message blocked notification. Protecting Sensitive Information in Documents Sharing: \u2693\ufe0e If a user attempts to share a document that contains sensitive information with external users or guests in a Microsoft Teams channel or chat, the DLP rule prevents opening the document by the external user. In this case, the DLP policy must include SharePoint and OneDrive locations in order for protection to be in place. When new files are added to SharePoint or OneDrive in Microsoft 365, it may take a few moments for them to be crawled and indexed. It takes additional time for the Office Data Loss Prevention (DLP) policy to scan the content and apply rules to help protect sensitive information. If external sharing is turned on, sensitive content could be shared and accessed by guests before the Office DLP rule finishes processing. You can ensure that documents are protected until DLP scan completes and marks them as safe to share by using a PowerShell cmdlet to enable a feature called sensitive by default : Set-SPOTenant\u202f-MarkNewFilesSensitiveByDefault BlockExternalSharing Use the cmdlet BlockPerUserNotifyUserOutsideOrg Conditions Content contains any of these sensitive info types: [Select all that applies] Content is shared from Microsoft 365 with people outside my organization . Action Restrict access to the content for external users. Notify users with email and policy tips. Send incident reports to the Administrator. More Information For additional information on sensitive by default , refer here . Protection of Teams and SharePoint sites: \u2693\ufe0e Sensitivity labels can be used to protect data not only in documents and emails, but also in Teams and SharePoint sites. During creation Teams settings can be defined such as: Private (or public), external user access and access from unmanaged devices. When you apply a sensitivity label to a supported container, the label automatically applies the classification and configured protection settings to the site or group. Referring to using sensitivity labels in Teams, Groups or SharePoint sites . This helps protect your Teams and SharePoint sites holistically and not just individual files within those sites. There are various control options available in the M365 compliance center to enable various group settings and to restrict sharing of sensitive information via chat or by sharing the files. The sensitivity labels are then available to a user who is creating a new Team. Teams and Guest Access \u2693\ufe0e Guest is a user type in Microsoft Teams which is included with Office 365 licenses. With guest access, you can provide access to teams, documents within channels, resources, chats, and applications for people external to your organization. In a real-life scenario, guests may be a vendor, a supplier or an external partner who is working on a project but is not a member of your organization and has a business account (Azure AAD) or consumer email account (Outlook, Gmail, Hotmail, etc.). They can participate as guests in Teams and explore the channel experiences. External Access ( Federation ) is turned on by default in Teams, which means your organization can communicate with all external domains. The Teams admin can turn it off or specify which domains to include or exclude. Federation users do not have access to your organization\u2019s Teams or Teams\u2019 resources. They can only communicate via 1-1 chat . If a federation user needs access to Teams\u2019 channels and resources, they must be added as a guest in the organization. The setting up of guest and federation users has been explained in Requirements for Federation or Guest user scenarios . Let's start with the explanation below. Organizations (sender and receiver) which have O365 licenses and Teams enabled, can start 1-1 chats/meetings/voice calls. The external user (receiver) will not be added by default to AAD and will not get access to internal resources like files or folders. This external user will be considered a one-time user and which we call a Federation user . If the user needs additional privileges, administrators will provide access by converting them to a guest user. If a member has been added to a Teams channel, the user profile will be automatically added (forced to add) to Azure Active directory and will be treated almost as an internal user (refer figure below). This user is an external or guest user . Federation: Teams support 1:1 federation chat only . Teams do not currently support: Group Chats with one or more federation users Channel conversations with federation users Figure 6: Adding members to external chat To set-up guest access, please refer here . The detailed comparison of Team member and guest has been explained in this section . When a guest is invited to join a team, they receive a link to accept. The guest must accept the invitation before joining the team and the associated channels. Below is the admin experience of adding additional privileges. Login to Guest access - Microsoft Teams admin center . Figure 7: Admin experience at Microsoft admin center for controlling guest access. Figure 8: External access setting allows \u2013 Chat/voice calls/meetings for federation domains. Requirements for Federation or Guest user scenarios \u2693\ufe0e To test the scenarios a Teams-DLP policy is required along with a guest and federation user. Below steps help in setting up the DLP-Policy and adding new guest users. Step 1: Create Teams-DLP policy \u2693\ufe0e DLP policies help organizations prevent data loss. The process of creating a unified DLP policy with Teams as the workload is explained in the process below. Please refer to the User Experience section before the start of this process. Login to compliance.microsoft.com and click on Data Loss Prevention Click on the create policy. Figure 9: DLP policy creation By default Microsoft provides Industry standard regulatory templates to protect sensitive information. The templates have been divided into 4 categories \u2013 Financial , Medical and Health, Privacy and Custom . Each of the first 3 categories have pre-defined data protection templates based on the industry needs. There is also an option to filter based on country and region. If your organization needs a combination of these templates or a new need that is not available in the list, select Custom Category \u2013 Custom Template . This allows you to choose sensitive types that work for your organization\u2019s needs. Figure 10: Selecting a template Figure 11: DLP Policy name Next, the screen below allows administrators to select the accounts where the chosen sensitive information needs to be protected. It can be implemented across the entire organization, a particular project, or a particular entity of the organization. Also, there is an option to explicitly exclude some accounts from this protection based on the need. If you do not define any explicit inclusions or exclusions, the policy will apply to All Employee with No Exclusions by default. Figure 12: Policy applies to desired locations. Once the applicable project team and business entities to be protected are selected, we need to create a rule and action on the policy as shown on the screen below. Create a rule by adding conditions ( is this rule applicable to Within the Organization or Outside the Organization ) and under content contains, add the sensitive information types which were identified as part of the data classification needs of your organization. In the list of sensitive information types, one has the ability to select SIT\u2019s that were created using regular expressions, out of the box (OOB) provided, and matching keywords. Figure 13: Creation of DLP rules Add exceptions if any and then create actions. By default users are blocked from sending the Teams chats and channel messages that contain the SIT you are protecting. But you can choose who has access to files shared from SharePoint, OneDrive, and Teams Click Next, you can enable the policy right away or you can choose to test for a few days before enabling, as shown below. Figure 14: Test first and then deploy. Step 2: Add a Guest User \u2693\ufe0e Guest users can be added in two ways: From Azure Active Directory or from the Channel->Add member screen in Teams. New user - Azure Active Directory admin center example Figure 15: Adding a guest user through Azure Directory Figure 16: Sending Invite to guest user Figure 17: The user added to AAD Once added the new guest user receives a message as shown below: Figure 18: E-mail message to guests with a link to accept Upon acceptance the guest user then receives the following message: Figure 19: E-mail message after successful addition From this point the user is a member of AAD and has access to all tenant resources, just like an internal user. The admin can restrict access based on organizational needs. Step 3: Create a Teams Channel \u2693\ufe0e In the above steps we have created a DLP policy and added an external user. It is important to consider protecting your Teams channel messages holistically and not just individual files within those sites. There are various control options available in the M365 compliance center to enable various group settings and to restrict sharing of sensitive information via chat or by sharing the files. The sensitivity labels are then available to a user who is creating a new team. At a Team channel or site level, three types of controls are possible: Who can join a Team? a. Privacy \u2013 Public vs Private b. Choose public for anyone in your organization to join the team, or private for only selective members can join the team. c. Control whether the Team owner can add guests to the team. Control access to Teams sites from unmanaged devices a. For unmanaged devices (those not hybrid AD joined or complaint on Intune), allow full access, web only access, or block access completely. Granular control for external sharing of files in Teams sites. a. Choose the level of external sharing : anonymous, secure external sharing, or block external access completely. Let us create a Teams channel and add a user to the channel: Figure 20: New Teams Channel creation Figure 21: Choosing Privacy setting Figure 22: Channel name and purpose Next add a new external user to the newly created channel. Please note that the first user was added through the AAD admin center and this user Gmail account is being added through Teams channel -> Add member. Figure 23: Adding guest users as a member to the newly created channel Please note that this newly added user will automatically be added to AAD, as displayed below: Figure 24: Checking the added user from the AAD admin center In the above steps, we have added 2 users. These 2 users are now added to AAD. @M365x708261.onmicrosoft.com @gmail.com Step 4: Add External (Guest) or Federation User \u2693\ufe0e Next, let us attempt to add a new user, who is a federation and should not be part of AAD. Refer to here for more details. When trying to add the 3rd new user to the existing Teams channel, assume that the user has an O365 license in the tenant. When attempting to add the user directly from Teams, the application only allows the user to be added as a guest user @M365x708261.onmicrosoft.com . Since we do not want this user to be added to AAD we will keep them as federation users (or One-time chat user). Figure 25: Trying to add a Federation user to the channel. We now have 2 guest users, a federation user, a Teams-DLP rule, and a Teams channel. We are ready to test the scenarios. User Experience \u2693\ufe0e Scenario 1: Sharing Credit card details to a Federation user via 1-1 chat. \u2693\ufe0e Sender\u2019s Screen: The Sender is attempting to send credit card information to the newly created federation user via 1-1 chat: Figure 26: Credit card information in Team chat The message is blocked as the DLP rule is activated and the sender is notified: Figure 27: Blocked credit card message Receiver Screen: The receiver gets a blank blocked message, as shown below. Please note that there will be a delay of a few seconds in blocking the message and which is normal behavior (passive DLP). Figure 28: Blank blocked message Scenario 2: Sharing a file from SharePoint /OneDrive to Federation user. \u2693\ufe0e Senders Screen: The Sender is trying to attach a file which has credit card information via 1-1 chat: Figure 29: Option to upload files missing Notice there is no option to upload a file to the federation user since they are not in AAD. Receivers Screen: In this scenario the receiver will not get a message. Scenario 3: Sharing Credit card details with a Federation user via 1-1 chat. If the federation user (Sender) has shared a SIT via 1-1 chat, the DLP rule acted will be based on the federation user organization policies. In the above scenario, if a credit card is not a SIT in the federation user's organization, the message will come as-is to the receiver. The receiver will not have any control over the federation users' DLP policies. Scenario 4: Sharing Credit card details to Guest user via 1-1 chat. \u2693\ufe0e The Sender and Receiver can chat, just like an internal user since the guest is a member of AAD. The Sender then attempts to share sensitive information via chat: Senders Screen: Figure 30: Guest user Teams chat The DLP rule is activated and the message is blocked: Figure 31: DLP blocked message Receivers Screen: The Receiver receives the blocked message, as shown below: Figure 32: Blocked message to receiver Scenario 5: Sharing a file via 1-1 chat with Guest User. \u2693\ufe0e Senders Screen: The Sender is trying to attach a file, which has credit card information, via 1-1 chat to the guest user: Figure 33: Attaching a file in chat with credit card information Figure 34: Attaching a file in chat with credit card information < Figure 35: Attaching a file in chat with credit card information < Receivers Screen: This message was received by the receiver: Figure 36: UI message to receiver The receiver while attempting to open the attachment: Figure 37: Error message when opening file And upon clicking Request Access : Figure 38: Access Denied message Scenario 6: Sharing Credit card details to Guest users via Teams channel chat. \u2693\ufe0e Senders Screen: The Sender attempts to share a credit card number via the channel chat: Figure 39: Attaching a file in channel with credit card information Figure 40: Attaching a file in channel with credit card information Receivers Screen: The message was blocked. Figure 41: Message blocked in Teams channel Scenario 7: Sharing a file to a Guest User on Teams channel \u2693\ufe0e Senders Screen: The Sender attempts to share a file that has credit card number details over the chat in the channel: Figure 42: Attaching a file in channel with credit card information Receivers Screen: The Receiver gets the message and, upon opening the file, receives an access denied message. Figure 43: Error messages when opening Figure 44: Error messages when opening Figure 45: Error messages when opening Reports \u2693\ufe0e After creating the DLP policies or rules on the desired workload (i.e., Teams Chat or Channel), you can track the actions using the reports in the Microsoft 365 Compliance Center. Compliance.microsoft.com -> Reports -> Organization Data > Select Teams . Or https://compliance.microsoft.com/reports/dlppolicymatchesreport This report shows the count of DLP policy matches over time. You can filter the report by date, location, policy, or action. This report can help discover the business processes that may violate the organization\u2019s DLP policies and understand the impact created by the action that is applied on the content. It also helps identify the list of top users and repeat users who are contributing to incidents within your organization. Highlighted in red boxes indicates key filters or features in the reports. Figure 46: DLP-Reports Figure 47: DLP-Incidents Figure 48: DLP-Summary To view the reports in the Microsoft 365 Compliance Center, the user needs to be a member of the Security Reader role group. By default, this role group is assigned to the Compliance Administrator. Implementation Strategy \u2693\ufe0e See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with a focus on cross technologies. Based on experience, a solid Implementation strategy follows these three phases Crawl -The first stage is about starting to evaluate where your organization is today regarding security and compliance with your goal of defining a strategic direction for your company. Use this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for education, defining requirements, and evaluation or testing. This phase is primarily to identify data classification needs like, Identifying the key critical Sensitive Information Types (SIT) Walk -The second stage builds the foundation for a successful, scale, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or proof of concept with a select group of users or locations. This phase deals with protecting the identified, SIT\u2019s. This can be done either by labelling the documents or by applying rules across workloads. Test these policies on certain users/groups before deploying directly into production. Run -The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Keep monitoring the results and fine tune the rules. Validate the results through alerts/reports and take measures. For more details on deployment strategy, visit the MIP DAG Figure 49: Phases of Implementation FAQ \u2693\ufe0e Are there any guidance documents for implementing MIP in various industries, i.e., education, healthcare and finance have quite unique needs? Here is some industry guidance for security and compliance: Industry guidance for S+C Do DLP policies apply to data that are sent from teams to apps that are added to a channel? No, this scenario is not supported today but is on our roadmap. No ETA at this time. Is it on the roadmap that Sensitivity Labels also gets supported in Teams-DLP? Yes, it is on our roadmap. I have external contact and I (accidentally or intentionally) share an SSN in teams, if the team\u2019s policy is in place to restrict SSN to external parties, is this saying that the msg containing the SSN will not go through? Yes, that is correct. The DLP rule will activate and protect data sharing. Is an integration between MIP and Teams planned so that each document that is exchanged through a channel inherits a Sensitivity Label (visual marking and / or protection? There is a roadmap item to have documents inherited from MIP container labels. There is no ETA at this time. If you upload a document to a Teams chat, does DLP scan the document. Use the sensitive by default setting to protect the document until it is scanned to determine if it contains sensitive info. It will be scanned within a few seconds and blocked if necessary. Does Teams respect apps that have been approved/blocked in MCAS? No, not today. We can look into supporting it in the future. I understand that we are eventually \"deprecating\" Streams and recordings will be stored in SPO/OD4B. How can we best utilize DLP for Teams in this scenario? No plan today but this is in our roadmap. There is always a delay of a few seconds before the message gets blocked. Are there any performance improvements planned to handle this? We are looking into building a better pipeline, but this is a major undertaking. It is on our roadmap with no clear timelines. How can we block uploaded and downloaded documents on native Teams clients? You can control document storage for Teams through SharePoint DLP, which acts as the backend for Teams document management. Abbreviations \u2693\ufe0e Name Description MIP Microsoft Information Protection DLP Data Loss Prevention SCC Security and Compliance Center (Portal to create policies) RBAC Role Based Access Control SIT Sensitive Information Type SPO Share Point Online EXO Exchange Online ODB One Drive for Business OOB Out of the box AAD Azure Active Directory","title":"Teams DLP Playbook"},{"location":"playbooks/teamsdlp/#introduction","text":"This playbook provides an overview of how enterprise customers can deploy Microsoft Teams-DLP for protecting sensitive information that is coming/going within or outside of the organization. Unified DLP has integration with multiple workloads that help to protect customer data with a single policy. Teams-DLP is one of the workloads within the Unified-DLP console. This playbook walks through the various aspects of deploying use cases across content/containers and shows the effectiveness of the unified DLP portal as a single place to define all aspects of your DLP strategy. Using this play book will help to: Understand the unified console and interface. Develop a strategy for deploying Teams-DLP across the organization. Provide near real time Alerts with notifications. Review various scenarios to test Teams-DLP over chat and channel communication. This playbook helps readers plan and protect sensitive information scenarios that normally exist in every organization. It also helps as a user guide to mitigate the risk of exchanging crucial data while communicating over chat or giving access to sites for guest users. We are making the assumption one has identified the Sensitive Information Types (SITs) that are to be protected In Teams Chat or Channel messages. Info For more information on data classification click here and the deployment accelerator guide click here , please refer to the Appendix section in the whitepaper or Sensitivity Label Taxonomy section in the DAG .","title":"Introduction"},{"location":"playbooks/teamsdlp/#overview","text":"Microsoft Information Protection (MIP) helps to identify, discover, classify, and protect sensitive information wherever it lives either at rest or in transit. Figure 1: Microsoft Information Protection Cycle Know your data assists in understanding the current data landscape and provides organizations with the ability to identify sensitive content residing in Microsoft 365 across Exchange, SharePoint, OneDrive for Business, and physical devices depending on workloads used and licensing owned. Protecting your data assists in applying flexible protection that includes visual marking, encryption and access restrictions across apps, services and devices that travel inside and outside the organization. Prevent data loss (DLP) assists in preventing accidental data loss and oversharing of sensitive information within or outside the organization. In the Data Loss Prevention capability of MIP, Global and Compliance admins can create policies across workloads and apply rules to protect data oversharing. Pre-defined built in regulatory templates across various industries are available. Administrators can also create their own custom policies to suit organizational needs. The URL for creating DLP policies is: DLP . Login with an appropriate role as described in Role Requirements of this document and creating policies inclusive of desired workloads. Figure 2: Microsoft 365 Compliance Portal DLP wizard Data Loss Prevention capabilities are across workloads such as.: Exchange, SPO, ODB, Devices (End point DLP), 3rd party Apps and now to Teams chat and channel messages. Figure 3: Microsoft 365 Compliance Portal \u2013 DLP across workloads This playbook explains the process of protecting data in the location \u201cTeams chat and channel messages.\u201d Individuals can view the DLP actions using reports and explore the files that contain sensitive information or have labels applied using the Content Explorer . The user activities on these labels can be viewed using the Activity Explorer . The below displayed features (Content Explorer & Activity Explorer) are not available on Teams-DLP activities at this moment but on the roadmap. During subsequent releases, the alerts produced during the protection of data can be viewed using DLP-Alerts/Activity Explorer. Activity Explorer, provides a 360-degree view (also known as Know your data ) of user risky activities across the tenant and helps administrators take preventive measures. The below figure shows Activity Explorer with detailed metadata of user activity where and when it has happened. Note Teams-DLP- User Activity in the Activity Explorer is coming soon Figure 4: Activity Explorer with user activities Similarly, MIP has a Content Explorer which is part of the Data Classification dashboard. Content Explorer shows a current snapshot of items with sensitivity labels, retention labels and (SITs) in your organization. A DLP policy can help protect sensitive information, which is detected through one or more sensitive information types. Definitions for many common sensitive information types from across many different regions that are ready to use. For example, a credit card number, bank account numbers, national ID numbers, and Windows Live ID service numbers. Figure 5: Content Explorer with summary view Upon further drill down, the exact file and location containing sensitive information can be viewed for further action or protection, along with data pertaining to the last modification date and user. Tip For both features (Activity Explorer and Content Explorer), separate role-based access is required to view the files Role Requirements . These are on the at this time for Teams-DLP activities.","title":"Overview"},{"location":"playbooks/teamsdlp/#licensing-requirements","text":"Office 365 Advanced Compliance, which is available as a standalone option and is included in Office 365 E5 and Microsoft 365 E5 Compliance. Office 365 and Microsoft 365 E3 include DLP protection for SharePoint, OneDrive, and Exchange Online. This also includes files that are shared through Teams because Teams uses SharePoint Online and OneDrive to share files. Support for DLP protection in Teams chat and channel messages requires E5 . To learn more about licensing requirements, see Licensing Guide .","title":"Licensing Requirements"},{"location":"playbooks/teamsdlp/#role-requirements","text":"To create DLP policies or rules in the Microsoft 365 Compliance Center (MCC), the user should have a role of Global Admin or Compliance Admin or Compliance Data Admin . An additional role is required to view Content Explorer or Activity Explorer. To view the data visualization in the Data Classification module, there are two roles that grant access to content explorer RBAC : Content Explorer List viewer : Membership in this role group allows you to see each item and its location in list view. The data classification list viewer role has been pre-assigned to this role group. Content Explorer Content viewer : Membership in this role group allows you to view the contents of each item in the list. The data classification content viewer role has been pre-assigned to this role group.","title":"Role Requirements"},{"location":"playbooks/teamsdlp/#data-loss-prevention-for-teams-dlp","text":"A DLP policy helps organizations prevent data loss. It also helps users to make better decisions when sending SITs knowingly or unknowingly. The process of creating a unified DLP policy with Teams as the workload is explained in the later sections of this document. Tip Please refer to User Experience , before starting this process. Currently, Teams-DLP supports protecting data while sharing a message or a file that contains sensitive information via 1-1 chat or through channel messages. Below are some of the scenarios of an elevated level. The detailed screenshots with test results have been explained in User Experience of this document.","title":"Data Loss Prevention for Teams-DLP"},{"location":"playbooks/teamsdlp/#protecting-sensitive-information-in-messages","text":"If someone is trying to share a chat message that contains sensitive information to an external user or guest, based on the creation of DLP-Rule for the Teams workload, the message will be blocked within seconds. Both the sender and receiver see the message blocked notification.","title":"Protecting Sensitive Information in Messages:"},{"location":"playbooks/teamsdlp/#protecting-sensitive-information-in-documents-sharing","text":"If a user attempts to share a document that contains sensitive information with external users or guests in a Microsoft Teams channel or chat, the DLP rule prevents opening the document by the external user. In this case, the DLP policy must include SharePoint and OneDrive locations in order for protection to be in place. When new files are added to SharePoint or OneDrive in Microsoft 365, it may take a few moments for them to be crawled and indexed. It takes additional time for the Office Data Loss Prevention (DLP) policy to scan the content and apply rules to help protect sensitive information. If external sharing is turned on, sensitive content could be shared and accessed by guests before the Office DLP rule finishes processing. You can ensure that documents are protected until DLP scan completes and marks them as safe to share by using a PowerShell cmdlet to enable a feature called sensitive by default : Set-SPOTenant\u202f-MarkNewFilesSensitiveByDefault BlockExternalSharing Use the cmdlet BlockPerUserNotifyUserOutsideOrg Conditions Content contains any of these sensitive info types: [Select all that applies] Content is shared from Microsoft 365 with people outside my organization . Action Restrict access to the content for external users. Notify users with email and policy tips. Send incident reports to the Administrator. More Information For additional information on sensitive by default , refer here .","title":"Protecting Sensitive Information in Documents Sharing:"},{"location":"playbooks/teamsdlp/#protection-of-teams-and-sharepoint-sites","text":"Sensitivity labels can be used to protect data not only in documents and emails, but also in Teams and SharePoint sites. During creation Teams settings can be defined such as: Private (or public), external user access and access from unmanaged devices. When you apply a sensitivity label to a supported container, the label automatically applies the classification and configured protection settings to the site or group. Referring to using sensitivity labels in Teams, Groups or SharePoint sites . This helps protect your Teams and SharePoint sites holistically and not just individual files within those sites. There are various control options available in the M365 compliance center to enable various group settings and to restrict sharing of sensitive information via chat or by sharing the files. The sensitivity labels are then available to a user who is creating a new Team.","title":"Protection of Teams and SharePoint sites:"},{"location":"playbooks/teamsdlp/#teams-and-guest-access","text":"Guest is a user type in Microsoft Teams which is included with Office 365 licenses. With guest access, you can provide access to teams, documents within channels, resources, chats, and applications for people external to your organization. In a real-life scenario, guests may be a vendor, a supplier or an external partner who is working on a project but is not a member of your organization and has a business account (Azure AAD) or consumer email account (Outlook, Gmail, Hotmail, etc.). They can participate as guests in Teams and explore the channel experiences. External Access ( Federation ) is turned on by default in Teams, which means your organization can communicate with all external domains. The Teams admin can turn it off or specify which domains to include or exclude. Federation users do not have access to your organization\u2019s Teams or Teams\u2019 resources. They can only communicate via 1-1 chat . If a federation user needs access to Teams\u2019 channels and resources, they must be added as a guest in the organization. The setting up of guest and federation users has been explained in Requirements for Federation or Guest user scenarios . Let's start with the explanation below. Organizations (sender and receiver) which have O365 licenses and Teams enabled, can start 1-1 chats/meetings/voice calls. The external user (receiver) will not be added by default to AAD and will not get access to internal resources like files or folders. This external user will be considered a one-time user and which we call a Federation user . If the user needs additional privileges, administrators will provide access by converting them to a guest user. If a member has been added to a Teams channel, the user profile will be automatically added (forced to add) to Azure Active directory and will be treated almost as an internal user (refer figure below). This user is an external or guest user . Federation: Teams support 1:1 federation chat only . Teams do not currently support: Group Chats with one or more federation users Channel conversations with federation users Figure 6: Adding members to external chat To set-up guest access, please refer here . The detailed comparison of Team member and guest has been explained in this section . When a guest is invited to join a team, they receive a link to accept. The guest must accept the invitation before joining the team and the associated channels. Below is the admin experience of adding additional privileges. Login to Guest access - Microsoft Teams admin center . Figure 7: Admin experience at Microsoft admin center for controlling guest access. Figure 8: External access setting allows \u2013 Chat/voice calls/meetings for federation domains.","title":"Teams and Guest Access"},{"location":"playbooks/teamsdlp/#requirements-for-federation-or-guest-user-scenarios","text":"To test the scenarios a Teams-DLP policy is required along with a guest and federation user. Below steps help in setting up the DLP-Policy and adding new guest users.","title":"Requirements for Federation or Guest user scenarios"},{"location":"playbooks/teamsdlp/#step-1-create-teams-dlp-policy","text":"DLP policies help organizations prevent data loss. The process of creating a unified DLP policy with Teams as the workload is explained in the process below. Please refer to the User Experience section before the start of this process. Login to compliance.microsoft.com and click on Data Loss Prevention Click on the create policy. Figure 9: DLP policy creation By default Microsoft provides Industry standard regulatory templates to protect sensitive information. The templates have been divided into 4 categories \u2013 Financial , Medical and Health, Privacy and Custom . Each of the first 3 categories have pre-defined data protection templates based on the industry needs. There is also an option to filter based on country and region. If your organization needs a combination of these templates or a new need that is not available in the list, select Custom Category \u2013 Custom Template . This allows you to choose sensitive types that work for your organization\u2019s needs. Figure 10: Selecting a template Figure 11: DLP Policy name Next, the screen below allows administrators to select the accounts where the chosen sensitive information needs to be protected. It can be implemented across the entire organization, a particular project, or a particular entity of the organization. Also, there is an option to explicitly exclude some accounts from this protection based on the need. If you do not define any explicit inclusions or exclusions, the policy will apply to All Employee with No Exclusions by default. Figure 12: Policy applies to desired locations. Once the applicable project team and business entities to be protected are selected, we need to create a rule and action on the policy as shown on the screen below. Create a rule by adding conditions ( is this rule applicable to Within the Organization or Outside the Organization ) and under content contains, add the sensitive information types which were identified as part of the data classification needs of your organization. In the list of sensitive information types, one has the ability to select SIT\u2019s that were created using regular expressions, out of the box (OOB) provided, and matching keywords. Figure 13: Creation of DLP rules Add exceptions if any and then create actions. By default users are blocked from sending the Teams chats and channel messages that contain the SIT you are protecting. But you can choose who has access to files shared from SharePoint, OneDrive, and Teams Click Next, you can enable the policy right away or you can choose to test for a few days before enabling, as shown below. Figure 14: Test first and then deploy.","title":"Step 1: Create Teams-DLP policy"},{"location":"playbooks/teamsdlp/#step-2-add-a-guest-user","text":"Guest users can be added in two ways: From Azure Active Directory or from the Channel->Add member screen in Teams. New user - Azure Active Directory admin center example Figure 15: Adding a guest user through Azure Directory Figure 16: Sending Invite to guest user Figure 17: The user added to AAD Once added the new guest user receives a message as shown below: Figure 18: E-mail message to guests with a link to accept Upon acceptance the guest user then receives the following message: Figure 19: E-mail message after successful addition From this point the user is a member of AAD and has access to all tenant resources, just like an internal user. The admin can restrict access based on organizational needs.","title":"Step 2: Add a Guest User"},{"location":"playbooks/teamsdlp/#step-3-create-a-teams-channel","text":"In the above steps we have created a DLP policy and added an external user. It is important to consider protecting your Teams channel messages holistically and not just individual files within those sites. There are various control options available in the M365 compliance center to enable various group settings and to restrict sharing of sensitive information via chat or by sharing the files. The sensitivity labels are then available to a user who is creating a new team. At a Team channel or site level, three types of controls are possible: Who can join a Team? a. Privacy \u2013 Public vs Private b. Choose public for anyone in your organization to join the team, or private for only selective members can join the team. c. Control whether the Team owner can add guests to the team. Control access to Teams sites from unmanaged devices a. For unmanaged devices (those not hybrid AD joined or complaint on Intune), allow full access, web only access, or block access completely. Granular control for external sharing of files in Teams sites. a. Choose the level of external sharing : anonymous, secure external sharing, or block external access completely. Let us create a Teams channel and add a user to the channel: Figure 20: New Teams Channel creation Figure 21: Choosing Privacy setting Figure 22: Channel name and purpose Next add a new external user to the newly created channel. Please note that the first user was added through the AAD admin center and this user Gmail account is being added through Teams channel -> Add member. Figure 23: Adding guest users as a member to the newly created channel Please note that this newly added user will automatically be added to AAD, as displayed below: Figure 24: Checking the added user from the AAD admin center In the above steps, we have added 2 users. These 2 users are now added to AAD. @M365x708261.onmicrosoft.com @gmail.com","title":"Step 3: Create a Teams Channel"},{"location":"playbooks/teamsdlp/#step-4-add-external-guest-or-federation-user","text":"Next, let us attempt to add a new user, who is a federation and should not be part of AAD. Refer to here for more details. When trying to add the 3rd new user to the existing Teams channel, assume that the user has an O365 license in the tenant. When attempting to add the user directly from Teams, the application only allows the user to be added as a guest user @M365x708261.onmicrosoft.com . Since we do not want this user to be added to AAD we will keep them as federation users (or One-time chat user). Figure 25: Trying to add a Federation user to the channel. We now have 2 guest users, a federation user, a Teams-DLP rule, and a Teams channel. We are ready to test the scenarios.","title":"Step 4: Add External (Guest) or Federation User"},{"location":"playbooks/teamsdlp/#user-experience","text":"","title":"User Experience"},{"location":"playbooks/teamsdlp/#scenario-1-sharing-credit-card-details-to-a-federation-user-via-1-1-chat","text":"Sender\u2019s Screen: The Sender is attempting to send credit card information to the newly created federation user via 1-1 chat: Figure 26: Credit card information in Team chat The message is blocked as the DLP rule is activated and the sender is notified: Figure 27: Blocked credit card message Receiver Screen: The receiver gets a blank blocked message, as shown below. Please note that there will be a delay of a few seconds in blocking the message and which is normal behavior (passive DLP). Figure 28: Blank blocked message","title":"Scenario 1: Sharing Credit card details to a Federation user via 1-1 chat."},{"location":"playbooks/teamsdlp/#scenario-2-sharing-a-file-from-sharepoint-onedrive-to-federation-user","text":"Senders Screen: The Sender is trying to attach a file which has credit card information via 1-1 chat: Figure 29: Option to upload files missing Notice there is no option to upload a file to the federation user since they are not in AAD. Receivers Screen: In this scenario the receiver will not get a message. Scenario 3: Sharing Credit card details with a Federation user via 1-1 chat. If the federation user (Sender) has shared a SIT via 1-1 chat, the DLP rule acted will be based on the federation user organization policies. In the above scenario, if a credit card is not a SIT in the federation user's organization, the message will come as-is to the receiver. The receiver will not have any control over the federation users' DLP policies.","title":"Scenario 2: Sharing a file from SharePoint /OneDrive to Federation user."},{"location":"playbooks/teamsdlp/#scenario-4-sharing-credit-card-details-to-guest-user-via-1-1-chat","text":"The Sender and Receiver can chat, just like an internal user since the guest is a member of AAD. The Sender then attempts to share sensitive information via chat: Senders Screen: Figure 30: Guest user Teams chat The DLP rule is activated and the message is blocked: Figure 31: DLP blocked message Receivers Screen: The Receiver receives the blocked message, as shown below: Figure 32: Blocked message to receiver","title":"Scenario 4: Sharing Credit card details to Guest user via 1-1 chat."},{"location":"playbooks/teamsdlp/#scenario-5-sharing-a-file-via-1-1-chat-with-guest-user","text":"Senders Screen: The Sender is trying to attach a file, which has credit card information, via 1-1 chat to the guest user: Figure 33: Attaching a file in chat with credit card information Figure 34: Attaching a file in chat with credit card information < Figure 35: Attaching a file in chat with credit card information < Receivers Screen: This message was received by the receiver: Figure 36: UI message to receiver The receiver while attempting to open the attachment: Figure 37: Error message when opening file And upon clicking Request Access : Figure 38: Access Denied message","title":"Scenario 5: Sharing a file via 1-1 chat with Guest User."},{"location":"playbooks/teamsdlp/#scenario-6-sharing-credit-card-details-to-guest-users-via-teams-channel-chat","text":"Senders Screen: The Sender attempts to share a credit card number via the channel chat: Figure 39: Attaching a file in channel with credit card information Figure 40: Attaching a file in channel with credit card information Receivers Screen: The message was blocked. Figure 41: Message blocked in Teams channel","title":"Scenario 6: Sharing Credit card details to Guest users via Teams channel chat."},{"location":"playbooks/teamsdlp/#scenario-7-sharing-a-file-to-a-guest-user-on-teams-channel","text":"Senders Screen: The Sender attempts to share a file that has credit card number details over the chat in the channel: Figure 42: Attaching a file in channel with credit card information Receivers Screen: The Receiver gets the message and, upon opening the file, receives an access denied message. Figure 43: Error messages when opening Figure 44: Error messages when opening Figure 45: Error messages when opening","title":"Scenario 7: Sharing a file to a Guest User on Teams channel"},{"location":"playbooks/teamsdlp/#reports","text":"After creating the DLP policies or rules on the desired workload (i.e., Teams Chat or Channel), you can track the actions using the reports in the Microsoft 365 Compliance Center. Compliance.microsoft.com -> Reports -> Organization Data > Select Teams . Or https://compliance.microsoft.com/reports/dlppolicymatchesreport This report shows the count of DLP policy matches over time. You can filter the report by date, location, policy, or action. This report can help discover the business processes that may violate the organization\u2019s DLP policies and understand the impact created by the action that is applied on the content. It also helps identify the list of top users and repeat users who are contributing to incidents within your organization. Highlighted in red boxes indicates key filters or features in the reports. Figure 46: DLP-Reports Figure 47: DLP-Incidents Figure 48: DLP-Summary To view the reports in the Microsoft 365 Compliance Center, the user needs to be a member of the Security Reader role group. By default, this role group is assigned to the Compliance Administrator.","title":"Reports"},{"location":"playbooks/teamsdlp/#implementation-strategy","text":"See Microsoft 365 productivity illustrations for guidance on implementation of all M365 capabilities with a focus on cross technologies. Based on experience, a solid Implementation strategy follows these three phases Crawl -The first stage is about starting to evaluate where your organization is today regarding security and compliance with your goal of defining a strategic direction for your company. Use this strategy to foster adoption of a solution by gathering the requirements of supporting systems, impact on end users, and skillset needed for each role owner. The crawl phase describes steps you should do at the beginning of any deployment, whether your requirements are basic or advanced. It includes steps for education, defining requirements, and evaluation or testing. This phase is primarily to identify data classification needs like, Identifying the key critical Sensitive Information Types (SIT) Walk -The second stage builds the foundation for a successful, scale, and sustainable deployment. In this phase, you plan the details of your implementation and to build the solution. You may also run a pilot or proof of concept with a select group of users or locations. This phase deals with protecting the identified, SIT\u2019s. This can be done either by labelling the documents or by applying rules across workloads. Test these policies on certain users/groups before deploying directly into production. Run -The last stage is about optimizing the solution for Microsoft 365. In this phase you will set up an automated scalable approach for each solution. Keep monitoring the results and fine tune the rules. Validate the results through alerts/reports and take measures. For more details on deployment strategy, visit the MIP DAG Figure 49: Phases of Implementation","title":"Implementation Strategy"},{"location":"playbooks/teamsdlp/#faq","text":"Are there any guidance documents for implementing MIP in various industries, i.e., education, healthcare and finance have quite unique needs? Here is some industry guidance for security and compliance: Industry guidance for S+C Do DLP policies apply to data that are sent from teams to apps that are added to a channel? No, this scenario is not supported today but is on our roadmap. No ETA at this time. Is it on the roadmap that Sensitivity Labels also gets supported in Teams-DLP? Yes, it is on our roadmap. I have external contact and I (accidentally or intentionally) share an SSN in teams, if the team\u2019s policy is in place to restrict SSN to external parties, is this saying that the msg containing the SSN will not go through? Yes, that is correct. The DLP rule will activate and protect data sharing. Is an integration between MIP and Teams planned so that each document that is exchanged through a channel inherits a Sensitivity Label (visual marking and / or protection? There is a roadmap item to have documents inherited from MIP container labels. There is no ETA at this time. If you upload a document to a Teams chat, does DLP scan the document. Use the sensitive by default setting to protect the document until it is scanned to determine if it contains sensitive info. It will be scanned within a few seconds and blocked if necessary. Does Teams respect apps that have been approved/blocked in MCAS? No, not today. We can look into supporting it in the future. I understand that we are eventually \"deprecating\" Streams and recordings will be stored in SPO/OD4B. How can we best utilize DLP for Teams in this scenario? No plan today but this is in our roadmap. There is always a delay of a few seconds before the message gets blocked. Are there any performance improvements planned to handle this? We are looking into building a better pipeline, but this is a major undertaking. It is on our roadmap with no clear timelines. How can we block uploaded and downloaded documents on native Teams clients? You can control document storage for Teams through SharePoint DLP, which acts as the backend for Teams document management.","title":"FAQ"},{"location":"playbooks/teamsdlp/#abbreviations","text":"Name Description MIP Microsoft Information Protection DLP Data Loss Prevention SCC Security and Compliance Center (Portal to create policies) RBAC Role Based Access Control SIT Sensitive Information Type SPO Share Point Online EXO Exchange Online ODB One Drive for Business OOB Out of the box AAD Azure Active Directory","title":"Abbreviations"},{"location":"powershell/aed/","text":"","title":"Aed"},{"location":"powershell/audit/","text":"","title":"Audit"},{"location":"powershell/cc/","text":"","title":"Cc"},{"location":"powershell/cm/","text":"","title":"Cm"},{"location":"powershell/dlp/","text":"","title":"Dlp"},{"location":"powershell/ir/","text":"","title":"Ir"},{"location":"powershell/mig/","text":"","title":"Mig"},{"location":"powershell/mip/","text":"","title":"Mip"},{"location":"powershell/rm/","text":"","title":"Rm"},{"location":"previews/adpscp/","text":"Now GA in both Information Governance and Records Management solutions The long awaited feature is here. What is the feature? \u2693\ufe0e Today, we are announcing the general availability for adaptive policy scopes. This new functionality allows admins to create attribute-based retention or label policies that can be scoped to geography, department, or other user, group, or site attributes. Improvements and key benefits \u2693\ufe0e Ability to create different types of adaptive scopes \u2013 Create adaptive scopes for users, sites and groups based on attributes. For example, a user scope can be created based on attributes like Department, Country, Title and many more while site scopes can be created using site names, site URLs or SharePoint property bags. Ability to apply more than one type of adaptive scope to a retention or a label policy \u2013 Can apply more than one type of scope/s (user/site/group) to a retention policy or a label policy. Policy lookup \u2013 Can now look up a specific user, site or a group to see the list of all the policies that are applied. Policy reporting \u2013 Can view a report of who is covered by a policy (user/site/group), history of coverage and/or removal. Scope reporting \u2013 Similar to policy reporting, can also view a report of all the changes that happen to user, site and group scopes. GEAR on behalf of the MIG product group","title":"Adpscp"},{"location":"previews/adpscp/#what-is-the-feature","text":"Today, we are announcing the general availability for adaptive policy scopes. This new functionality allows admins to create attribute-based retention or label policies that can be scoped to geography, department, or other user, group, or site attributes.","title":"What is the feature?"},{"location":"previews/adpscp/#improvements-and-key-benefits","text":"Ability to create different types of adaptive scopes \u2013 Create adaptive scopes for users, sites and groups based on attributes. For example, a user scope can be created based on attributes like Department, Country, Title and many more while site scopes can be created using site names, site URLs or SharePoint property bags. Ability to apply more than one type of adaptive scope to a retention or a label policy \u2013 Can apply more than one type of scope/s (user/site/group) to a retention policy or a label policy. Policy lookup \u2013 Can now look up a specific user, site or a group to see the list of all the policies that are applied. Policy reporting \u2013 Can view a report of who is covered by a policy (user/site/group), history of coverage and/or removal. Scope reporting \u2013 Similar to policy reporting, can also view a report of all the changes that happen to user, site and group scopes. GEAR on behalf of the MIG product group","title":"Improvements and key benefits"},{"location":"resources/aed/","text":"Microsoft Purview eDiscovery Resources \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Technical Sessions Playbooks and Guides \u2693\ufe0e Become a Microsoft Purview eDiscovery Ninja Webinars \u2693\ufe0e Microsoft Purview eDiscovery Webinars","title":"eDiscovery"},{"location":"resources/aed/#microsoft-purview-ediscovery-resources","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview eDiscovery Resources"},{"location":"resources/aed/#videos","text":"Technical Sessions","title":"Videos"},{"location":"resources/aed/#playbooks-and-guides","text":"Become a Microsoft Purview eDiscovery Ninja","title":"Playbooks and Guides"},{"location":"resources/aed/#webinars","text":"Microsoft Purview eDiscovery Webinars","title":"Webinars"},{"location":"resources/audit/","text":"Microsoft Purview Audit Resources \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Technical Sessions Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Webinars \u2693\ufe0e Microsoft Purview Audit Webinars Blogs \u2693\ufe0e Harnessing Advanced Audit to power your forensic investigations in 5 steps Privacy breaches: Using Microsoft 365 Advanced Audit and Advanced eDiscovery to minimize impact Using Advanced Audit to improve your forensic investigation capability","title":"Audit"},{"location":"resources/audit/#microsoft-purview-audit-resources","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Audit Resources"},{"location":"resources/audit/#videos","text":"Technical Sessions","title":"Videos"},{"location":"resources/audit/#playbooks-and-guides","text":"Deployment Acceleration Guide","title":"Playbooks and Guides"},{"location":"resources/audit/#webinars","text":"Microsoft Purview Audit Webinars","title":"Webinars"},{"location":"resources/audit/#blogs","text":"Harnessing Advanced Audit to power your forensic investigations in 5 steps Privacy breaches: Using Microsoft 365 Advanced Audit and Advanced eDiscovery to minimize impact Using Advanced Audit to improve your forensic investigation capability","title":"Blogs"},{"location":"resources/cc/","text":"Microsoft Purview Communication Compliance Resources \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Monitor inappropriate communication through Microsoft 365 Detect Workplace Harassment & Respond - Communication Compliance in Microsoft 365 Foster a culture of safety and inclusion with Communication Compliance\u200b Fulfill regulatory compliance requirements with Communication Compliance\u200b Better with Microsoft Teams. Learn more about our latest native Teams integrated features! Learn how to reduce communication risks within your organization Roadmap \u2693\ufe0e Communication Compliance Playbooks, Guides and Blogs \u2693\ufe0e Deployment Acceleration Guide Communication Compliance Interactive Guide Communication compliance in Microsoft 365 Reducing Code of Conduct and Regulatory Compliance Violation Risks - Latest Updates and announcements Implement policies for Insider Risk Management and Communication Compliance Communication Compliance Feature updates Ignite 2021 Announcements Mitigate the Impact of Communication Risks by Accelerating Review Time Cybersecurity\u2019s next fight: How to protect employees from online harassment Customer Stories \u2693\ufe0e TD Securities addresses regulatory obligations using Communication Compliance Webinars \u2693\ufe0e Reducing Code of Conduct and Regulatory Compliance Violation Risks - Video / Deck / FAQ Insider Risk Management and Communication Compliance (IRCC) Webinars Upcoming - What\u2019s new with Insider Risk and Communication Compliance | US/EMEA | November 22, 2021 16:00 GMT / 8:00 PST | Register Podcast \u2693\ufe0e Uncovering Hidden Risks Learning Path \u2693\ufe0e Communication Compliance learning path Ninja Training \u2693\ufe0e Microsoft Purview Communication Compliance Ninja Training","title":"Communication Compliance"},{"location":"resources/cc/#microsoft-purview-communication-compliance-resources","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Communication Compliance Resources"},{"location":"resources/cc/#videos","text":"Monitor inappropriate communication through Microsoft 365 Detect Workplace Harassment & Respond - Communication Compliance in Microsoft 365 Foster a culture of safety and inclusion with Communication Compliance\u200b Fulfill regulatory compliance requirements with Communication Compliance\u200b Better with Microsoft Teams. Learn more about our latest native Teams integrated features! Learn how to reduce communication risks within your organization","title":"Videos"},{"location":"resources/cc/#roadmap","text":"Communication Compliance","title":"Roadmap"},{"location":"resources/cc/#playbooks-guides-and-blogs","text":"Deployment Acceleration Guide Communication Compliance Interactive Guide Communication compliance in Microsoft 365 Reducing Code of Conduct and Regulatory Compliance Violation Risks - Latest Updates and announcements Implement policies for Insider Risk Management and Communication Compliance Communication Compliance Feature updates Ignite 2021 Announcements Mitigate the Impact of Communication Risks by Accelerating Review Time Cybersecurity\u2019s next fight: How to protect employees from online harassment","title":"Playbooks, Guides and Blogs"},{"location":"resources/cc/#customer-stories","text":"TD Securities addresses regulatory obligations using Communication Compliance","title":"Customer Stories"},{"location":"resources/cc/#webinars","text":"Reducing Code of Conduct and Regulatory Compliance Violation Risks - Video / Deck / FAQ Insider Risk Management and Communication Compliance (IRCC) Webinars Upcoming - What\u2019s new with Insider Risk and Communication Compliance | US/EMEA | November 22, 2021 16:00 GMT / 8:00 PST | Register","title":"Webinars"},{"location":"resources/cc/#podcast","text":"Uncovering Hidden Risks","title":"Podcast"},{"location":"resources/cc/#learning-path","text":"Communication Compliance learning path","title":"Learning Path"},{"location":"resources/cc/#ninja-training","text":"Microsoft Purview Communication Compliance Ninja Training","title":"Ninja Training"},{"location":"resources/cm/","text":"Microsoft Purview Compliance Manager \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Survey \u2693\ufe0e As a valued customer and partner with Microsoft we value your input and opinions. We here at Microsoft are constantly striving to provide our customers and partners with the very best in technology that meets or exceeds their needs. To this end we are asking that you take a brief survey (10minutes), located here . Ninja Training \u2693\ufe0e Microsoft Purview Compliance Manager Ninja Training Videos \u2693\ufe0e Introduction to Compliance Manager Simplify Compliance and Reduce Risk with our 150+ Assessment templates or bring your own assessment Create assessments and monitor your progress with Compliance Manager - Microsoft Tech Community Extend and customize assessments to suit your needs in Compliance Manager Episode #3 - Scenario Based Demos - Compliance Manager Playbooks and Guides \u2693\ufe0e Compliance Manager Interactive Guide Deployment Acceleration Guide Microsoft Purview Compliance Manager Ignite 2021 Announcements Webinars \u2693\ufe0e Microsoft Purview Compliance Manager Webinars Learning Path \u2693\ufe0e Reduce risk with Microsoft Purview Compliance Manager","title":"Compliance Manager"},{"location":"resources/cm/#microsoft-purview-compliance-manager","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Compliance Manager"},{"location":"resources/cm/#survey","text":"As a valued customer and partner with Microsoft we value your input and opinions. We here at Microsoft are constantly striving to provide our customers and partners with the very best in technology that meets or exceeds their needs. To this end we are asking that you take a brief survey (10minutes), located here .","title":"Survey"},{"location":"resources/cm/#ninja-training","text":"Microsoft Purview Compliance Manager Ninja Training","title":"Ninja Training"},{"location":"resources/cm/#videos","text":"Introduction to Compliance Manager Simplify Compliance and Reduce Risk with our 150+ Assessment templates or bring your own assessment Create assessments and monitor your progress with Compliance Manager - Microsoft Tech Community Extend and customize assessments to suit your needs in Compliance Manager Episode #3 - Scenario Based Demos - Compliance Manager","title":"Videos"},{"location":"resources/cm/#playbooks-and-guides","text":"Compliance Manager Interactive Guide Deployment Acceleration Guide Microsoft Purview Compliance Manager Ignite 2021 Announcements","title":"Playbooks and Guides"},{"location":"resources/cm/#webinars","text":"Microsoft Purview Compliance Manager Webinars","title":"Webinars"},{"location":"resources/cm/#learning-path","text":"Reduce risk with Microsoft Purview Compliance Manager","title":"Learning Path"},{"location":"resources/dlp/","text":"Microsoft Purview Data Loss Prevention \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Vblog - Learn how to apply DLP policy to non-Microsoft cloud apps How to configure a DLP policy Microsoft Teams DLP - Know Your Data Microsoft Teams DLP - Create a Teams DLP Policy Microsoft Teams DLP - End User Experience Microsoft Teams DLP - Reporting \ud83c\udd95 How to extend auto label policy to DLP Playbooks and Guides \u2693\ufe0e Deployment Acceleration Guide Endpoint DLP interactive guide Teams DLP interactive guide Migrating from Exchange ETR to DLP playbook Teams DLP Playbook Join Endpoint DLP preview ring Webinars \u2693\ufe0e Data Loss Prevention (DLP) Webinars","title":"Data Loss Prevention"},{"location":"resources/dlp/#microsoft-purview-data-loss-prevention","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Data Loss Prevention"},{"location":"resources/dlp/#videos","text":"Vblog - Learn how to apply DLP policy to non-Microsoft cloud apps How to configure a DLP policy Microsoft Teams DLP - Know Your Data Microsoft Teams DLP - Create a Teams DLP Policy Microsoft Teams DLP - End User Experience Microsoft Teams DLP - Reporting \ud83c\udd95 How to extend auto label policy to DLP","title":"Videos"},{"location":"resources/dlp/#playbooks-and-guides","text":"Deployment Acceleration Guide Endpoint DLP interactive guide Teams DLP interactive guide Migrating from Exchange ETR to DLP playbook Teams DLP Playbook Join Endpoint DLP preview ring","title":"Playbooks and Guides"},{"location":"resources/dlp/#webinars","text":"Data Loss Prevention (DLP) Webinars","title":"Webinars"},{"location":"resources/ir/","text":"Microsoft Purview Insider Risk Management \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Insider Risk Management - Microsoft Mechanics Insider Risk Management Overview Insider Risk Management Analytics Insider Risk Management Policy Configuration Insider Risk Management Alerts Triage Experience Insider Risk Management Investigation and Escalation Insider Risk Management Configure HR Data Connector Microsoft 365 Insider Risk Management and St. Luke's University Health Network Playbooks, Guides and Blogs \u2693\ufe0e Deployment Acceleration Guide Insider Risk interactive guide Implement policies for Insider Risk Management and Communication Compliance Insider Risk Blog Ignite 2021 Announcements Microsoft 365 Insider Risk Management Sentinel Connector Podcast \u2693\ufe0e Uncovering Hidden Risks Webinars \u2693\ufe0e Insider Risk Management and Communication Compliance Webinars Learning Path \u2693\ufe0e Insider Risk Management learning path Ninja Training \u2693\ufe0e Microsoft Purview Insider Risk Management Ninja Training","title":"Insider Risk Management"},{"location":"resources/ir/#microsoft-purview-insider-risk-management","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Insider Risk Management"},{"location":"resources/ir/#videos","text":"Insider Risk Management - Microsoft Mechanics Insider Risk Management Overview Insider Risk Management Analytics Insider Risk Management Policy Configuration Insider Risk Management Alerts Triage Experience Insider Risk Management Investigation and Escalation Insider Risk Management Configure HR Data Connector Microsoft 365 Insider Risk Management and St. Luke's University Health Network","title":"Videos"},{"location":"resources/ir/#playbooks-guides-and-blogs","text":"Deployment Acceleration Guide Insider Risk interactive guide Implement policies for Insider Risk Management and Communication Compliance Insider Risk Blog Ignite 2021 Announcements Microsoft 365 Insider Risk Management Sentinel Connector","title":"Playbooks, Guides and Blogs"},{"location":"resources/ir/#podcast","text":"Uncovering Hidden Risks","title":"Podcast"},{"location":"resources/ir/#webinars","text":"Insider Risk Management and Communication Compliance Webinars","title":"Webinars"},{"location":"resources/ir/#learning-path","text":"Insider Risk Management learning path","title":"Learning Path"},{"location":"resources/ir/#ninja-training","text":"Microsoft Purview Insider Risk Management Ninja Training","title":"Ninja Training"},{"location":"resources/mig/","text":"Microsoft Purview Data Lifecycle Management and Records Management \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e How to Auto-apply Retention Labels using Compliance Center JumpStarts and Guides \u2693\ufe0e Deployment Acceleration Guide End User Training for Retention labels Adaptive Scopes Exchange Workload JumpStart Webinars \u2693\ufe0e Microsoft Purview Data Lifecycle Management and Records Management Webinars Blogs \u2693\ufe0e Using Adaptive Policy Scopes to Apply M365 Retention to Shared, Resource, and Inactive Mailboxes Using Custom SharePoint Site Properties to Apply Microsoft 365 Retention with Adaptive Policy Scopes Downloads \u2693\ufe0e Microsoft Purview Data Lifecycle Management and Records Management permissions by feature/persona/role","title":"Data Lifecycle Management/Records Management"},{"location":"resources/mig/#microsoft-purview-data-lifecycle-management-and-records-management","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Data Lifecycle Management and Records Management"},{"location":"resources/mig/#videos","text":"How to Auto-apply Retention Labels using Compliance Center","title":"Videos"},{"location":"resources/mig/#jumpstarts-and-guides","text":"Deployment Acceleration Guide End User Training for Retention labels Adaptive Scopes Exchange Workload JumpStart","title":"JumpStarts and Guides"},{"location":"resources/mig/#webinars","text":"Microsoft Purview Data Lifecycle Management and Records Management Webinars","title":"Webinars"},{"location":"resources/mig/#blogs","text":"Using Adaptive Policy Scopes to Apply M365 Retention to Shared, Resource, and Inactive Mailboxes Using Custom SharePoint Site Properties to Apply Microsoft 365 Retention with Adaptive Policy Scopes","title":"Blogs"},{"location":"resources/mig/#downloads","text":"Microsoft Purview Data Lifecycle Management and Records Management permissions by feature/persona/role","title":"Downloads"},{"location":"resources/mip/","text":"Microsoft Purview Information Protection \u2693\ufe0e We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis. Videos \u2693\ufe0e Vblog series: setting up a secure collaboration environment Vblog series \u2013 end user point of view Vblog series - Admin point of view Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking Data protection in Power BI Playbooks and Guides \u2693\ufe0e \ud83c\udd95 Microsoft Purview Information Protection Ninja Training Deployment Acceleration Guide Data Classification White Paper End User Training for Sensitivity labels How to re-label documents classified with a deprecated sensitivity label \ud83c\udd95 IP Interactive Guide Webinars \u2693\ufe0e Microsoft Purview Information Protection Webinars","title":"Information Protection"},{"location":"resources/mip/#microsoft-purview-information-protection","text":"We built this page to help you easily find all relevant content and resources relating to the Microsoft Purview solutions. Please bookmark this page for future reference as we will update it on an ongoing basis.","title":"Microsoft Purview Information Protection"},{"location":"resources/mip/#videos","text":"Vblog series: setting up a secure collaboration environment Vblog series \u2013 end user point of view Vblog series - Admin point of view Using Sensitivity Labels in M365 \u2013 How to Protect NDA Data from Leaking Data protection in Power BI","title":"Videos"},{"location":"resources/mip/#playbooks-and-guides","text":"\ud83c\udd95 Microsoft Purview Information Protection Ninja Training Deployment Acceleration Guide Data Classification White Paper End User Training for Sensitivity labels How to re-label documents classified with a deprecated sensitivity label \ud83c\udd95 IP Interactive Guide","title":"Playbooks and Guides"},{"location":"resources/mip/#webinars","text":"Microsoft Purview Information Protection Webinars","title":"Webinars"},{"location":"sbd/SBDinPDF/","text":"SBD Summary Manual \u2693\ufe0e What is it? \u2693\ufe0e One of our field person created a great summary manual associated with the SDB, which is helpful because in case anyone needs to search for a specific content in SBD. Download the pdf \u2693\ufe0e Summary manual associated with the SDB","title":"\ud83c\udd95 SBD in PDF  - Summary of SBD in pdf"},{"location":"sbd/SBDinPDF/#sbd-summary-manual","text":"","title":"SBD Summary Manual"},{"location":"sbd/SBDinPDF/#what-is-it","text":"One of our field person created a great summary manual associated with the SDB, which is helpful because in case anyone needs to search for a specific content in SBD.","title":"What is it?"},{"location":"sbd/SBDinPDF/#download-the-pdf","text":"Summary manual associated with the SDB","title":"Download the pdf"},{"location":"sbd/sbd-ep1/","text":"Episode 1 - Series Introduction \u2693\ufe0e In This Episode \u2693\ufe0e In the episode, we will introduce the Scenario Based Demos (SBD) series, talk about Data Classification and Data Governance, and a few other things. Video \u2693\ufe0e","title":"E01 - Series Intro"},{"location":"sbd/sbd-ep1/#episode-1-series-introduction","text":"","title":"Episode 1 - Series Introduction"},{"location":"sbd/sbd-ep1/#in-this-episode","text":"In the episode, we will introduce the Scenario Based Demos (SBD) series, talk about Data Classification and Data Governance, and a few other things.","title":"In This Episode"},{"location":"sbd/sbd-ep1/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep10/","text":"Episode 10 - Microsoft Endpoint Management (Intune) with MIP \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will change direction a bit and talk about Microsoft Endpoint Management (MEM). specifically, when it is integrating with Microsoft Information Protection (MIP). We will also introduce MEM, and we will talk about device compliance, conditional access and device enrollment. We will walk you through how to prepare your tenant for MEM, and more. Note This is part one of two, so stay tuned for part two soon. Video \u2693\ufe0e","title":"E10 - MEM/Intune and MIP"},{"location":"sbd/sbd-ep10/#episode-10-microsoft-endpoint-management-intune-with-mip","text":"","title":"Episode 10 - Microsoft Endpoint Management (Intune) with MIP"},{"location":"sbd/sbd-ep10/#in-this-episode","text":"In this episode, we will change direction a bit and talk about Microsoft Endpoint Management (MEM). specifically, when it is integrating with Microsoft Information Protection (MIP). We will also introduce MEM, and we will talk about device compliance, conditional access and device enrollment. We will walk you through how to prepare your tenant for MEM, and more. Note This is part one of two, so stay tuned for part two soon.","title":"In This Episode"},{"location":"sbd/sbd-ep10/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep11/","text":"Episode 10 - Microsoft Endpoint Management (Intune) with MIP - Part 2 \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will continue going through the Microsoft Endpoint Management (MEM) topic. specifically, when it is integrating with Microsoft Information Protection (MIP). Here, We will talk about auto-enrollment for Windows devices, iOS device enrollment, as well as device compliance policies. As usual, we will walk you through all the required prerequisites, configuration steps and testing. Video \u2693\ufe0e","title":"E11 - MEM/Intune and MIP Part 2"},{"location":"sbd/sbd-ep11/#episode-10-microsoft-endpoint-management-intune-with-mip-part-2","text":"","title":"Episode 10 - Microsoft Endpoint Management (Intune) with MIP - Part 2"},{"location":"sbd/sbd-ep11/#in-this-episode","text":"In this episode, we will continue going through the Microsoft Endpoint Management (MEM) topic. specifically, when it is integrating with Microsoft Information Protection (MIP). Here, We will talk about auto-enrollment for Windows devices, iOS device enrollment, as well as device compliance policies. As usual, we will walk you through all the required prerequisites, configuration steps and testing.","title":"In This Episode"},{"location":"sbd/sbd-ep11/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep2/","text":"Episode 2 - Data Discovery Concept \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will continue on the Information classification and governance introduction topic. We will also go through the Data Discovery and Risk Analysis concept and example. Followed by the classification taxonomy for the tenant and the data retention plan. Video \u2693\ufe0e","title":"E02 - Data Discovery Concept"},{"location":"sbd/sbd-ep2/#episode-2-data-discovery-concept","text":"","title":"Episode 2 - Data Discovery Concept"},{"location":"sbd/sbd-ep2/#in-this-episode","text":"In this episode, we will continue on the Information classification and governance introduction topic. We will also go through the Data Discovery and Risk Analysis concept and example. Followed by the classification taxonomy for the tenant and the data retention plan.","title":"In This Episode"},{"location":"sbd/sbd-ep2/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep3/","text":"Episode 3 - Security vs Compliance \u2693\ufe0e In This Episode \u2693\ufe0e In this SBD episode, we will go through the main differences between the Security Practice and Compliance policies, what are they, and how they work together. We will also go through the main challenges that come with Compliance management, and how Microsoft Compliance Manager can help address those challenges. Finally, we will go through a technical demo on Microsoft 365 Compliance Manager, and how we start setting it up to meet our SBD requirements. Video \u2693\ufe0e","title":"E03 - Security vs Compliance"},{"location":"sbd/sbd-ep3/#episode-3-security-vs-compliance","text":"","title":"Episode 3 - Security vs Compliance"},{"location":"sbd/sbd-ep3/#in-this-episode","text":"In this SBD episode, we will go through the main differences between the Security Practice and Compliance policies, what are they, and how they work together. We will also go through the main challenges that come with Compliance management, and how Microsoft Compliance Manager can help address those challenges. Finally, we will go through a technical demo on Microsoft 365 Compliance Manager, and how we start setting it up to meet our SBD requirements.","title":"In This Episode"},{"location":"sbd/sbd-ep3/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep4/","text":"Episode 4 - AIP Scanner \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will walk you through the Azure Information Protection (AIP) Scanner architecture, recommendation, installation and configuration. We will also go through the AIP logs in the Log Analytics workspace. This AIP Scanner End-to-End demo will help you understanding the requirements, prerequisites and the expected results, when you are carrying out the data discovery tasks within your on-premises repositories. Video \u2693\ufe0e","title":"E04 - AIP Scanner"},{"location":"sbd/sbd-ep4/#episode-4-aip-scanner","text":"","title":"Episode 4 - AIP Scanner"},{"location":"sbd/sbd-ep4/#in-this-episode","text":"In this episode, we will walk you through the Azure Information Protection (AIP) Scanner architecture, recommendation, installation and configuration. We will also go through the AIP logs in the Log Analytics workspace. This AIP Scanner End-to-End demo will help you understanding the requirements, prerequisites and the expected results, when you are carrying out the data discovery tasks within your on-premises repositories.","title":"In This Episode"},{"location":"sbd/sbd-ep4/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep5/","text":"Episode 5 - Sensitivity Labels \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will start with the Microsoft Information Protection (MIP) Sensitivity Labels for content classification and protection. We will go through our SBD classification taxonomy recap and configuration. This is the first part of two on this topic. We will learn the difference between a parent and sub labels, how to use and configure each of them. Also how to configure different protection methods on labels. Video \u2693\ufe0e","title":"E05 - Sensitivity Labels"},{"location":"sbd/sbd-ep5/#episode-5-sensitivity-labels","text":"","title":"Episode 5 - Sensitivity Labels"},{"location":"sbd/sbd-ep5/#in-this-episode","text":"In this episode, we will start with the Microsoft Information Protection (MIP) Sensitivity Labels for content classification and protection. We will go through our SBD classification taxonomy recap and configuration. This is the first part of two on this topic. We will learn the difference between a parent and sub labels, how to use and configure each of them. Also how to configure different protection methods on labels.","title":"In This Episode"},{"location":"sbd/sbd-ep5/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep6/","text":"Episode 6 - Label Behaviors & Testing \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will continue with the Microsoft Information Protection (MIP) Sensitivity Labels for content classification and protection. We will go over a short flashback of part 1 episode and continue testing the behavior of various classifications and clients, as well as M365 Activity Explorer walk-through. This is the second part of two on this topic. Video \u2693\ufe0e","title":"E06 - Label Behaviors"},{"location":"sbd/sbd-ep6/#episode-6-label-behaviors-testing","text":"","title":"Episode 6 - Label Behaviors &amp; Testing"},{"location":"sbd/sbd-ep6/#in-this-episode","text":"In this episode, we will continue with the Microsoft Information Protection (MIP) Sensitivity Labels for content classification and protection. We will go over a short flashback of part 1 episode and continue testing the behavior of various classifications and clients, as well as M365 Activity Explorer walk-through. This is the second part of two on this topic.","title":"In This Episode"},{"location":"sbd/sbd-ep6/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep7/","text":"Episode 7 - Container Labels \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will start with the Microsoft Information Protection (MIP) Sensitivity Labels for containers classification and protection. We will go through our SBD classification taxonomy for container recap and configuration. Moreover, we will go over the main differences between content labels (as discussed in the last two episodes) and container labels, and how to use and configure (step-by-step) container labels. Also how to configure different protection methods and privacy settings on those container labels. Video \u2693\ufe0e","title":"E07 - Container Labels"},{"location":"sbd/sbd-ep7/#episode-7-container-labels","text":"","title":"Episode 7 - Container Labels"},{"location":"sbd/sbd-ep7/#in-this-episode","text":"In this episode, we will start with the Microsoft Information Protection (MIP) Sensitivity Labels for containers classification and protection. We will go through our SBD classification taxonomy for container recap and configuration. Moreover, we will go over the main differences between content labels (as discussed in the last two episodes) and container labels, and how to use and configure (step-by-step) container labels. Also how to configure different protection methods and privacy settings on those container labels.","title":"In This Episode"},{"location":"sbd/sbd-ep7/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep8/","text":"Episode 8 - SITs and Client-side Autolabeling \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will go through Microsoft Information Protection (MIP) Custom Sensitive Information Types (SITs) and the Client-side Auto Label features. We will first go over Custom SITs overview, then we will show you how you should approach the custom SIT design and logic the will address your needs. Moreover, learn how to effectively use the client-side auto label capability (not to be confused with the service-side Auto label), not only with your users, but also with your Azure Information Protection (AIP) Scanner infrastructure to protect your files hosted on your on-premise. Video \u2693\ufe0e","title":"E08 - Client-side Autolabel"},{"location":"sbd/sbd-ep8/#episode-8-sits-and-client-side-autolabeling","text":"","title":"Episode 8 - SITs and Client-side Autolabeling"},{"location":"sbd/sbd-ep8/#in-this-episode","text":"In this episode, we will go through Microsoft Information Protection (MIP) Custom Sensitive Information Types (SITs) and the Client-side Auto Label features. We will first go over Custom SITs overview, then we will show you how you should approach the custom SIT design and logic the will address your needs. Moreover, learn how to effectively use the client-side auto label capability (not to be confused with the service-side Auto label), not only with your users, but also with your Azure Information Protection (AIP) Scanner infrastructure to protect your files hosted on your on-premise.","title":"In This Episode"},{"location":"sbd/sbd-ep8/#video","text":"","title":"Video"},{"location":"sbd/sbd-ep9/","text":"Episode 9 - Service-side Autolabeling \u2693\ufe0e In This Episode \u2693\ufe0e In this episode, we will continue our discussion around Microsoft Information Protection (MIP) auto-labeling capability, and this one is all about the Service-side Auto Label features. we will learn about the new updates and improvements introduced recently, and how to effectively use the service-side auto label capability. Video \u2693\ufe0e","title":"E09 - Service-side Autolabel"},{"location":"sbd/sbd-ep9/#episode-9-service-side-autolabeling","text":"","title":"Episode 9 - Service-side Autolabeling"},{"location":"sbd/sbd-ep9/#in-this-episode","text":"In this episode, we will continue our discussion around Microsoft Information Protection (MIP) auto-labeling capability, and this one is all about the Service-side Auto Label features. we will learn about the new updates and improvements introduced recently, and how to effectively use the service-side auto label capability.","title":"In This Episode"},{"location":"sbd/sbd-ep9/#video","text":"","title":"Video"},{"location":"sbd/sbd-intro/","text":"About the Series \u2693\ufe0e Introduction \u2693\ufe0e In this new series we explore a fictitious company and the process they must go through to fully adopt and deploy Microsoft 365 compliance technologies. Make sure to check back frequently as we continue to release new episodes! The Story \u2693\ufe0e We are a medical research institution, specializing in conducting research on prominent diseases and are currently focused on developing a research study on COVID 19. We are based in two geographic locations, Australia and US. With the recent increase of cyber attacks worldwide however, we need to develop an IP&G strategy to be able to enhance our information security posture. Click here to check out the videos!","title":"Sbd intro"},{"location":"sbd/sbd-intro/#about-the-series","text":"","title":"About the Series"},{"location":"sbd/sbd-intro/#introduction","text":"In this new series we explore a fictitious company and the process they must go through to fully adopt and deploy Microsoft 365 compliance technologies. Make sure to check back frequently as we continue to release new episodes!","title":"Introduction"},{"location":"sbd/sbd-intro/#the-story","text":"We are a medical research institution, specializing in conducting research on prominent diseases and are currently focused on developing a research study on COVID 19. We are based in two geographic locations, Australia and US. With the recent increase of cyber attacks worldwide however, we need to develop an IP&G strategy to be able to enhance our information security posture. Click here to check out the videos!","title":"The Story"}]}